{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from onnxscript import (script, opset18 as op, FLOAT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Opset18 in module onnxscript.onnx_opset._impl.opset18 object:\n",
      "\n",
      "class Opset18(onnxscript.onnx_opset._impl.opset17.Opset17)\n",
      " |  Method resolution order:\n",
      " |      Opset18\n",
      " |      onnxscript.onnx_opset._impl.opset17.Opset17\n",
      " |      onnxscript.onnx_opset._impl.opset16.Opset16\n",
      " |      onnxscript.onnx_opset._impl.opset15.Opset15\n",
      " |      onnxscript.onnx_opset._impl.opset14.Opset14\n",
      " |      onnxscript.onnx_opset._impl.opset13.Opset13\n",
      " |      onnxscript.onnx_opset._impl.opset12.Opset12\n",
      " |      onnxscript.onnx_opset._impl.opset11.Opset11\n",
      " |      onnxscript.onnx_opset._impl.opset10.Opset10\n",
      " |      onnxscript.onnx_opset._impl.opset9.Opset9\n",
      " |      onnxscript.onnx_opset._impl.opset8.Opset8\n",
      " |      onnxscript.onnx_opset._impl.opset7.Opset7\n",
      " |      onnxscript.onnx_opset._impl.opset6.Opset6\n",
      " |      onnxscript.onnx_opset._impl.opset5.Opset5\n",
      " |      onnxscript.onnx_opset._impl.opset4.Opset4\n",
      " |      onnxscript.onnx_opset._impl.opset3.Opset3\n",
      " |      onnxscript.onnx_opset._impl.opset2.Opset2\n",
      " |      onnxscript.onnx_opset._impl.opset1.Opset1\n",
      " |      onnxscript.values.Opset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  BitwiseAnd(self, A: 'T_BitwiseAnd', B: 'T_BitwiseAnd') -> 'T_BitwiseAnd'\n",
      " |      [üåê BitwiseAnd(18)](https://onnx.ai/onnx/operators/onnx__BitwiseAnd.html#bitwiseand-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulting from performing the bitwise `and` operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the bitwise operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the bitwise operator.\n",
      " |  \n",
      " |  BitwiseNot(self, X: 'T_BitwiseNot') -> 'T_BitwiseNot'\n",
      " |      [üåê BitwiseNot(18)](https://onnx.ai/onnx/operators/onnx__BitwiseNot.html#bitwisenot-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the bitwise not of the input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  BitwiseOr(self, A: 'T_BitwiseOr', B: 'T_BitwiseOr') -> 'T_BitwiseOr'\n",
      " |      [üåê BitwiseOr(18)](https://onnx.ai/onnx/operators/onnx__BitwiseOr.html#bitwiseor-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulting from performing the bitwise `or` operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the bitwise operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the bitwise operator.\n",
      " |  \n",
      " |  BitwiseXor(self, A: 'T_BitwiseXor', B: 'T_BitwiseXor') -> 'T_BitwiseXor'\n",
      " |      [üåê BitwiseXor(18)](https://onnx.ai/onnx/operators/onnx__BitwiseXor.html#bitwisexor-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulting from performing the bitwise `xor` operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the bitwise operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the bitwise operator.\n",
      " |  \n",
      " |  CenterCropPad(self, input_data: 'T_CenterCropPad', shape: 'Tind_CenterCropPad', *, axes: 'Optional[Sequence[int]]' = None) -> 'T_CenterCropPad'\n",
      " |      [üåê CenterCropPad(18)](https://onnx.ai/onnx/operators/onnx__CenterCropPad.html#centercroppad-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Center crop or pad an input to given dimensions.\n",
      " |      \n",
      " |      The crop/pad dimensions can be specified for a subset of the `axes`. Non-specified dimensions will not be\n",
      " |      cropped or padded.\n",
      " |      \n",
      " |      If the input dimensions are bigger than the crop shape, a centered cropping window is extracted from the input.\n",
      " |      If the input dimensions are smaller than the crop shape, the input is padded on each side equally,\n",
      " |      so that the input is centered in the output.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_data: (differentiable) Input to extract the centered crop from.\n",
      " |      \n",
      " |          shape: (non-differentiable) 1-D tensor representing the cropping window\n",
      " |              dimensions.\n",
      " |      \n",
      " |          axes: If provided, it specifies a subset of axes that 'shape' refer to. If\n",
      " |              not provided, all axes are assumed [0, 1, ..., r-1], where r =\n",
      " |              rank(data). Negative value means counting dimensions from the back.\n",
      " |              Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined\n",
      " |              if an axis is repeated.\n",
      " |  \n",
      " |  Col2Im(self, input: 'T_Col2Im', image_shape: 'INT64', block_shape: 'INT64', *, dilations: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_Col2Im'\n",
      " |      [üåê Col2Im(18)](https://onnx.ai/onnx/operators/onnx__Col2Im.html#col2im-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator rearranges column blocks back into a multidimensional image\n",
      " |      \n",
      " |      Col2Im behaves similarly to PyTorch's fold https://pytorch.org/docs/stable/generated/torch.nn.Fold.html,\n",
      " |      but it only supports *batched* multi-dimensional image tensors.\n",
      " |      Another implementation in Python with N-dimension support can be found at https://github.com/f-dangel/unfoldNd/.\n",
      " |      \n",
      " |      NOTE:\n",
      " |        Although specifying image_shape looks redundant because it could be calculated from\n",
      " |        convolution formulas, it is required as input for more advanced scenarios as explained\n",
      " |        at PyTorch's implementation (https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Col2Im.cpp#L10)\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input data tensor to be rearranged from column\n",
      " |              blocks back into an image. This is a 3-dimensional tensor containing [N,\n",
      " |              C * n-ary-product(block_shape), L], where N is batch dimension, C is\n",
      " |              image channel dimension and L is number of blocks.The blocks are\n",
      " |              enumerated in increasing lexicographic-order of their indices.For\n",
      " |              example, with an image-size 10*20 and block-size 9*18, there would be\n",
      " |              2*3 blocks, enumerated in the order block(0, 0), block(0, 1), block(0,\n",
      " |              2), block(1, 0), block(1, 1), block(1, 2).\n",
      " |      \n",
      " |          image_shape: (non-differentiable) The shape of the spatial dimensions of the\n",
      " |              image after rearranging the column blocks.This is a 1-dimensional tensor\n",
      " |              with size of at least 2, containing the value [H_img, W_img]  for a 2-D\n",
      " |              image or [dim_i1, dim_i2, ..., dim_iN] for a N-D image.\n",
      " |      \n",
      " |          block_shape: (non-differentiable) The shape of the block to apply on the\n",
      " |              input.This is a 1-dimensional tensor of size of at least 2, containing\n",
      " |              the value [H_block, W_block]  for a 2-D image or [dim_b1, dim_b2, ...,\n",
      " |              dim_bN] for a N-D block.This is the block-shape before dilation is\n",
      " |              applied to it.\n",
      " |      \n",
      " |          dilations: 1-dimensional tensor with dilation value along each spatial axis\n",
      " |              of the image. If not present, the dilation defaults to 1 along each\n",
      " |              spatial axis of the image.\n",
      " |      \n",
      " |          pads: 1-dimensional tensor with padding value for the beginning and ending\n",
      " |              along each spatial axis, it can take any value greater than or equal to\n",
      " |              0. The value represent the number of pixels added to the beginning and\n",
      " |              end part of the corresponding axis. `pads` format should be as follow\n",
      " |              [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin is the number\n",
      " |              of pixels added at the beginning of axis `i` and xi_end is the number of\n",
      " |              pixels added at the end of axis `i`. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: 1-dimensional tensor with stride value along each spatial axis. If\n",
      " |              not present, the stride defaults to 1 along each spatial axis.\n",
      " |  \n",
      " |  GroupNormalization(self, X: 'T_GroupNormalization', scale: 'T_GroupNormalization', bias: 'T_GroupNormalization', *, epsilon: 'float' = 9.999999747378752e-06, num_groups: 'int') -> 'T_GroupNormalization'\n",
      " |      [üåê GroupNormalization(18)](https://onnx.ai/onnx/operators/onnx__GroupNormalization.html#groupnormalization-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      A GroupNormalization function. Carries out group normalization as described in\n",
      " |      the paper https://arxiv.org/abs/1803.08494\n",
      " |      \n",
      " |      This operator transforms input according to\n",
      " |      ::\n",
      " |      \n",
      " |          y = scale * (x - mean) / sqrt(variance + epsilon) + bias,\n",
      " |      \n",
      " |      \n",
      " |      where the mean and variance are computed per instance per group of channels, and\n",
      " |      `scale` and `bias` should be specified for each group of channels. The number of\n",
      " |      groups `num_groups` should be divisible by the number of channels so that there are\n",
      " |      an equal number of channels per group.\n",
      " |      \n",
      " |      When the number of groups is the same as the number of channels, this operator is\n",
      " |      equivalent to InstanceNormalization. When there is only one group, this operator\n",
      " |      is equivalent to LayerNormalization.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor. Dimensions for image cases are `(N x\n",
      " |              C x H x W)`, where `N` is the batch size, `C` is the number of channels,\n",
      " |              and `H` and `W` are the height and width of the data. Statistics are\n",
      " |              computed for every group of channels over `C`, `H`, and `W`. For\n",
      " |              non-image cases, the dimensions are in the form of `(N x C x D1 x D2 ...\n",
      " |              Dn)`.\n",
      " |      \n",
      " |          scale: (differentiable) Scale tensor of shape `(num_groups)`.\n",
      " |      \n",
      " |          bias: (differentiable) Bias tensor of shape `(num_groups)`.\n",
      " |      \n",
      " |          epsilon: The epsilon value to use to avoid division by zero.\n",
      " |      \n",
      " |          num_groups: The number of groups of channels. It should be a divisor of the\n",
      " |              number of channels `C`.\n",
      " |  \n",
      " |  LpPool(self, X: 'T_LpPool', *, auto_pad: 'str' = 'NOTSET', ceil_mode: 'int' = 0, dilations: 'Optional[Sequence[int]]' = None, kernel_shape: 'Sequence[int]', p: 'int' = 2, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_LpPool'\n",
      " |      [üåê LpPool(18)](https://onnx.ai/onnx/operators/onnx__LpPool.html#lppool-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       LpPool consumes an input tensor X and applies Lp pooling across\n",
      " |       the tensor according to kernel sizes, stride sizes, and pad lengths.\n",
      " |       Lp pooling consisting of computing the Lp norm on all values of a subset\n",
      " |       of the input tensor according to the kernel size and downsampling the\n",
      " |       data into the output tensor Y for further processing. The output spatial shape will be following:\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - {kernelSpatialShape}) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       or\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - {kernelSpatialShape}) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       if ceil_mode is enabled `pad_shape[i]` is the sum of pads along axis `i`.\n",
      " |      \n",
      " |       `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n",
      " |       ```\n",
      " |       VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - {kernelSpatialShape} + 1) / strides_spatial_shape[i])\n",
      " |       SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n",
      " |       ```\n",
      " |       And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n",
      " |       ```\n",
      " |       pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + {kernelSpatialShape} - input_spatial_shape[i]\n",
      " |       ```\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size.\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          ceil_mode: Whether to use ceil or floor (default) to compute the output\n",
      " |              shape.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults is 1 along each spatial axis.\n",
      " |      \n",
      " |          kernel_shape: The size of the kernel along each axis.\n",
      " |      \n",
      " |          p: p value of the Lp norm used to pool over the input data.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  Mish(self, X: 'T_Mish') -> 'T_Mish'\n",
      " |      [üåê Mish(18)](https://onnx.ai/onnx/operators/onnx__Mish.html#mish-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Mish: A Self Regularized Non-Monotonic Neural Activation Function.\n",
      " |      \n",
      " |      Perform the linear unit element-wise on the input tensor X using formula:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  OptionalGetElement(self, input: 'O_OptionalGetElement') -> 'V_OptionalGetElement'\n",
      " |      [üåê OptionalGetElement(18)](https://onnx.ai/onnx/operators/onnx__OptionalGetElement.html#optionalgetelement-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      If the input is a tensor or sequence type, it returns the input.\n",
      " |      If the input is an optional type, it outputs the element in the input.\n",
      " |      It is an error if the input is an empty optional-type (i.e. does not have an element) and the behavior is undefined in this case.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: The optional input.\n",
      " |  \n",
      " |  OptionalHasElement(self, input: 'Optional[O_OptionalHasElement]' = None) -> 'B_OptionalHasElement'\n",
      " |      [üåê OptionalHasElement(18)](https://onnx.ai/onnx/operators/onnx__OptionalHasElement.html#optionalhaselement-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns true if (1) the input is an optional-type and contains an element,\n",
      " |      or, (2) the input is a tensor or sequence type.\n",
      " |      If the input is not provided or is an empty optional-type, this op returns false.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (optional) The optional input.\n",
      " |  \n",
      " |  Pad(self, data: 'T_Pad', pads: 'INT64', constant_value: 'Optional[T_Pad]' = None, axes: 'Optional[Tind_Pad]' = None, *, mode: 'str' = 'constant') -> 'T_Pad'\n",
      " |      [üåê Pad(18)](https://onnx.ai/onnx/operators/onnx__Pad.html#pad-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given a tensor containing the data to be padded (`data`), a tensor containing the number of start and end pad values for axis (`pads`), (optionally) a `mode`, and (optionally) `constant_value`,\n",
      " |      a padded tensor (`output`) is generated.\n",
      " |      \n",
      " |      The three supported `modes` are (similar to corresponding modes supported by `numpy.pad`):\n",
      " |      \n",
      " |      1) `constant`(default) - pads with a given constant value as specified by `constant_value` (which defaults to 0, empty string, or False)\n",
      " |      \n",
      " |      2) `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis\n",
      " |      \n",
      " |      3) `edge` - pads with the edge values of array\n",
      " |      \n",
      " |      \n",
      " |      Example 1 (`constant` mode):\n",
      " |      \n",
      " |      Insert 0 pads to the beginning of the second dimension.\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2],\n",
      " |              [2.3, 3.4],\n",
      " |              [4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |          pads = [0, 2, 0, 0]\n",
      " |      \n",
      " |          mode = 'constant'\n",
      " |      \n",
      " |          constant_value = 0.0\n",
      " |      \n",
      " |          output = [\n",
      " |              [0.0, 0.0, 1.0, 1.2],\n",
      " |              [0.0, 0.0, 2.3, 3.4],\n",
      " |              [0.0, 0.0, 4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2 (`reflect` mode):\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2],\n",
      " |              [2.3, 3.4],\n",
      " |              [4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |          pads = [0, 2, 0, 0]\n",
      " |      \n",
      " |          mode = 'reflect'\n",
      " |      \n",
      " |          output = [\n",
      " |              [1.0, 1.2, 1.0, 1.2],\n",
      " |              [2.3, 3.4, 2.3, 3.4],\n",
      " |              [4.5, 5.7, 4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 3 (`edge` mode):\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2],\n",
      " |              [2.3, 3.4],\n",
      " |              [4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |          pads = [0, 2, 0, 0]\n",
      " |      \n",
      " |          mode = 'edge'\n",
      " |      \n",
      " |          output = [\n",
      " |              [1.0, 1.0, 1.0, 1.2],\n",
      " |              [2.3, 2.3, 2.3, 3.4],\n",
      " |              [4.5, 4.5, 4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Input tensor.\n",
      " |      \n",
      " |          pads: (non-differentiable) Tensor of integers indicating the number of\n",
      " |              padding elements to add or remove (if negative) at the beginning and end\n",
      " |              of each axis. For 2D input tensor, it is the number of pixels. `pads`\n",
      " |              should be a 1D tensor of shape [2 * num_axes] where `num_axes` refers to\n",
      " |              the number of elements in the `axes` input or the input rank if `axes`\n",
      " |              are not provided explicitly. `pads` format should be: [x1_begin,\n",
      " |              x2_begin, ..., x1_end, x2_end,...], where xi_begin is the number of pad\n",
      " |              values added at the beginning of axis `axes[i]` and xi_end, the number\n",
      " |              of pad values added at the end of axis `axes[i]`.\n",
      " |      \n",
      " |          constant_value: (optional, non-differentiable) (Optional) A scalar value to\n",
      " |              be used if the mode chosen is `constant` (by default it is 0, empty\n",
      " |              string or False).\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) 1-D tensor of axes that `pads` apply\n",
      " |              to. Negative value means counting dimensions from the back. Accepted\n",
      " |              range is [-r, r-1] where r = rank(data). Behavior is undefined if an\n",
      " |              axis is repeated. If not provided, all axes are assumed (`[0, 1, ...,\n",
      " |              input_rank-1]`).\n",
      " |      \n",
      " |          mode: Supported modes: `constant`(default), `reflect`, `edge`\n",
      " |  \n",
      " |  ReduceL1(self, data: 'T_ReduceL1', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceL1'\n",
      " |      [üåê ReduceL1(18)](https://onnx.ai/onnx/operators/onnx__ReduceL1.html#reducel1-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the L1 norm of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceL2(self, data: 'T_ReduceL2', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceL2'\n",
      " |      [üåê ReduceL2(18)](https://onnx.ai/onnx/operators/onnx__ReduceL2.html#reducel2-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the L2 norm of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceLogSum(self, data: 'T_ReduceLogSum', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceLogSum'\n",
      " |      [üåê ReduceLogSum(18)](https://onnx.ai/onnx/operators/onnx__ReduceLogSum.html#reducelogsum-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the log sum of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceLogSumExp(self, data: 'T_ReduceLogSumExp', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceLogSumExp'\n",
      " |      [üåê ReduceLogSumExp(18)](https://onnx.ai/onnx/operators/onnx__ReduceLogSumExp.html#reducelogsumexp-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the log sum exponent of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceMax(self, data: 'T_ReduceMax', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceMax'\n",
      " |      [üåê ReduceMax(18)](https://onnx.ai/onnx/operators/onnx__ReduceMax.html#reducemax-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the max of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceMean(self, data: 'T_ReduceMean', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceMean'\n",
      " |      [üåê ReduceMean(18)](https://onnx.ai/onnx/operators/onnx__ReduceMean.html#reducemean-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the mean of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceMin(self, data: 'T_ReduceMin', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceMin'\n",
      " |      [üåê ReduceMin(18)](https://onnx.ai/onnx/operators/onnx__ReduceMin.html#reducemin-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the min of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceProd(self, data: 'T_ReduceProd', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceProd'\n",
      " |      [üåê ReduceProd(18)](https://onnx.ai/onnx/operators/onnx__ReduceProd.html#reduceprod-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the product of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceSumSquare(self, data: 'T_ReduceSumSquare', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceSumSquare'\n",
      " |      [üåê ReduceSumSquare(18)](https://onnx.ai/onnx/operators/onnx__ReduceSumSquare.html#reducesumsquare-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the sum square of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  Resize(self, X: 'T1_Resize', roi: 'Optional[T2_Resize]' = None, scales: 'Optional[FLOAT]' = None, sizes: 'Optional[INT64]' = None, *, antialias: 'int' = 0, axes: 'Optional[Sequence[int]]' = None, coordinate_transformation_mode: 'str' = 'half_pixel', cubic_coeff_a: 'float' = -0.75, exclude_outside: 'int' = 0, extrapolation_value: 'float' = 0.0, keep_aspect_ratio_policy: 'str' = 'stretch', mode: 'str' = 'nearest', nearest_mode: 'str' = 'round_prefer_floor') -> 'T1_Resize'\n",
      " |      [üåê Resize(18)](https://onnx.ai/onnx/operators/onnx__Resize.html#resize-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\n",
      " |      Each dimension value of the output tensor is: <br/>\n",
      " |        `output_dimension = floor(input_dimension * (roi_end - roi_start) * scale)` <br/>\n",
      " |      if input \\\"sizes\\\" is not specified.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) N-D tensor\n",
      " |      \n",
      " |          roi: (optional, non-differentiable) 1-D tensor given as [start1, ...,\n",
      " |              startN, end1, ..., endN], where N is the rank of X or the length of\n",
      " |              axes, if provided. The RoIs' coordinates are normalized in the\n",
      " |              coordinate system of the input image. It only takes effect when\n",
      " |              coordinate_transformation_mode is \"tf_crop_and_resize\"\n",
      " |      \n",
      " |          scales: (optional, non-differentiable) The scale array along each dimension.\n",
      " |              It takes value greater than 0. If it's less than 1, it's sampling down,\n",
      " |              otherwise, it's upsampling. The number of elements of 'scales' should be\n",
      " |              the same as the rank of input 'X' or the length of 'axes', if provided.\n",
      " |              One of 'scales' and 'sizes' MUST be specified and it is an error if both\n",
      " |              are specified. If 'sizes' is needed, the user can use an empty string as\n",
      " |              the name of 'scales' in this operator's input list.\n",
      " |      \n",
      " |          sizes: (optional, non-differentiable) Target size of the output tensor. Its\n",
      " |              interpretation depends on the 'keep_aspect_ratio_policy' value.The\n",
      " |              number of elements of 'sizes' should be the same as the rank of input\n",
      " |              'X', or the length of 'axes', if provided. Only one of 'scales' and\n",
      " |              'sizes' can be specified.\n",
      " |      \n",
      " |          antialias: If set to 1, \"linear\" and \"cubic\" interpolation modes will use an\n",
      " |              antialiasing filter when downscaling. Antialiasing is achieved by\n",
      " |              stretching the resampling filter by a factor max(1, 1 / scale), which\n",
      " |              means that when downsampling, more input pixels contribute to an output\n",
      " |              pixel.\n",
      " |      \n",
      " |          axes: If provided, it specifies a subset of axes that 'roi', 'scales' and\n",
      " |              'sizes' refer to. If not provided, all axes are assumed [0, 1, ...,\n",
      " |              r-1], where r = rank(data). Non-specified dimensions are interpreted as\n",
      " |              non-resizable. Negative value means counting dimensions from the back.\n",
      " |              Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined\n",
      " |              if an axis is repeated.\n",
      " |      \n",
      " |          coordinate_transformation_mode:\n",
      " |      This attribute describes how to transform\n",
      " |              the coordinate in the resized tensor to the coordinate in the original\n",
      " |              tensor. <br/>\n",
      " |      \n",
      " |      The coordinate of each dimension is transformed\n",
      " |              individually. Let's describe a case using axis x as an example.\n",
      " |      Denote\n",
      " |              x_resized as the coordinate of axis x in the resized tensor, x_original\n",
      " |              as the coordinate of axis x in the original tensor, `length_original` as\n",
      " |              the length of the original tensor in axis x, length_resized as the\n",
      " |              length of the resized tensor in axis x, roi_x = (start_x, end_x) of the\n",
      " |              axis x in input \"roi\", `scale = length_resized / length_original`, <br/>\n",
      " |              if coordinate_transformation_mode is `\"half_pixel\"`, <br/>\n",
      " |      `x_original =\n",
      " |              (x_resized + 0.5) / scale - 0.5` <br/>\n",
      " |      \n",
      " |      if\n",
      " |              coordinate_transformation_mode is `\"pytorch_half_pixel\"`, <br/>\n",
      " |              `x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0`\n",
      " |              <br/>\n",
      " |      \n",
      " |      if coordinate_transformation_mode is `\"align_corners\"`, <br/>\n",
      " |              `x_original = x_resized * (length_original - 1) / (length_resized - 1)`\n",
      " |              <br/>\n",
      " |      \n",
      " |      if coordinate_transformation_mode is `\"asymmetric\"`, <br/>\n",
      " |              `x_original = x_resized / scale` <br/>\n",
      " |      \n",
      " |      if\n",
      " |              coordinate_transformation_mode is `\"tf_crop_and_resize\"`, <br/>\n",
      " |              `x_original = length_resized > 1 ? start_x * (length_original - 1) +\n",
      " |              x_resized * (end_x - start_x) * (length_original - 1) / (length_resized\n",
      " |              - 1) : 0.5 * (start_x + end_x) * (length_original - 1)`\n",
      " |      .\n",
      " |      \n",
      " |          cubic_coeff_a: The coefficient 'a' used in cubic interpolation. Two common\n",
      " |              choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch).\n",
      " |              Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711\n",
      " |              for the details. This attribute is valid only if mode is \"cubic\".\n",
      " |      \n",
      " |          exclude_outside: If set to 1, the weight of sampling locations outside the\n",
      " |              tensor will be set to 0 and the weight will be renormalized so that\n",
      " |              their sum is 1.0. The default value is 0.\n",
      " |      \n",
      " |          extrapolation_value: When coordinate_transformation_mode is\n",
      " |              \"tf_crop_and_resize\" and x_original is outside the range [0,\n",
      " |              length_original - 1], this value is used as the corresponding output\n",
      " |              value. Default is 0.0f.\n",
      " |      \n",
      " |          keep_aspect_ratio_policy:\n",
      " |      This attribute describes how to interpret the\n",
      " |              `sizes` input with regard to keeping the original aspect ratio of the\n",
      " |              input, and it is not applicable when\n",
      " |      the `scales` input is used. <br/>\n",
      " |              Given a set of `sizes`, associated with a subset of `axes` (explicitly\n",
      " |              provided or default), and assuming `d = axes[i]`, with `i` being the\n",
      " |              index of the provided `sizes`. <br/>\n",
      " |      \n",
      " |      If `keep_aspect_ratio_policy` is\n",
      " |              `\"stretch\"`, the original aspect ratio is disregarded, and the input is\n",
      " |              resized to the specified size: <br/>\n",
      " |      `out_size[d] = sizes[i]` <br/>\n",
      " |      \n",
      " |      If\n",
      " |              `keep_aspect_ratio_policy` is `\"not_larger\"`, the sizes are adjusted so\n",
      " |              that no extent of the output is larger than the specified size, while\n",
      " |              keeping the original aspect ratio: <br/>\n",
      " |      `scale = Min(sizes[i] /\n",
      " |              in_size[d])` <br/>\n",
      " |      `out_size[d] = round_int(scale * in_size[i])` <br/>\n",
      " |              If `keep_aspect_ratio_policy` is `\"not_smaller\"`, the sizes are adjusted\n",
      " |              so that no extent of the output is smaller than the specified size,\n",
      " |              while keeping the original aspect ratio: <br/>\n",
      " |      `scale = Max(sizes[i] /\n",
      " |              in_size[d])` <br/>\n",
      " |      `out_size[d] = round_int(scale * in_size[i])` <br/>\n",
      " |              For non-resizable axes (those not specified in `axes`), the output size\n",
      " |              will be equal to the input size.\n",
      " |      \n",
      " |      Note: `round_int` stands for computing\n",
      " |              the nearest integer value, rounding halfway cases up.\n",
      " |      \n",
      " |          mode: Three interpolation modes: \"nearest\" (default), \"linear\" and \"cubic\".\n",
      " |              The \"linear\" mode includes linear interpolation for 1D tensor and\n",
      " |              N-linear interpolation for N-D tensor (for example, bilinear\n",
      " |              interpolation for 2D tensor). The \"cubic\" mode includes cubic\n",
      " |              interpolation for 1D tensor and N-cubic interpolation for N-D tensor\n",
      " |              (for example, bicubic interpolation for 2D tensor).\n",
      " |      \n",
      " |          nearest_mode: Four modes: \"round_prefer_floor\" (default, as known as round\n",
      " |              half down), \"round_prefer_ceil\" (as known as round half up), \"floor\",\n",
      " |              \"ceil\". Only used by nearest interpolation. It indicates how to get\n",
      " |              \"nearest\" pixel in input tensor from x_original, so this attribute is\n",
      " |              valid only if \"mode\" is \"nearest\".\n",
      " |  \n",
      " |  ScatterElements(self, data: 'T_ScatterElements', indices: 'Tind_ScatterElements', updates: 'T_ScatterElements', *, axis: 'int' = 0, reduction: 'str' = 'none') -> 'T_ScatterElements'\n",
      " |      [üåê ScatterElements(18)](https://onnx.ai/onnx/operators/onnx__ScatterElements.html#scatterelements-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      ScatterElements takes three inputs `data`, `updates`, and `indices` of the same\n",
      " |      rank r >= 1 and an optional attribute axis that identifies an axis of `data`\n",
      " |      (by default, the outer-most axis, that is axis 0). The output of the operation\n",
      " |      is produced by creating a copy of the input `data`, and then updating its value\n",
      " |      to values specified by `updates` at specific index positions specified by\n",
      " |      `indices`. Its output shape is the same as the shape of `data`.\n",
      " |      \n",
      " |      For each entry in `updates`, the target index in `data` is obtained by combining\n",
      " |      the corresponding entry in `indices` with the index of the entry itself: the\n",
      " |      index-value for dimension = axis is obtained from the value of the corresponding\n",
      " |      entry in `indices` and the index-value for dimension != axis is obtained from the\n",
      " |      index of the entry itself.\n",
      " |      \n",
      " |      `reduction` allows specification of an optional reduction operation, which is applied to all values in `updates`\n",
      " |      tensor into `output` at the specified `indices`.\n",
      " |      In cases where `reduction` is set to \"none\", indices should not have duplicate entries: that is, if idx1 != idx2,\n",
      " |      then indices[idx1] != indices[idx2]. For instance, in a 2-D tensor case, the update\n",
      " |      corresponding to the [i][j] entry is performed as below:\n",
      " |      ::\n",
      " |      \n",
      " |          output[indices[i][j]][j] = updates[i][j] if axis = 0,\n",
      " |          output[i][indices[i][j]] = updates[i][j] if axis = 1,\n",
      " |      \n",
      " |      \n",
      " |      When `reduction` is set to some reduction function `f`, the update corresponding to the [i][j] entry is performed as below:\n",
      " |      ::\n",
      " |      \n",
      " |          output[indices[i][j]][j] += f(output[indices[i][j]][j], updates[i][j]) if axis = 0,\n",
      " |          output[i][indices[i][j]] += f(output[i][indices[i][j]], updates[i][j]) if axis = 1,\n",
      " |      \n",
      " |      \n",
      " |      where the `f` is `+`, `*`, `max` or `min` as specified.\n",
      " |      \n",
      " |      This operator is the inverse of GatherElements. It is similar to Torch's Scatter operation.\n",
      " |      \n",
      " |      (Opset 18 change): Adds max/min to the set of allowed reduction ops.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [0.0, 0.0, 0.0],\n",
      " |              [0.0, 0.0, 0.0],\n",
      " |              [0.0, 0.0, 0.0],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [1, 0, 2],\n",
      " |              [0, 2, 1],\n",
      " |          ]\n",
      " |          updates = [\n",
      " |              [1.0, 1.1, 1.2],\n",
      " |              [2.0, 2.1, 2.2],\n",
      " |          ]\n",
      " |          output = [\n",
      " |              [2.0, 1.1, 0.0]\n",
      " |              [1.0, 0.0, 2.2]\n",
      " |              [0.0, 2.1, 1.2]\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      ::\n",
      " |      \n",
      " |          data = [[1.0, 2.0, 3.0, 4.0, 5.0]]\n",
      " |          indices = [[1, 3]]\n",
      " |          updates = [[1.1, 2.1]]\n",
      " |          axis = 1\n",
      " |          output = [[1.0, 1.1, 3.0, 2.1, 5.0]]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of int32/int64 indices, of r >= 1 (same\n",
      " |              rank as input). All index values are expected to be within bounds [-s,\n",
      " |              s-1] along axis of size s. It is an error if any of the index values are\n",
      " |              out of bounds.\n",
      " |      \n",
      " |          updates: (differentiable) Tensor of rank r >=1 (same rank and shape as\n",
      " |              indices)\n",
      " |      \n",
      " |          axis: Which axis to scatter on. Negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-r, r-1] where r = rank(data).\n",
      " |      \n",
      " |          reduction: Type of reduction to apply: none (default), add, mul, max, min.\n",
      " |              'none': no reduction applied. 'add':  reduction using the addition\n",
      " |              operation. 'mul': reduction using the multiplication operation.'max':\n",
      " |              reduction using the maximum operation.'min': reduction using the minimum\n",
      " |              operation.\n",
      " |  \n",
      " |  ScatterND(self, data: 'T_ScatterND', indices: 'INT64', updates: 'T_ScatterND', *, reduction: 'str' = 'none') -> 'T_ScatterND'\n",
      " |      [üåê ScatterND(18)](https://onnx.ai/onnx/operators/onnx__ScatterND.html#scatternd-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      ScatterND takes three inputs `data` tensor of rank r >= 1, `indices` tensor of rank q >= 1,\n",
      " |      and `updates` tensor of rank q + r - indices.shape[-1] - 1. The output of the operation\n",
      " |      is produced by creating a copy of the input `data`, and then updating its value to values\n",
      " |      specified by `updates` at specific index positions specified by `indices`. Its output shape\n",
      " |      is the same as the shape of `data`.\n",
      " |      \n",
      " |      `indices` is an integer tensor. Let k denote indices.shape[-1], the last dimension in the shape of `indices`.\n",
      " |      `indices` is treated as a (q-1)-dimensional tensor of k-tuples, where each k-tuple is a partial-index into `data`.\n",
      " |      Hence, k can be a value at most the rank of `data`. When k equals rank(data), each update entry specifies an\n",
      " |      update to a single element of the tensor. When k is less than rank(data) each update entry specifies an\n",
      " |      update to a slice of the tensor. Index values are allowed to be negative, as per the usual\n",
      " |      convention for counting backwards from the end, but are expected in the valid range.\n",
      " |      \n",
      " |      `updates` is treated as a (q-1)-dimensional tensor of replacement-slice-values. Thus, the\n",
      " |      first (q-1) dimensions of updates.shape must match the first (q-1) dimensions of indices.shape.\n",
      " |      The remaining dimensions of `updates` correspond to the dimensions of the\n",
      " |      replacement-slice-values. Each replacement-slice-value is a (r-k) dimensional tensor,\n",
      " |      corresponding to the trailing (r-k) dimensions of `data`.  Thus, the shape of `updates`\n",
      " |      must equal indices.shape[0:q-1] ++ data.shape[k:r-1], where ++ denotes the concatenation\n",
      " |      of shapes.\n",
      " |      \n",
      " |      The `output` is calculated via the following equation:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          output = np.copy(data)\n",
      " |          update_indices = indices.shape[:-1]\n",
      " |          for idx in np.ndindex(update_indices):\n",
      " |              output[indices[idx]] = updates[idx]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      The order of iteration in the above loop is not specified.\n",
      " |      In particular, indices should not have duplicate entries: that is, if idx1 != idx2, then indices[idx1] != indices[idx2].\n",
      " |      This ensures that the output value does not depend on the iteration order.\n",
      " |      \n",
      " |      `reduction` allows specification of an optional reduction operation, which is applied to all values in `updates`\n",
      " |      tensor into `output` at the specified `indices`.\n",
      " |      In cases where `reduction` is set to \"none\", indices should not have duplicate entries: that is, if idx1 != idx2,\n",
      " |      then indices[idx1] != indices[idx2]. This ensures that the output value does not depend on the iteration order.\n",
      " |      When `reduction` is set to some reduction function `f`, `output` is calculated as follows:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          output = np.copy(data)\n",
      " |          update_indices = indices.shape[:-1]\n",
      " |          for idx in np.ndindex(update_indices):\n",
      " |              output[indices[idx]] = f(output[indices[idx]], updates[idx])\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      where the `f` is `+`, `*`, `max` or `min` as specified.\n",
      " |      \n",
      " |      This operator is the inverse of GatherND.\n",
      " |      \n",
      " |      (Opset 18 change): Adds max/min to the set of allowed reduction ops.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      ::\n",
      " |      \n",
      " |          data    = [1, 2, 3, 4, 5, 6, 7, 8]\n",
      " |          indices = [[4], [3], [1], [7]]\n",
      " |          updates = [9, 10, 11, 12]\n",
      " |          output  = [1, 11, 3, 10, 9, 6, 7, 12]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      ::\n",
      " |      \n",
      " |          data    = [[[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],\n",
      " |                      [[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],\n",
      " |                      [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]],\n",
      " |                      [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]]]\n",
      " |          indices = [[0], [2]]\n",
      " |          updates = [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      " |                      [[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4]]]\n",
      " |          output  = [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      " |                      [[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],\n",
      " |                      [[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4]],\n",
      " |                      [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]]]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of rank q >= 1.\n",
      " |      \n",
      " |          updates: (differentiable) Tensor of rank q + r - indices_shape[-1] - 1.\n",
      " |      \n",
      " |          reduction: Type of reduction to apply: none (default), add, mul, max, min.\n",
      " |              'none': no reduction applied. 'add':  reduction using the addition\n",
      " |              operation. 'mul':  reduction using the addition operation. 'max':\n",
      " |              reduction using the maximum operation.'min': reduction using the minimum\n",
      " |              operation.\n",
      " |  \n",
      " |  Split(self, input: 'T_Split', split: 'Optional[INT64]' = None, *, axis: 'int' = 0, num_outputs: 'Optional[int]' = None) -> 'T_Split'\n",
      " |      [üåê Split(18)](https://onnx.ai/onnx/operators/onnx__Split.html#split-18 \"Online Documentation\")\n",
      " |      \n",
      " |      Split a tensor into a list of tensors, along the specified 'axis'.\n",
      " |      Either input 'split' or the attribute 'num_outputs' should be specified, but not both.\n",
      " |      If the attribute 'num_outputs' is specified, then the tensor is split into equal sized parts.\n",
      " |      If the tensor is not evenly splittable into `num_outputs`, the last chunk will be smaller.\n",
      " |      If the input 'split' is specified, it indicates the sizes of each output in the split.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The tensor to split\n",
      " |      \n",
      " |          split: (optional, non-differentiable) Optional length of each output. Values\n",
      " |              should be >= 0.Sum of the values must be equal to the dim value at\n",
      " |              'axis' specified.\n",
      " |      \n",
      " |          axis: Which axis to split on. A negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-rank, rank-1] where r = rank(input).\n",
      " |      \n",
      " |          num_outputs: Number of outputs to split parts of the tensor into. If the\n",
      " |              tensor is not evenly splittable the last chunk will be smaller.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  B_OptionalHasElement = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  O_OptionalGetElement = ~O_OptionalGetElement\n",
      " |  \n",
      " |  O_OptionalHasElement = ~O_OptionalHasElement\n",
      " |  \n",
      " |  T1_Resize = ~T1_Resize\n",
      " |  \n",
      " |  T2_Resize = ~T2_Resize\n",
      " |  \n",
      " |  T_BitwiseAnd = ~T_BitwiseAnd\n",
      " |  \n",
      " |  T_BitwiseNot = ~T_BitwiseNot\n",
      " |  \n",
      " |  T_BitwiseOr = ~T_BitwiseOr\n",
      " |  \n",
      " |  T_BitwiseXor = ~T_BitwiseXor\n",
      " |  \n",
      " |  T_CenterCropPad = ~T_CenterCropPad\n",
      " |  \n",
      " |  T_Col2Im = ~T_Col2Im\n",
      " |  \n",
      " |  T_GroupNormalization = ~T_GroupNormalization\n",
      " |  \n",
      " |  T_LpPool = ~T_LpPool\n",
      " |  \n",
      " |  T_Mish = ~T_Mish\n",
      " |  \n",
      " |  T_Pad = ~T_Pad\n",
      " |  \n",
      " |  T_ReduceL1 = ~T_ReduceL1\n",
      " |  \n",
      " |  T_ReduceL2 = ~T_ReduceL2\n",
      " |  \n",
      " |  T_ReduceLogSum = ~T_ReduceLogSum\n",
      " |  \n",
      " |  T_ReduceLogSumExp = ~T_ReduceLogSumExp\n",
      " |  \n",
      " |  T_ReduceMax = ~T_ReduceMax\n",
      " |  \n",
      " |  T_ReduceMean = ~T_ReduceMean\n",
      " |  \n",
      " |  T_ReduceMin = ~T_ReduceMin\n",
      " |  \n",
      " |  T_ReduceProd = ~T_ReduceProd\n",
      " |  \n",
      " |  T_ReduceSumSquare = ~T_ReduceSumSquare\n",
      " |  \n",
      " |  T_ScatterElements = ~T_ScatterElements\n",
      " |  \n",
      " |  T_ScatterND = ~T_ScatterND\n",
      " |  \n",
      " |  T_Split = ~T_Split\n",
      " |  \n",
      " |  Tind_CenterCropPad = ~Tind_CenterCropPad\n",
      " |  \n",
      " |  Tind_Pad = ~Tind_Pad\n",
      " |  \n",
      " |  Tind_ScatterElements = ~Tind_ScatterElements\n",
      " |  \n",
      " |  V_OptionalGetElement = typing.Union[typing.Sequence[onnxscript.onnx_ty...\n",
      " |  \n",
      " |  __annotations__ = {'B_OptionalHasElement': 'TypeAlias', 'V_OptionalGet...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset17.Opset17:\n",
      " |  \n",
      " |  BlackmanWindow(self, size: 'T1_BlackmanWindow', *, output_datatype: 'int' = 1, periodic: 'int' = 1) -> 'T2_BlackmanWindow'\n",
      " |      [üåê BlackmanWindow(17)](https://onnx.ai/onnx/operators/onnx__BlackmanWindow.html#blackmanwindow-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generates a Blackman window as described in the paper https://ieeexplore.ieee.org/document/1455106.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          size: (non-differentiable) A scalar value indicating the length of the\n",
      " |              window.\n",
      " |      \n",
      " |          output_datatype: The data type of the output tensor. Strictly must be one of\n",
      " |              the values from DataType enum in TensorProto whose values correspond to\n",
      " |              T2. The default value is 1 = FLOAT.\n",
      " |      \n",
      " |          periodic: If 1, returns a window to be used as periodic function. If 0,\n",
      " |              return a symmetric window. When 'periodic' is specified, hann computes a\n",
      " |              window of length size + 1 and returns the first size points. The default\n",
      " |              value is 1.\n",
      " |  \n",
      " |  DFT(self, input: 'T1_DFT', dft_length: 'Optional[T2_DFT]' = None, *, axis: 'int' = 1, inverse: 'int' = 0, onesided: 'int' = 0) -> 'T1_DFT'\n",
      " |      [üåê DFT(17)](https://onnx.ai/onnx/operators/onnx__DFT.html#dft-17 \"Online Documentation\")\n",
      " |      \n",
      " |      Computes the discrete Fourier transform of input.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: (non-differentiable) For real input, the following shape is expected:\n",
      " |              [batch_idx][signal_dim1][signal_dim2]...[signal_dimN][1]. For complex\n",
      " |              input, the following shape is expected:\n",
      " |              [batch_idx][signal_dim1][signal_dim2]...[signal_dimN][2]. The first\n",
      " |              dimension is the batch dimension. The following N dimentions correspond\n",
      " |              to the signal's dimensions. The final dimension represents the real and\n",
      " |              imaginary parts of the value in that order.\n",
      " |      \n",
      " |          dft_length: (optional, non-differentiable) The length of the signal.If\n",
      " |              greater than the axis dimension, the signal will be zero-padded up to\n",
      " |              dft_length. If less than the axis dimension, only the first dft_length\n",
      " |              values will be used as the signal. It's an optional value.\n",
      " |      \n",
      " |          axis: The axis on which to perform the DFT. By default this value is set to\n",
      " |              1, which corresponds to the first dimension after the batch index.\n",
      " |      \n",
      " |          inverse: Whether to perform the inverse discrete fourier transform. By\n",
      " |              default this value is set to 0, which corresponds to false.\n",
      " |      \n",
      " |          onesided: If onesided is 1, only values for w in [0, 1, 2, ...,\n",
      " |              floor(n_fft/2) + 1] are returned because the real-to-complex Fourier\n",
      " |              transform satisfies the conjugate symmetry, i.e., X[m, w] =\n",
      " |              X[m,w]=X[m,n_fft-w]*. Note if the input or window tensors are complex,\n",
      " |              then onesided output is not possible. Enabling onesided with real inputs\n",
      " |              performs a Real-valued fast Fourier transform (RFFT). When invoked with\n",
      " |              real or complex valued input, the default value is 0. Values can be 0 or\n",
      " |              1.\n",
      " |  \n",
      " |  HammingWindow(self, size: 'T1_HammingWindow', *, output_datatype: 'int' = 1, periodic: 'int' = 1) -> 'T2_HammingWindow'\n",
      " |      [üåê HammingWindow(17)](https://onnx.ai/onnx/operators/onnx__HammingWindow.html#hammingwindow-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generates a Hamming window as described in the paper https://ieeexplore.ieee.org/document/1455106.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          size: (non-differentiable) A scalar value indicating the length of the\n",
      " |              window.\n",
      " |      \n",
      " |          output_datatype: The data type of the output tensor. Strictly must be one of\n",
      " |              the values from DataType enum in TensorProto whose values correspond to\n",
      " |              T2. The default value is 1 = FLOAT.\n",
      " |      \n",
      " |          periodic: If 1, returns a window to be used as periodic function. If 0,\n",
      " |              return a symmetric window. When 'periodic' is specified, hann computes a\n",
      " |              window of length size + 1 and returns the first size points. The default\n",
      " |              value is 1.\n",
      " |  \n",
      " |  HannWindow(self, size: 'T1_HannWindow', *, output_datatype: 'int' = 1, periodic: 'int' = 1) -> 'T2_HannWindow'\n",
      " |      [üåê HannWindow(17)](https://onnx.ai/onnx/operators/onnx__HannWindow.html#hannwindow-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generates a Hann window as described in the paper https://ieeexplore.ieee.org/document/1455106.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          size: (non-differentiable) A scalar value indicating the length of the\n",
      " |              window.\n",
      " |      \n",
      " |          output_datatype: The data type of the output tensor. Strictly must be one of\n",
      " |              the values from DataType enum in TensorProto whose values correspond to\n",
      " |              T2. The default value is 1 = FLOAT.\n",
      " |      \n",
      " |          periodic: If 1, returns a window to be used as periodic function. If 0,\n",
      " |              return a symmetric window. When 'periodic' is specified, hann computes a\n",
      " |              window of length size + 1 and returns the first size points. The default\n",
      " |              value is 1.\n",
      " |  \n",
      " |  LayerNormalization(self, X: 'T_LayerNormalization', Scale: 'T_LayerNormalization', B: 'Optional[T_LayerNormalization]' = None, *, axis: 'int' = -1, epsilon: 'float' = 9.999999747378752e-06, stash_type: 'int' = 1) -> 'Tuple[T_LayerNormalization, U_LayerNormalization, U_LayerNormalization]'\n",
      " |      [üåê LayerNormalization(17)](https://onnx.ai/onnx/operators/onnx__LayerNormalization.html#layernormalization-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |            This is layer normalization defined in ONNX as function.\n",
      " |            The overall computation can be split into two stages.\n",
      " |            The first stage is standardization, which makes the\n",
      " |            normalized elements have zero mean and unit variances.\n",
      " |            The computation required by standardization can be\n",
      " |            described by the following equations.\n",
      " |            ```\n",
      " |            Mean = ReduceMean<axes=normalized_axes>(X)\n",
      " |            D = Sub(X, Mean)\n",
      " |            DD = Mul(D, D)\n",
      " |            Var = ReduceMean<axes=normalized_axes>(DD)\n",
      " |            VarEps = Add(Var, epsilon)\n",
      " |            StdDev = Sqrt(VarEps)\n",
      " |            InvStdDev = Reciprocal(StdDev)\n",
      " |            Normalized = Mul(D, InvStdDev)\n",
      " |            ```\n",
      " |            where `normalized_axes` is `[axis, ..., rank of X - 1]`.\n",
      " |            The variables `Var` and `StdDev` stand for variance and\n",
      " |            standard deviation, respectively. The second output is\n",
      " |            `Mean` and the last one is `InvStdDev`.\n",
      " |            Depending on `stash_type` attribute, the actual computation\n",
      " |            must happen in different floating-point precision.\n",
      " |            For example, if `stash_type` is 1, this operator casts\n",
      " |            all input variables to 32-bit float, perform the computation, and\n",
      " |            finally cast `Normalized` back to the original type of `X`.\n",
      " |            The second stage then scales and shifts the outcome of the\n",
      " |            first stage using\n",
      " |            ```\n",
      " |            NormalizedScaled = Mul(Normalized, Scale)\n",
      " |            Y = Add(NormalizedScaled, B)\n",
      " |            ```\n",
      " |            The second stage doesn't depends on `stash_type`.\n",
      " |            All equations are in [this syntax](https://github.com/onnx/onnx/blob/main/docs/Syntax.md).\n",
      " |            The same variable (i.e., input, output, and attribute) uses\n",
      " |            the same name in the equations above and this operator's definition.\n",
      " |            Let `d[i]` indicate the i-th dimension of `X`.\n",
      " |            If `X`'s shape is `[d[0], ..., d[axis-1], d[axis], ..., d[rank-1]]`,\n",
      " |            the shape of `Mean` and `InvStdDev` is `[d[0], ..., d[axis-1], 1, ..., 1]`.\n",
      " |            `Y` and `X` have the same shape.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: Tensor to be normalized.\n",
      " |      \n",
      " |          Scale: Scale tensor.\n",
      " |      \n",
      " |          B: (optional) Bias tensor.\n",
      " |      \n",
      " |          axis: The first normalization dimension. If rank(X) is r, axis' allowed\n",
      " |              range is [-r, r]. Negative value means counting dimensions from the\n",
      " |              back.\n",
      " |      \n",
      " |          epsilon: The epsilon value to use to avoid division by zero.\n",
      " |      \n",
      " |          stash_type: Type of Mean and InvStdDev. This also specifies stage one's\n",
      " |              computation precision.\n",
      " |  \n",
      " |  MelWeightMatrix(self, num_mel_bins: 'T1_MelWeightMatrix', dft_length: 'T1_MelWeightMatrix', sample_rate: 'T1_MelWeightMatrix', lower_edge_hertz: 'T2_MelWeightMatrix', upper_edge_hertz: 'T2_MelWeightMatrix', *, output_datatype: 'int' = 1) -> 'T3_MelWeightMatrix'\n",
      " |      [üåê MelWeightMatrix(17)](https://onnx.ai/onnx/operators/onnx__MelWeightMatrix.html#melweightmatrix-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a MelWeightMatrix that can be used to re-weight a Tensor containing a linearly sampled frequency spectra (from DFT or STFT) into num_mel_bins frequency information based on the [lower_edge_hertz, upper_edge_hertz] range on the mel scale.\n",
      " |      This function defines the mel scale in terms of a frequency in hertz according to the following formula:\n",
      " |      \n",
      " |          mel(f) = 2595 * log10(1 + f/700)\n",
      " |      \n",
      " |      In the returned matrix, all the triangles (filterbanks) have a peak value of 1.0.\n",
      " |      \n",
      " |      The returned MelWeightMatrix can be used to right-multiply a spectrogram S of shape [frames, num_spectrogram_bins] of linear scale spectrum values (e.g. STFT magnitudes) to generate a \"mel spectrogram\" M of shape [frames, num_mel_bins].\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          num_mel_bins: (non-differentiable) The number of bands in the mel spectrum.\n",
      " |      \n",
      " |          dft_length: (non-differentiable) The size of the original DFT. The size of\n",
      " |              the original DFT is used to infer the size of the onesided DFT, which is\n",
      " |              understood to be floor(dft_length/2) + 1, i.e. the spectrogram only\n",
      " |              contains the nonredundant DFT bins.\n",
      " |      \n",
      " |          sample_rate: (non-differentiable) Samples per second of the input signal\n",
      " |              used to create the spectrogram. Used to figure out the frequencies\n",
      " |              corresponding to each spectrogram bin, which dictates how they are\n",
      " |              mapped into the mel scale.\n",
      " |      \n",
      " |          lower_edge_hertz: (non-differentiable) Lower bound on the frequencies to be\n",
      " |              included in the mel spectrum. This corresponds to the lower edge of the\n",
      " |              lowest triangular band.\n",
      " |      \n",
      " |          upper_edge_hertz: (non-differentiable) The desired top edge of the highest\n",
      " |              frequency band.\n",
      " |      \n",
      " |          output_datatype: The data type of the output tensor. Strictly must be one of\n",
      " |              the values from DataType enum in TensorProto whose values correspond to\n",
      " |              T3. The default value is 1 = FLOAT.\n",
      " |  \n",
      " |  STFT(self, signal: 'T1_STFT', frame_step: 'T2_STFT', window: 'Optional[T1_STFT]' = None, frame_length: 'Optional[T2_STFT]' = None, *, onesided: 'int' = 1) -> 'T1_STFT'\n",
      " |      [üåê STFT(17)](https://onnx.ai/onnx/operators/onnx__STFT.html#stft-17 \"Online Documentation\")\n",
      " |      \n",
      " |      Computes the Short-time Fourier Transform of the signal.\n",
      " |      \n",
      " |      Args:\n",
      " |          signal: (non-differentiable) Input tensor representing a real or complex\n",
      " |              valued signal. For real input, the following shape is expected:\n",
      " |              [batch_size][signal_length][1]. For complex input, the following shape\n",
      " |              is expected: [batch_size][signal_length][2], where\n",
      " |              [batch_size][signal_length][0] represents the real component and\n",
      " |              [batch_size][signal_length][1] represents the imaginary component of the\n",
      " |              signal.\n",
      " |      \n",
      " |          frame_step: (non-differentiable) The number of samples to step between\n",
      " |              successive DFTs.\n",
      " |      \n",
      " |          window: (optional, non-differentiable) A tensor representing the window that\n",
      " |              will be slid over the signal.The window must have rank 1 with shape:\n",
      " |              [window_shape]. It's an optional value.\n",
      " |      \n",
      " |          frame_length: (optional, non-differentiable) A scalar representing the size\n",
      " |              of the DFT. It's an optional value.\n",
      " |      \n",
      " |          onesided: If onesided is 1, only values for w in [0, 1, 2, ...,\n",
      " |              floor(n_fft/2) + 1] are returned because the real-to-complex Fourier\n",
      " |              transform satisfies the conjugate symmetry, i.e., X[m, w] =\n",
      " |              X[m,w]=X[m,n_fft-w]*. Note if the input or window tensors are complex,\n",
      " |              then onesided output is not possible. Enabling onesided with real inputs\n",
      " |              performs a Real-valued fast Fourier transform (RFFT).When invoked with\n",
      " |              real or complex valued input, the default value is 1. Values can be 0 or\n",
      " |              1.\n",
      " |  \n",
      " |  SequenceMap(self, input_sequence: 'S_SequenceMap', *additional_inputs: 'V_SequenceMap', body: 'GraphProto') -> 'S_SequenceMap'\n",
      " |      [üåê SequenceMap(17)](https://onnx.ai/onnx/operators/onnx__SequenceMap.html#sequencemap-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Applies a sub-graph to each sample in the input sequence(s).\n",
      " |      \n",
      " |      Inputs can be either tensors or sequences, with the exception of the first input which must\n",
      " |      be a sequence. The length of the first input sequence will determine the number of samples in the\n",
      " |      outputs. Any other sequence inputs should have the same number of samples. The number of inputs\n",
      " |      and outputs, should match the one of the subgraph.\n",
      " |      \n",
      " |      For each i-th element in the output, a sample will be extracted from the input sequence(s) at\n",
      " |      the i-th position and the sub-graph will be applied to it.\n",
      " |      The outputs will contain the outputs of the sub-graph for each sample, in the same order as in\n",
      " |      the input.\n",
      " |      \n",
      " |      This operator assumes that processing each sample is independent and could executed in parallel\n",
      " |      or in any order. Users cannot expect any specific ordering in which each subgraph is computed.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |      \n",
      " |          additional_inputs: (variadic, heterogeneous) Additional inputs to the graph\n",
      " |      \n",
      " |          body: The graph to be run for each sample in the sequence(s). It should have\n",
      " |              as many inputs and outputs as inputs and outputs to the SequenceMap\n",
      " |              function.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset17.Opset17:\n",
      " |  \n",
      " |  S_SequenceMap = ~S_SequenceMap\n",
      " |  \n",
      " |  T1_BlackmanWindow = ~T1_BlackmanWindow\n",
      " |  \n",
      " |  T1_DFT = ~T1_DFT\n",
      " |  \n",
      " |  T1_HammingWindow = ~T1_HammingWindow\n",
      " |  \n",
      " |  T1_HannWindow = ~T1_HannWindow\n",
      " |  \n",
      " |  T1_MelWeightMatrix = ~T1_MelWeightMatrix\n",
      " |  \n",
      " |  T1_STFT = ~T1_STFT\n",
      " |  \n",
      " |  T2_BlackmanWindow = typing.Union[onnxscript.onnx_types.BFLOAT16, onn.....\n",
      " |  \n",
      " |  T2_DFT = ~T2_DFT\n",
      " |  \n",
      " |  T2_HammingWindow = typing.Union[onnxscript.onnx_types.BFLOAT16, onn......\n",
      " |  \n",
      " |  T2_HannWindow = typing.Union[onnxscript.onnx_types.BFLOAT16, onn...t.o...\n",
      " |  \n",
      " |  T2_MelWeightMatrix = ~T2_MelWeightMatrix\n",
      " |  \n",
      " |  T2_STFT = ~T2_STFT\n",
      " |  \n",
      " |  T3_MelWeightMatrix = typing.Union[onnxscript.onnx_types.BFLOAT16, onn....\n",
      " |  \n",
      " |  T_LayerNormalization = ~T_LayerNormalization\n",
      " |  \n",
      " |  U_LayerNormalization = typing.Union[onnxscript.onnx_types.BFLOAT16, on...\n",
      " |  \n",
      " |  V_SequenceMap = ~V_SequenceMap\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset16.Opset16:\n",
      " |  \n",
      " |  GreaterOrEqual(self, A: 'T_GreaterOrEqual', B: 'T_GreaterOrEqual') -> 'T1_GreaterOrEqual'\n",
      " |      [üåê GreaterOrEqual(16)](https://onnx.ai/onnx/operators/onnx__GreaterOrEqual.html#greaterorequal-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `greater_equal` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  GridSample(self, X: 'T1_GridSample', grid: 'T2_GridSample', *, align_corners: 'int' = 0, mode: 'str' = 'bilinear', padding_mode: 'str' = 'zeros') -> 'T1_GridSample'\n",
      " |      [üåê GridSample(16)](https://onnx.ai/onnx/operators/onnx__GridSample.html#gridsample-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given an input `X` and a flow-field `grid`, computes the output `Y` using `X` values and pixel locations from `grid`.\n",
      " |      Currently, only spatial (4-D) inputs are supported. For input `X` with shape (N, C, H, W) and `grid` with shape (N, H_out, W_out, 2),\n",
      " |      the output `Y` will have shape (N, C, H_out, W_out).\n",
      " |      \n",
      " |      The tensor `X` contains values at centers of square pixels in a H by W 2-dimensional image.\n",
      " |      The tensor `grid` describes normalized positions where the output `Y` is to be computed\n",
      " |      using a specified interpolation method (the mode) and a padding mode (for grid positions falling outside the 2-dimensional image).\n",
      " |      \n",
      " |      Elements in `grid[N, H_out, W_out]` are size-2 vectors specifying positions in the 2-dimensional space of `X`.\n",
      " |      They are used to interpolate output values of `Y[N, C, H_out, W_out]`.\n",
      " |      \n",
      " |      The GridSample operator is often used in doing grid generator and sampler in the [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025).\n",
      " |      See also in [torch.nn.functional.grid_sample](https://pytorch.org/docs/master/generated/torch.nn.functional.grid_sample.html#torch-nn-functional-grid-sample).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) 4-D tensor of shape (N, C, H, W), where N is the batch\n",
      " |              size, C is the numbers of channels, H and W are the height and width of\n",
      " |              the input data.\n",
      " |      \n",
      " |          grid: (non-differentiable) Input offset, 4-D tensor of shape (N, H_out,\n",
      " |              W_out, 2), where H_out and W_out are the height and width of grid and\n",
      " |              output, Grid specifies the sampling pixel locations normalized by the\n",
      " |              input spatial dimensions. Therefore, it should have most values in the\n",
      " |              range of [-1, 1]. If grid has values outside the range of [-1, 1], the\n",
      " |              corresponding outputs will be handled as defined by padding_mode.\n",
      " |      \n",
      " |          align_corners: If align_corners=1, the extrema (-1 and 1) are considered as\n",
      " |              referring to the center points of the input's corner pixels. If\n",
      " |              align_corners=0, they are instead considered as referring to the corner\n",
      " |              points of the input's corner pixels, making the sampling more resolution\n",
      " |              agnostic.\n",
      " |      \n",
      " |          mode: Three interpolation modes: bilinear (default), nearest and bicubic.\n",
      " |      \n",
      " |          padding_mode: Support padding modes for outside grid values:\n",
      " |              `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound\n",
      " |              grid locations, border: use border values for out-of-bound grid\n",
      " |              locations, reflection: use values at locations reflected by the border\n",
      " |              for out-of-bound grid locations. If index 0 represents the margin pixel,\n",
      " |              the reflected value at index -1 will be the same as the value at index\n",
      " |              1. For location far away from the border, it will keep being reflected\n",
      " |              until becoming in bound. If pixel location x = -3.5 reflects by border\n",
      " |              -1 and becomes x' = 1.5, then reflects by border 1 and becomes x'' =\n",
      " |              0.5.\n",
      " |  \n",
      " |  Identity(self, input: 'V_Identity') -> 'V_Identity'\n",
      " |      [üåê Identity(16)](https://onnx.ai/onnx/operators/onnx__Identity.html#identity-16 \"Online Documentation\")\n",
      " |      \n",
      " |      Identity operator\n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  If(self, cond: 'B_If', *, else_branch: 'GraphProto', then_branch: 'GraphProto') -> 'V_If'\n",
      " |      [üåê If(16)](https://onnx.ai/onnx/operators/onnx__If.html#if-16 \"Online Documentation\")\n",
      " |      \n",
      " |      If conditional\n",
      " |      \n",
      " |      Args:\n",
      " |          cond: Condition for the if\n",
      " |      \n",
      " |          else_branch: Graph to run if condition is false. Has N outputs: values you\n",
      " |              wish to be live-out to the enclosing scope. The number of outputs must\n",
      " |              match the number of outputs in the then_branch.\n",
      " |      \n",
      " |          then_branch: Graph to run if condition is true. Has N outputs: values you\n",
      " |              wish to be live-out to the enclosing scope. The number of outputs must\n",
      " |              match the number of outputs in the else_branch.\n",
      " |  \n",
      " |  LeakyRelu(self, X: 'T_LeakyRelu', *, alpha: 'float' = 0.009999999776482582) -> 'T_LeakyRelu'\n",
      " |      [üåê LeakyRelu(16)](https://onnx.ai/onnx/operators/onnx__LeakyRelu.html#leakyrelu-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      LeakyRelu takes input data (Tensor<T>) and an argument alpha, and produces one\n",
      " |      output data (Tensor<T>) where the function `f(x) = alpha * x for x < 0`,\n",
      " |      `f(x) = x for x >= 0`, is applied to the data tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: Coefficient of leakage.\n",
      " |  \n",
      " |  LessOrEqual(self, A: 'T_LessOrEqual', B: 'T_LessOrEqual') -> 'T1_LessOrEqual'\n",
      " |      [üåê LessOrEqual(16)](https://onnx.ai/onnx/operators/onnx__LessOrEqual.html#lessorequal-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `less_equal` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Loop(self, M: 'Optional[I_Loop]', cond: 'Optional[B_Loop]', *v_initial: 'V_Loop', body: 'GraphProto') -> 'V_Loop'\n",
      " |      [üåê Loop(16)](https://onnx.ai/onnx/operators/onnx__Loop.html#loop-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generic Looping construct. This loop has multiple termination conditions:\n",
      " |      \n",
      " |      1) Trip count. Iteration count specified at runtime. Set by\n",
      " |         specifying the input M. Optional. Set to empty string to omit.\n",
      " |         Note that a static trip count (specified at graph construction time) can be\n",
      " |         specified by passing in a constant node for input M.\n",
      " |      2) Loop termination condition. This is an input to the op that determines\n",
      " |         whether to run the first iteration and also a loop-carried dependency for\n",
      " |         the body graph. The body graph must yield a value for the condition variable,\n",
      " |         whether this input is provided or not.\n",
      " |      \n",
      " |      This table summarizes the operating modes of this operator with equivalent\n",
      " |      C-style code:\n",
      " |      \n",
      " |      Operator inputs defined as (max_trip_count, condition_var).\n",
      " |      \n",
      " |      * input (\"\", \"\"):\n",
      " |              for (int i=0; ; ++i) {\n",
      " |                cond = ... // Note this value is ignored, but is required in the body\n",
      " |              }\n",
      " |      \n",
      " |      * input (\"\", cond) // Note this is analogous to a while loop\n",
      " |              bool cond = ...;\n",
      " |              for (int i=0; cond; ++i) {\n",
      " |                cond = ...;\n",
      " |              }\n",
      " |      \n",
      " |      * input (\"\", 1) // Note this is analogous to a do-while loop\n",
      " |              bool cond = true\n",
      " |              for (int i=0; cond; ++i) {\n",
      " |                cond = ...;\n",
      " |              }\n",
      " |      \n",
      " |      * input (trip_count, \"\") // Note this is analogous to a for loop\n",
      " |              int trip_count = ...\n",
      " |              for (int i=0; i < trip_count; ++i) {\n",
      " |                cond = ...; // ignored\n",
      " |              }\n",
      " |      \n",
      " |      * input (trip_count, cond)\n",
      " |              int trip_count = ...;\n",
      " |              bool cond = ...;\n",
      " |              for (int i=0; i < trip_count && cond; ++i) {\n",
      " |                cond = ...;\n",
      " |              }\n",
      " |      \n",
      " |      \n",
      " |      *Sample usage - cond as well as trip count*\n",
      " |      \n",
      " |          graph predict-net {\n",
      " |            %a = Constant[value = <Scalar Tensor [3]>]()\n",
      " |            %b = Constant[value = <Scalar Tensor [6]>]()\n",
      " |            %keepgoing = Constant[value = <Scalar Tensor [1]>]()\n",
      " |            %max_trip_count = Constant[value = <Scalar Tensor [10]>]()\n",
      " |            %keepgoing_out, %b_out, %user_defined_vals = Loop[body = <graph body-net>](%max_trip_count, %keepgoing, %b)\n",
      " |            return\n",
      " |          }\n",
      " |      \n",
      " |          graph body-net (\n",
      " |            %i[INT32, scalar]           // iteration number\n",
      " |            %keepgoing_in[BOOL, scalar] // incoming loop-termination-condition; not used\n",
      " |            %b_in[INT32, scalar]        // incoming value of loop-carried-dependency b\n",
      " |          ) {\n",
      " |            %my_local = Add(%a, %b_in)\n",
      " |            %b_out = Sub(%a, %b_in) // outgoing value of loop-carried-dependency b\n",
      " |            %keepgoing_out = Greater(%my_local, %b_out) // outgoing loop-termination-condition\n",
      " |            %user_defined_val = Add(%b_in, %b_in) // scan-output value to be accumulated\n",
      " |            return %keepgoing_out, %b_out, %user_defined_val\n",
      " |          }\n",
      " |      \n",
      " |      *Sample equivalent C code*\n",
      " |      \n",
      " |          {\n",
      " |            /* User-defined code (enclosing scope) */\n",
      " |            int a = 3, b = 6;\n",
      " |            bool keepgoing = true; // Analogous to input cond\n",
      " |            /* End user-defined code */\n",
      " |      \n",
      " |            /* Implicitly-defined code */\n",
      " |            const int max_trip_count = 10; // Analogous to input M\n",
      " |            int user_defined_vals[]; // Imagine this is resizable\n",
      " |            /* End implicitly-defined code */\n",
      " |            /* initialize loop-carried variables and scan-output variables */\n",
      " |            bool keepgoing_out = keepgoing\n",
      " |            int b_out = b\n",
      " |      \n",
      " |            for (int i=0; i < max_trip_count && keepgoing_out; ++i) {\n",
      " |              /* Implicitly-defined code: bind actual parameter values\n",
      " |                 to formal parameter variables of loop-body */\n",
      " |              bool keepgoing_in = keepgoing_out;\n",
      " |              bool b_in = b_out;\n",
      " |      \n",
      " |              /* User-defined code (loop body) */\n",
      " |              int my_local = a + b_in; // Reading value \"a\" from the enclosing scope is fine\n",
      " |              b_out = a - b_in;\n",
      " |              keepgoing_out = my_local > b_out;\n",
      " |              user_defined_val = b_in + b_in; // b_in and b_out are different variables\n",
      " |              /* End user-defined code */\n",
      " |      \n",
      " |              /* Implicitly defined-code */\n",
      " |              user_defined_vals[i] = user_defined_val // accumulate scan-output values\n",
      " |            }\n",
      " |            // int t = my_local; // Can't do this. my_local is not accessible here.\n",
      " |      \n",
      " |            // The values below are bound to the output variables of the loop and therefore accessible\n",
      " |            // b_out; user_defined_vals; keepgoing_out;\n",
      " |          }\n",
      " |      \n",
      " |      There are several things of note in this code snippet:\n",
      " |      \n",
      " |      1) Values from the enclosing scope (i.e. variable \"a\" here) are in scope and can\n",
      " |         be referenced in the inputs of the loop.\n",
      " |      2) Any values computed in the loop body that needs to be used in a subsequent\n",
      " |         iteration or after the loop are modelled using a pair of variables in the loop-body,\n",
      " |         consisting of an input variable (eg., b_in) and an output variable (eg., b_out).\n",
      " |         These are referred to as loop-carried dependences. The loop operation node\n",
      " |         supplies the input value of the input variable for the first iteration, and\n",
      " |         returns the output value of the output variable produced by the final\n",
      " |         iteration.\n",
      " |      3) Scan_output variables are used to implicitly concatenate values computed across\n",
      " |         all the iterations. In the above example, the value of user_defined_val computed\n",
      " |         over all iterations are concatenated and returned as the value of user_defined_vals\n",
      " |         after the loop.\n",
      " |      4) Values created in the body cannot be accessed in the enclosing scope,\n",
      " |         except using the mechanism described above.\n",
      " |      \n",
      " |      Note that the semantics of this op support \"diagonal\" or \"wavefront\" execution.\n",
      " |      (See Step 3 here for an example:\n",
      " |      https://devblogs.nvidia.com/optimizing-recurrent-neural-networks-cudnn-5/).\n",
      " |      Frontends should emit multi-layer RNNs as a series of While operators (with\n",
      " |      time being the inner looping dimension), with each successive layer consuming\n",
      " |      the scan_outputs from the previous layer, possibly going through several\n",
      " |      point-wise operators (e.g. dropout, residual connections, linear layer).\n",
      " |      \n",
      " |      The input/output of subgraph (produced by loop node) matching is based on order instead of name. The implementation will figure out the names based on this order.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          M: (optional) A maximum trip-count for the loop specified at runtime.\n",
      " |              Optional. Pass empty string to skip.\n",
      " |      \n",
      " |          cond: (optional) A boolean termination condition. Optional. Pass empty\n",
      " |              string to skip.\n",
      " |      \n",
      " |          v_initial: (variadic, heterogeneous) The initial values of any loop-carried\n",
      " |              dependencies (values that change across loop iterations)\n",
      " |      \n",
      " |          body: The graph run each iteration. It has 2+N inputs: (iteration_num,\n",
      " |              condition, loop carried dependencies...). It has 1+N+K outputs:\n",
      " |              (condition, loop carried dependencies..., scan_outputs...). Each\n",
      " |              scan_output is created by concatenating the value of the specified\n",
      " |              output value at the end of each iteration of the loop. It is an error if\n",
      " |              the dimensions or data type of these scan_outputs change across loop\n",
      " |              iterations.\n",
      " |  \n",
      " |  PRelu(self, X: 'T_PRelu', slope: 'T_PRelu') -> 'T_PRelu'\n",
      " |      [üåê PRelu(16)](https://onnx.ai/onnx/operators/onnx__PRelu.html#prelu-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one\n",
      " |      output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,\n",
      " |      `f(x) = x for x >= 0`., is applied to the data tensor elementwise.\n",
      " |      This operator supports **unidirectional broadcasting** (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          slope: (differentiable) Slope tensor. The shape of slope can be smaller then\n",
      " |              first input X; if so, its shape must be unidirectional broadcastable to\n",
      " |              X\n",
      " |  \n",
      " |  RoiAlign(self, X: 'T1_RoiAlign', rois: 'T1_RoiAlign', batch_indices: 'T2_RoiAlign', *, coordinate_transformation_mode: 'str' = 'half_pixel', mode: 'str' = 'avg', output_height: 'int' = 1, output_width: 'int' = 1, sampling_ratio: 'int' = 0, spatial_scale: 'float' = 1.0) -> 'T1_RoiAlign'\n",
      " |      [üåê RoiAlign(16)](https://onnx.ai/onnx/operators/onnx__RoiAlign.html#roialign-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Region of Interest (RoI) align operation described in the\n",
      " |      [Mask R-CNN paper](https://arxiv.org/abs/1703.06870).\n",
      " |      RoiAlign consumes an input tensor X and region of interests (rois)\n",
      " |      to apply pooling across each RoI; it produces a 4-D tensor of shape\n",
      " |      (num_rois, C, output_height, output_width).\n",
      " |      \n",
      " |      RoiAlign is proposed to avoid the misalignment by removing\n",
      " |      quantizations while converting from original image into feature\n",
      " |      map and from feature map into RoI feature; in each ROI bin,\n",
      " |      the value of the sampled locations are computed directly\n",
      " |      through bilinear interpolation.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: Input data tensor from the previous operator; 4-D feature map of shape\n",
      " |              (N, C, H, W), where N is the batch size, C is the number of channels,\n",
      " |              and H and W are the height and the width of the data.\n",
      " |      \n",
      " |          rois: RoIs (Regions of Interest) to pool over; rois is 2-D input of shape\n",
      " |              (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates\n",
      " |              are in the coordinate system of the input image. Each coordinate set has\n",
      " |              a 1:1 correspondence with the 'batch_indices' input.\n",
      " |      \n",
      " |          batch_indices: 1-D tensor of shape (num_rois,) with each element denoting\n",
      " |              the index of the corresponding image in the batch.\n",
      " |      \n",
      " |          coordinate_transformation_mode: Allowed values are 'half_pixel' and\n",
      " |              'output_half_pixel'. Use the value 'half_pixel' to pixel shift the input\n",
      " |              coordinates by -0.5 (the recommended behavior). Use the value\n",
      " |              'output_half_pixel' to omit the pixel shift for the input (use this for\n",
      " |              a backward-compatible behavior).\n",
      " |      \n",
      " |          mode: The pooling method. Two modes are supported: 'avg' and 'max'. Default\n",
      " |              is 'avg'.\n",
      " |      \n",
      " |          output_height: default 1; Pooled output Y's height.\n",
      " |      \n",
      " |          output_width: default 1; Pooled output Y's width.\n",
      " |      \n",
      " |          sampling_ratio: Number of sampling points in the interpolation grid used to\n",
      " |              compute the output value of each pooled output bin. If > 0, then exactly\n",
      " |              sampling_ratio x sampling_ratio grid points are used. If == 0, then an\n",
      " |              adaptive number of grid points are used (computed as ceil(roi_width /\n",
      " |              output_width), and likewise for height). Default is 0.\n",
      " |      \n",
      " |          spatial_scale: Multiplicative spatial scale factor to translate ROI\n",
      " |              coordinates from their input spatial scale to the scale used when\n",
      " |              pooling, i.e., spatial scale of the input feature map X relative to the\n",
      " |              input image. E.g.; default is 1.0f.\n",
      " |  \n",
      " |  Scan(self, *initial_state_and_scan_inputs: 'V_Scan', body: 'GraphProto', num_scan_inputs: 'int', scan_input_axes: 'Optional[Sequence[int]]' = None, scan_input_directions: 'Optional[Sequence[int]]' = None, scan_output_axes: 'Optional[Sequence[int]]' = None, scan_output_directions: 'Optional[Sequence[int]]' = None) -> 'V_Scan'\n",
      " |      [üåê Scan(16)](https://onnx.ai/onnx/operators/onnx__Scan.html#scan-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Scan can be used to iterate over one or more scan_input tensors,\n",
      " |      constructing zero or more scan_output tensors. It combines ideas from general recurrences,\n",
      " |      functional programming constructs such as scan, fold, map, and zip, and is intended to enable\n",
      " |      generalizations of RNN-like constructs for sequence-to-sequence processing.\n",
      " |      Other tensors (referred to as state_variables here) can be used to carry a state\n",
      " |      when iterating from one element to another (similar to hidden-state in RNNs, also referred\n",
      " |      to as loop-carried dependences in the context of loops).\n",
      " |      Many common usages involve a single scan_input tensor (where functionality\n",
      " |      similar to scan, fold and map can be obtained). When more than one scan_input is used,\n",
      " |      a behavior similar to zip is obtained.\n",
      " |      \n",
      " |      The attribute body must be a graph, specifying the computation to be performed in\n",
      " |      every iteration. It takes as input the current values of the state_variables and\n",
      " |      the current iterated element of the scan_inputs. It must return the (updated) values\n",
      " |      of the state_variables and zero or more scan_output_element tensors. The values of the\n",
      " |      scan_output_element tensors are concatenated over all the iterations to produce the\n",
      " |      scan_output values of the scan construct (similar to the concatenated intermediate\n",
      " |      hidden-state values of RNN-like constructs). All the output tensors (state_variables as\n",
      " |      well as scan_output_element tensors) are required to have the same shape in each iteration\n",
      " |      of the loop (a restriction imposed to enable efficient memory allocation).\n",
      " |      \n",
      " |      Note that the iterated element passed to the body subgraph does not have a sequence\n",
      " |      axis. It will have a rank one less than the rank of the corresponding scan_input.\n",
      " |      \n",
      " |      The scan operation returns the final values of the state_variables as well as the\n",
      " |      scan_outputs.\n",
      " |      \n",
      " |      The optional attribute scan_input_directions specifies the direction (forward or backward)\n",
      " |      for each scan input. If this attribute is omitted, all sequences are scanned in the forward\n",
      " |      direction. A bidirectional scan may be performed by specifying the same tensor input twice\n",
      " |      in the scan_inputs, once with a forward direction, and once with a backward direction.\n",
      " |      \n",
      " |      The scan_output of the operation is produced by concatenating the scan_output_element\n",
      " |      values produced by the body in each iteration.  The optional attribute scan_output_directions\n",
      " |      specifies the direction in which scan_output is constructed (by appending or prepending the\n",
      " |      scan_output_element to scan_output in each iteration) for each scan_output. If this attribute\n",
      " |      is omitted, the scan_output_element is appended to the scan_output in each iteration.\n",
      " |      \n",
      " |      The optional attribute scan_input_axes specifies the axis to be scanned for each scan_input.\n",
      " |      If omitted, every scan_input will be scanned in axis 0. For example, if axis 0 is the\n",
      " |      batch axis and axis 1 is the time axis (to be scanned), specify an axis value of 1.\n",
      " |      Note that scanning a non-zero axis may be less efficient than scanning axis zero.\n",
      " |      \n",
      " |      The optional attribute scan_output_axes specifies the axis along which the scan_outputs\n",
      " |      are accumulated for each scan_output. For example, if axis 1 is the time axis (to be\n",
      " |      scanned) for both inputs and outputs, specify a scan_input axis and scan_output axis\n",
      " |      value of 1.\n",
      " |      \n",
      " |      Note that because of the ONNX restriction that only the last parameter of an operator can\n",
      " |      be variadic, the initial-states and scan-inputs are listed together as one input parameter.\n",
      " |      Similarly, the final-states and scan-outputs are listed together as one output parameter.\n",
      " |      The attribute num_scan_inputs indicates the number M of scan-inputs.\n",
      " |      \n",
      " |      The behavior of\n",
      " |      \n",
      " |          Scan <\n",
      " |              num_scan_inputs = m,\n",
      " |              body = loop-body,\n",
      " |              scan_input_axes = [axis_1, ..., axis_m]\n",
      " |          > (init_1, ..., init_n, scan_1, ..., scan_m)\n",
      " |      \n",
      " |      is equivalent to the following pseudo-code:\n",
      " |      \n",
      " |          // scan_i.shape[axis_i] denotes the (max) sequence-length of scan_i\n",
      " |          // scan_i.shape[axis_i] is required to be equal to scan_j.shape[axis_j] for all i,j.\n",
      " |          sequence_length = scan_1.shape[axis_1];\n",
      " |      \n",
      " |          // initialize state-variables\n",
      " |          st_1 = init_1; ... st_n = init_n;\n",
      " |          // initialize scan-output variables: [] denotes an empty tensor\n",
      " |          scan_out_1 = []; ...; scan_out_k = [];\n",
      " |          // identify number of iterations:\n",
      " |      \n",
      " |          // execute loop\n",
      " |          for (int t = 0; t < sequence_length; ++t) {\n",
      " |              // generate the scan-input elements: the notation T<axis=k>[t] indicates the sub-tensor\n",
      " |              // of rank one less than T obtained by indexing T at position t along axis k.\n",
      " |              si_1 = scan_1<axis=axis_1>[t];\n",
      " |              ... ;\n",
      " |              si_m = scan_m<axis=axis_m>[t];\n",
      " |              // execute loop-body\n",
      " |              st_1, ..., st_n, so_1, ..., so_k = loop-body(st_1, ..., st_n, si_1, ..., si_m)\n",
      " |              // accumulate the scan-output elements\n",
      " |              scan_out_1 = Concat<axis=0>(scan_out_1, so_1); ... ; scan_out_k = Concat<axis=0>(scan_out_k, so_k);\n",
      " |          }\n",
      " |      \n",
      " |          return st_1, ..., st_n, scan_out_1, ..., scan_out_k;\n",
      " |      \n",
      " |      *Sample usage: Encoding RNN using a Scan*\n",
      " |      \n",
      " |      The following example shows how a simple RNN over an input tensor %X, with weight tensor %Wi,\n",
      " |      recurrence weight tensor %Ri, bias tensors %Wbi and %Rbi, and initial hidden-state %H_0 can\n",
      " |      be encoded as a ScanLoop. Note that the loop-body is a nested graph, and it directly computes\n",
      " |      %Wi, %Ri, %Wbi, and %Rbi (typically constants or initializers in the body graph). If these\n",
      " |      values are computed in the outer graph, they need to be passed in as extra state_variables.\n",
      " |      \n",
      " |          graph rnn-encoding {\n",
      " |            %H_0 = ...\n",
      " |            %X = ...\n",
      " |            %Y_h, %Y = Scan[body = <graph rnn-cell-1>, num_scan_inputs=1](%H_0, %X)\n",
      " |            return %Y, %Y_h\n",
      " |          }\n",
      " |      \n",
      " |          graph rnn-cell-1 (\n",
      " |            %H_tminus1[FLOAT, tensor]\n",
      " |            %X_t[FLOAT, tensor]\n",
      " |          ) {\n",
      " |            %Wi = ...\n",
      " |            %Ri = ...\n",
      " |            %Wbi = ...\n",
      " |            %Rbi = ...\n",
      " |            %t1 = X_t * (Wi^T)\n",
      " |            %t2 = H_tminus1*(Ri^T)\n",
      " |            %t3 = Add(%t1, %t2)\n",
      " |            %t4 = Add(%t3, %Wbi)\n",
      " |            %t5 = Add(%t4, %Rbi)\n",
      " |            %Ht = Tanh(%t5)\n",
      " |            %Accumulate = Identity(%Ht)\n",
      " |            return %Ht, %Accumulate\n",
      " |          }\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          initial_state_and_scan_inputs: (variadic, heterogeneous) Initial values of\n",
      " |              the loop's N state variables followed by M scan_inputs\n",
      " |      \n",
      " |          body: The graph run each iteration. It has N+M inputs: (loop state\n",
      " |              variables..., scan_input_elts...). It has N+K outputs: (loop state\n",
      " |              variables..., scan_output_elts...). Each scan_output is created by\n",
      " |              concatenating the value of the specified scan_output_elt value at the\n",
      " |              end of each iteration of the loop. It is an error if the dimensions of\n",
      " |              these values change across loop iterations.\n",
      " |      \n",
      " |          num_scan_inputs: An attribute specifying the number of scan_inputs M.\n",
      " |      \n",
      " |          scan_input_axes: An optional list of M flags. The i-th element of the list\n",
      " |              specifies the axis to be scanned (the sequence axis) for the i-th\n",
      " |              scan_input. If omitted, 0 will be used as the scan axis for every\n",
      " |              scan_input. Negative value for an axis means counting dimensions from\n",
      " |              the back. Accepted range is [-r, r-1] where r = rank(input).\n",
      " |      \n",
      " |          scan_input_directions: An optional list of M flags. The i-th element of the\n",
      " |              list specifies the direction to be scanned for the i-th scan_input\n",
      " |              tensor: 0 indicates forward direction and 1 indicates reverse direction.\n",
      " |              If omitted, all scan_input tensors will be scanned in the forward\n",
      " |              direction.\n",
      " |      \n",
      " |          scan_output_axes: An optional list of K flags. The i-th element of the list\n",
      " |              specifies the axis for the i-th scan_output. The scan outputs are\n",
      " |              accumulated along the specified axis. If omitted, 0 will be used as the\n",
      " |              scan axis for every scan_output. Negative value for an axis means\n",
      " |              counting dimensions from the back. Accepted range is [-r, r-1].\n",
      " |      \n",
      " |          scan_output_directions: An optional list of K flags, one for each\n",
      " |              scan_output. The i-th element of the list specifies whether the i-th\n",
      " |              scan_output should be constructed by appending or prepending a new value\n",
      " |              in each iteration: 0 indicates appending and 1 indicates prepending. If\n",
      " |              omitted, all scan_output tensors will be produced by appending a value\n",
      " |              in each iteration.\n",
      " |  \n",
      " |  Where(self, condition: 'B_Where', X: 'T_Where', Y: 'T_Where') -> 'T_Where'\n",
      " |      [üåê Where(16)](https://onnx.ai/onnx/operators/onnx__Where.html#where-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Return elements, either from X or Y, depending on condition.\n",
      " |      Where behaves like\n",
      " |      [numpy.where](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html)\n",
      " |      with three parameters.\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          condition: (non-differentiable) When True (nonzero), yield X, otherwise\n",
      " |              yield Y\n",
      " |      \n",
      " |          X: (differentiable) values selected at indices where condition is True\n",
      " |      \n",
      " |          Y: (differentiable) values selected at indices where condition is False\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset16.Opset16:\n",
      " |  \n",
      " |  B_If = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  B_Loop = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  B_Where = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  I_Loop = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T1_GreaterOrEqual = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_GridSample = ~T1_GridSample\n",
      " |  \n",
      " |  T1_LessOrEqual = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_RoiAlign = ~T1_RoiAlign\n",
      " |  \n",
      " |  T2_GridSample = ~T2_GridSample\n",
      " |  \n",
      " |  T2_RoiAlign = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T_GreaterOrEqual = ~T_GreaterOrEqual\n",
      " |  \n",
      " |  T_LeakyRelu = ~T_LeakyRelu\n",
      " |  \n",
      " |  T_LessOrEqual = ~T_LessOrEqual\n",
      " |  \n",
      " |  T_PRelu = ~T_PRelu\n",
      " |  \n",
      " |  T_Where = ~T_Where\n",
      " |  \n",
      " |  V_Identity = ~V_Identity\n",
      " |  \n",
      " |  V_If = typing.Union[typing.Sequence[onnxscript.onnx_typ...t.onnx_types...\n",
      " |  \n",
      " |  V_Loop = ~V_Loop\n",
      " |  \n",
      " |  V_Scan = ~V_Scan\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset15.Opset15:\n",
      " |  \n",
      " |  BatchNormalization(self, X: 'T_BatchNormalization', scale: 'T1_BatchNormalization', B: 'T1_BatchNormalization', input_mean: 'T2_BatchNormalization', input_var: 'T2_BatchNormalization', *, epsilon: 'float' = 9.999999747378752e-06, momentum: 'float' = 0.8999999761581421, training_mode: 'int' = 0) -> 'Tuple[T_BatchNormalization, T2_BatchNormalization, T2_BatchNormalization]'\n",
      " |      [üåê BatchNormalization(15)](https://onnx.ai/onnx/operators/onnx__BatchNormalization.html#batchnormalization-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Carries out batch normalization as described in the paper\n",
      " |      https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\n",
      " |      There are five required inputs 'X', 'scale', 'B', 'input_mean' and\n",
      " |      'input_var'.\n",
      " |      Note that 'input_mean' and 'input_var' are expected to be the estimated\n",
      " |      statistics in inference mode (training_mode=False, default),\n",
      " |      and the running statistics in training mode (training_mode=True).\n",
      " |      There are multiple cases for the number of outputs, which we list below:\n",
      " |      \n",
      " |      * Output case #1: Y, running_mean, running_var (training_mode=True)\n",
      " |      * Output case #2: Y (training_mode=False)\n",
      " |      \n",
      " |      When training_mode=False, extra outputs are invalid.\n",
      " |      The outputs are updated as follows when training_mode=True:\n",
      " |      ::\n",
      " |      \n",
      " |          running_mean = input_mean * momentum + current_mean * (1 - momentum)\n",
      " |          running_var = input_var * momentum + current_var * (1 - momentum)\n",
      " |      \n",
      " |          Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B\n",
      " |      \n",
      " |      \n",
      " |      where:\n",
      " |      ::\n",
      " |      \n",
      " |          current_mean = ReduceMean(X, axis=all_except_channel_index)\n",
      " |          current_var =  ReduceVar(X, axis=all_except_channel_index)\n",
      " |      \n",
      " |      \n",
      " |      Notice that `ReduceVar` refers to the population variance, and it equals to\n",
      " |      `sum(sqrd(x_i - x_avg)) / N`\n",
      " |      where `N` is the population size (this formula does not use sample size `N - 1`).\n",
      " |      \n",
      " |      The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.\n",
      " |      \n",
      " |      When training_mode=False:\n",
      " |      ::\n",
      " |      \n",
      " |          Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      For previous (depreciated) non-spatial cases, implementors are suggested\n",
      " |      to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size,\n",
      " |              C is the number of channels. Statistics are computed for every channel\n",
      " |              of C over N and D1 to Dn dimensions. For image data, input dimensions\n",
      " |              become (N x C x H x W). The op also accepts single dimension input of\n",
      " |              size N in which case C is assumed to be 1\n",
      " |      \n",
      " |          scale: (differentiable) Scale tensor of shape (C).\n",
      " |      \n",
      " |          B: (differentiable) Bias tensor of shape (C).\n",
      " |      \n",
      " |          input_mean: (differentiable) running (training) or estimated (testing) mean\n",
      " |              tensor of shape (C).\n",
      " |      \n",
      " |          input_var: (differentiable) running (training) or estimated (testing)\n",
      " |              variance tensor of shape (C).\n",
      " |      \n",
      " |          epsilon: The epsilon value to use to avoid division by zero.\n",
      " |      \n",
      " |          momentum: Factor used in computing the running mean and variance.e.g.,\n",
      " |              running_mean = running_mean * momentum + mean * (1 - momentum).\n",
      " |      \n",
      " |          training_mode: If set to true, it indicates BatchNormalization is being used\n",
      " |              for training, and outputs 1, 2, 3, and 4 would be populated.\n",
      " |  \n",
      " |  Bernoulli(self, input: 'T1_Bernoulli', *, dtype: '_Optional[int]' = None, seed: '_Optional[float]' = None) -> 'T2_Bernoulli'\n",
      " |      [üåê Bernoulli(15)](https://onnx.ai/onnx/operators/onnx__Bernoulli.html#bernoulli-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Draws binary random numbers (0 or 1) from a Bernoulli distribution. The input tensor should be a tensor\n",
      " |      containing probabilities p (a value in the range [0,1]) to be used for drawing the binary random number,\n",
      " |      where an output of 1 is produced with probability p and an output of 0 is produced with probability (1-p).\n",
      " |      \n",
      " |      This operator is non-deterministic and may not produce the same values in different\n",
      " |      implementations (even if a seed is specified).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: All values in input have to be in the range:[0, 1].\n",
      " |      \n",
      " |          dtype: The data type for the elements of the output tensor. if not\n",
      " |              specified, we will use the data type of the input tensor.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  CastLike(self, input: 'T1_CastLike', target_type: 'T2_CastLike') -> 'T2_CastLike'\n",
      " |      [üåê CastLike(15)](https://onnx.ai/onnx/operators/onnx__CastLike.html#castlike-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator casts the elements of a given input tensor (the first input) to\n",
      " |      the same data type as the elements of the second input tensor.\n",
      " |      See documentation of the Cast operator for further details.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor to be cast.\n",
      " |      \n",
      " |          target_type: (non-differentiable) The (first) input tensor will be cast to\n",
      " |              produce a tensor of the same type as this (second input) tensor.\n",
      " |  \n",
      " |  Optional(self, input: '_Optional[V_Optional]' = None, *, type: '_Optional[TypeProto]' = None) -> 'O_Optional'\n",
      " |      [üåê Optional(15)](https://onnx.ai/onnx/operators/onnx__Optional.html#optional-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Constructs an optional-type value containing either an empty optional of a certain type specified by the attribute,\n",
      " |      or a non-empty value containing the input element.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (optional) The input element.\n",
      " |      \n",
      " |          type: Type of the element in the optional output\n",
      " |  \n",
      " |  Pow(self, X: 'T_Pow', Y: 'T1_Pow') -> 'T_Pow'\n",
      " |      [üåê Pow(15)](https://onnx.ai/onnx/operators/onnx__Pow.html#pow-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Pow takes input data (Tensor<T>) and exponent Tensor, and\n",
      " |      produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,\n",
      " |      is applied to the data tensor elementwise.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) First operand, base of the exponent.\n",
      " |      \n",
      " |          Y: (differentiable) Second operand, power of the exponent.\n",
      " |  \n",
      " |  Shape(self, data: 'T_Shape', *, end: '_Optional[int]' = None, start: 'int' = 0) -> 'T1_Shape'\n",
      " |      [üåê Shape(15)](https://onnx.ai/onnx/operators/onnx__Shape.html#shape-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Takes a tensor as input and outputs an 1D int64 tensor containing the shape of the input tensor.\n",
      " |      Optional attributes start and end can be used to compute a slice of the input tensor's shape.\n",
      " |      If start axis is omitted, the slice starts from axis 0.\n",
      " |      The end axis, if specified, is exclusive (and the returned value will not include the size of that axis).\n",
      " |      If the end axis is omitted, the axes upto the last one will be included.\n",
      " |      Negative axes indicate counting back from the last axis.\n",
      " |      Note that axes will be clamped to the range [0, r-1], where r is the\n",
      " |      rank of the input tensor if they are out-of-range (after adding r in the case of\n",
      " |      negative axis). Thus, specifying any end value > r is equivalent to specifying an end\n",
      " |      value of r, and specifying any start value < -r is equivalent to specifying a start\n",
      " |      value of 0.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Input tensor with shape: [2, 3, 4]\n",
      " |          No attributes specified.\n",
      " |          Output: [2, 3, 4]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Input tensor with shape: [2, 3, 4]\n",
      " |          start: -1\n",
      " |          Output: [4]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Input tensor with shape: [2, 3, 4]\n",
      " |          end: -1\n",
      " |          Output: [2, 3]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Input tensor with shape: [2, 3, 4]\n",
      " |          start: 1\n",
      " |          end: 2\n",
      " |          Output: [3]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (non-differentiable) An input tensor.\n",
      " |      \n",
      " |          end: (Optional) Ending axis for slicing the shape. Negative value means\n",
      " |              counting dimensions from the back. If omitted, sizes of all axes upto\n",
      " |              (including) the last one will be included.\n",
      " |      \n",
      " |          start: (Optional) Starting axis for slicing the shape. Default value is\n",
      " |              0.Negative value means counting dimensions from the back.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset15.Opset15:\n",
      " |  \n",
      " |  O_Optional = typing.Union[typing.Sequence[onnxscript.onnx_typ...t.onnx...\n",
      " |  \n",
      " |  T1_BatchNormalization = ~T1_BatchNormalization\n",
      " |  \n",
      " |  T1_Bernoulli = ~T1_Bernoulli\n",
      " |  \n",
      " |  T1_CastLike = ~T1_CastLike\n",
      " |  \n",
      " |  T1_Pow = ~T1_Pow\n",
      " |  \n",
      " |  T1_Shape = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T2_BatchNormalization = ~T2_BatchNormalization\n",
      " |  \n",
      " |  T2_Bernoulli = typing.Union[onnxscript.onnx_types.BFLOAT16, onn...t.on...\n",
      " |  \n",
      " |  T2_CastLike = ~T2_CastLike\n",
      " |  \n",
      " |  T_BatchNormalization = ~T_BatchNormalization\n",
      " |  \n",
      " |  T_Pow = ~T_Pow\n",
      " |  \n",
      " |  T_Shape = ~T_Shape\n",
      " |  \n",
      " |  V_Optional = ~V_Optional\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset14.Opset14:\n",
      " |  \n",
      " |  Add(self, A: 'T_Add', B: 'T_Add') -> 'T_Add'\n",
      " |      [üåê Add(14)](https://onnx.ai/onnx/operators/onnx__Add.html#add-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs element-wise binary addition (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      (Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) First operand.\n",
      " |      \n",
      " |          B: (differentiable) Second operand.\n",
      " |  \n",
      " |  CumSum(self, x: 'T_CumSum', axis: 'T2_CumSum', *, exclusive: 'int' = 0, reverse: 'int' = 0) -> 'T_CumSum'\n",
      " |      [üåê CumSum(14)](https://onnx.ai/onnx/operators/onnx__CumSum.html#cumsum-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs cumulative sum of the input elements along the given axis.\n",
      " |      By default, it will do the sum inclusively meaning the first element is copied as is.\n",
      " |      Through an `exclusive` attribute, this behavior can change to exclude the first element.\n",
      " |      It can also perform summation in the opposite direction of the axis. For that, set `reverse` attribute to 1.\n",
      " |      \n",
      " |      Example:\n",
      " |      ::\n",
      " |      \n",
      " |          input_x = [1, 2, 3]\n",
      " |          axis=0\n",
      " |          output = [1, 3, 6]\n",
      " |          exclusive=1\n",
      " |          output = [0, 1, 3]\n",
      " |          exclusive=0\n",
      " |          reverse=1\n",
      " |          output = [6, 5, 3]\n",
      " |          exclusive=1\n",
      " |          reverse=1\n",
      " |          output = [5, 3, 0]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: (differentiable) An input tensor that is to be processed.\n",
      " |      \n",
      " |          axis: (non-differentiable) A 0-D tensor. Must be in the range [-rank(x),\n",
      " |              rank(x)-1]. Negative value means counting dimensions from the back.\n",
      " |      \n",
      " |          exclusive: If set to 1 will return exclusive sum in which the top element is\n",
      " |              not included. In other terms, if set to 1, the j-th output element would\n",
      " |              be the sum of the first (j-1) elements. Otherwise, it would be the sum\n",
      " |              of the first j elements.\n",
      " |      \n",
      " |          reverse: If set to 1 will perform the sums in reverse direction.\n",
      " |  \n",
      " |  Div(self, A: 'T_Div', B: 'T_Div') -> 'T_Div'\n",
      " |      [üåê Div(14)](https://onnx.ai/onnx/operators/onnx__Div.html#div-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs element-wise binary division (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      (Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) First operand.\n",
      " |      \n",
      " |          B: (differentiable) Second operand.\n",
      " |  \n",
      " |  GRU(self, X: 'T_GRU', W: 'T_GRU', R: 'T_GRU', B: 'Optional[T_GRU]' = None, sequence_lens: 'Optional[T1_GRU]' = None, initial_h: 'Optional[T_GRU]' = None, *, activation_alpha: 'Optional[Sequence[float]]' = None, activation_beta: 'Optional[Sequence[float]]' = None, activations: 'Optional[Sequence[str]]' = None, clip: 'Optional[float]' = None, direction: 'str' = 'forward', hidden_size: 'Optional[int]' = None, layout: 'int' = 0, linear_before_reset: 'int' = 0) -> 'Tuple[T_GRU, T_GRU]'\n",
      " |      [üåê GRU(14)](https://onnx.ai/onnx/operators/onnx__GRU.html#gru-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes an one-layer GRU. This operator is usually supported via some custom\n",
      " |      implementation such as CuDNN.\n",
      " |      \n",
      " |      Notations:\n",
      " |      \n",
      " |      * `X` - input tensor\n",
      " |      * `z` - update gate\n",
      " |      * `r` - reset gate\n",
      " |      * `h` - hidden gate\n",
      " |      * `t` - time step (t-1 means previous time step)\n",
      " |      * `W[zrh]` - W parameter weight matrix for update, reset, and hidden gates\n",
      " |      * `R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates\n",
      " |      * `Wb[zrh]` - W bias vectors for update, reset, and hidden gates\n",
      " |      * `Rb[zrh]` - R bias vectors for update, reset, and hidden gates\n",
      " |      * `WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates\n",
      " |      * `RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates\n",
      " |      * `WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates\n",
      " |      * `RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates\n",
      " |      * `H` - Hidden state\n",
      " |      * `num_directions` - 2 if direction == bidirectional else 1\n",
      " |      \n",
      " |      Activation functions:\n",
      " |      \n",
      " |      * Relu(x)                - max(0, x)\n",
      " |      * Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})\n",
      " |      * Sigmoid(x)             - 1/(1 + e^{-x})\n",
      " |      \n",
      " |      NOTE:\n",
      " |        Below are optional\n",
      " |      \n",
      " |      * Affine(x)              - alpha * x + beta\n",
      " |      * LeakyRelu(x)           - x if x >= 0 else alpha * x\n",
      " |      * ThresholdedRelu(x)     - x if x >= alpha else 0\n",
      " |      * ScaledTanh(x)          - alpha * Tanh(beta * x)\n",
      " |      * HardSigmoid(x)         - min(max(alpha * x + beta, 0), 1)\n",
      " |      * Elu(x)                 - x if x >= 0 else alpha * (e^x - 1)\n",
      " |      * Softsign(x)            - x/(1 + |x|)\n",
      " |      * Softplus(x)            - log(1 + e^x)\n",
      " |      \n",
      " |      Equations (Default: f=Sigmoid, g=Tanh):\n",
      " |      \n",
      " |      * zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)\n",
      " |      * rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)\n",
      " |      * ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0\n",
      " |      * ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0\n",
      " |      * Ht = (1 - zt) (.) ht + zt (.) Ht-1\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) The input sequences packed (and potentially padded) into\n",
      " |              one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor for the gates. Concatenation of\n",
      " |              `W[zrh]` and `WB[zrh]` (if bidirectional) along dimension 0. This tensor\n",
      " |              has shape `[num_directions, 3*hidden_size, input_size]`.\n",
      " |      \n",
      " |          R: (differentiable) The recurrence weight tensor. Concatenation of `R[zrh]`\n",
      " |              and `RB[zrh]` (if bidirectional) along dimension 0. This tensor has\n",
      " |              shape `[num_directions, 3*hidden_size, hidden_size]`.\n",
      " |      \n",
      " |          B: (optional, differentiable) The bias tensor for the gates. Concatenation\n",
      " |              of `[Wb[zrh], Rb[zrh]]` and `[WBb[zrh], RBb[zrh]]` (if bidirectional)\n",
      " |              along dimension 0. This tensor has shape `[num_directions,\n",
      " |              6*hidden_size]`. Optional: If not specified - assumed to be 0\n",
      " |      \n",
      " |          sequence_lens: (optional, non-differentiable) Optional tensor specifying\n",
      " |              lengths of the sequences in a batch. If not specified - assumed all\n",
      " |              sequences in the batch to have length `seq_length`. It has shape\n",
      " |              `[batch_size]`.\n",
      " |      \n",
      " |          initial_h: (optional, non-differentiable) Optional initial value of the\n",
      " |              hidden. If not specified - assumed to be 0. It has shape\n",
      " |              `[num_directions, batch_size, hidden_size]`.\n",
      " |      \n",
      " |          activation_alpha: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.For example with LeakyRelu, the default\n",
      " |              alpha is 0.01.\n",
      " |      \n",
      " |          activation_beta: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.\n",
      " |      \n",
      " |          activations: A list of 2 (or 4 if bidirectional) activation functions for\n",
      " |              update, reset, and hidden gates. The activation functions must be one of\n",
      " |              the activation functions specified above. Optional: See the equations\n",
      " |              for default if not specified.\n",
      " |      \n",
      " |          clip: Cell clip threshold. Clipping bounds the elements of a tensor in the\n",
      " |              range of [-threshold, +threshold] and is applied to the input of\n",
      " |              activations. No clip if not specified.\n",
      " |      \n",
      " |          direction: Specify if the RNN is forward, reverse, or bidirectional. Must be\n",
      " |              one of forward (default), reverse, or bidirectional.\n",
      " |      \n",
      " |          hidden_size: Number of neurons in the hidden layer\n",
      " |      \n",
      " |          layout: The shape format of inputs X, initial_h and outputs Y, Y_h. If 0,\n",
      " |              the following shapes are expected: X.shape = [seq_length, batch_size,\n",
      " |              input_size], Y.shape = [seq_length, num_directions, batch_size,\n",
      " |              hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size,\n",
      " |              hidden_size]. If 1, the following shapes are expected: X.shape =\n",
      " |              [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length,\n",
      " |              num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size,\n",
      " |              num_directions, hidden_size].\n",
      " |      \n",
      " |          linear_before_reset: When computing the output of the hidden gate, apply the\n",
      " |              linear transformation before multiplying by the output of the reset\n",
      " |              gate.\n",
      " |  \n",
      " |  HardSwish(self, X: 'T_HardSwish') -> 'T_HardSwish'\n",
      " |      [üåê HardSwish(14)](https://onnx.ai/onnx/operators/onnx__HardSwish.html#hardswish-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      HardSwish takes one input data (Tensor<T>) and produces one output data (Tensor<T>) where\n",
      " |      the HardSwish function, y = x * max(0, min(1, alpha * x + beta)) = x * HardSigmoid<alpha, beta>(x),\n",
      " |      where alpha = 1/6 and beta = 0.5, is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  LSTM(self, X: 'T_LSTM', W: 'T_LSTM', R: 'T_LSTM', B: 'Optional[T_LSTM]' = None, sequence_lens: 'Optional[T1_LSTM]' = None, initial_h: 'Optional[T_LSTM]' = None, initial_c: 'Optional[T_LSTM]' = None, P: 'Optional[T_LSTM]' = None, *, activation_alpha: 'Optional[Sequence[float]]' = None, activation_beta: 'Optional[Sequence[float]]' = None, activations: 'Optional[Sequence[str]]' = None, clip: 'Optional[float]' = None, direction: 'str' = 'forward', hidden_size: 'Optional[int]' = None, input_forget: 'int' = 0, layout: 'int' = 0) -> 'Tuple[T_LSTM, T_LSTM, T_LSTM]'\n",
      " |      [üåê LSTM(14)](https://onnx.ai/onnx/operators/onnx__LSTM.html#lstm-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes an one-layer LSTM. This operator is usually supported via some\n",
      " |      custom implementation such as CuDNN.\n",
      " |      \n",
      " |      Notations:\n",
      " |      \n",
      " |      * `X` - input tensor\n",
      " |      * `i` - input gate\n",
      " |      * `o` - output gate\n",
      " |      * `f` - forget gate\n",
      " |      * `c` - cell gate\n",
      " |      * `t` - time step (t-1 means previous time step)\n",
      " |      * `W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates\n",
      " |      * `R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates\n",
      " |      * `Wb[iofc]` - W bias vectors for input, output, forget, and cell gates\n",
      " |      * `Rb[iofc]` - R bias vectors for input, output, forget, and cell gates\n",
      " |      * `P[iof]`  - P peephole weight vector for input, output, and forget gates\n",
      " |      * `WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates\n",
      " |      * `RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates\n",
      " |      * `WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates\n",
      " |      * `RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates\n",
      " |      * `PB[iof]`  - P peephole weight vector for backward input, output, and forget gates\n",
      " |      * `H` - Hidden state\n",
      " |      * `num_directions` - 2 if direction == bidirectional else 1\n",
      " |      \n",
      " |      Activation functions:\n",
      " |      \n",
      " |      * Relu(x)                - max(0, x)\n",
      " |      * Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})\n",
      " |      * Sigmoid(x)             - 1/(1 + e^{-x})\n",
      " |      \n",
      " |      NOTE: Below are optional\n",
      " |      \n",
      " |      * Affine(x)              - alpha*x + beta\n",
      " |      * LeakyRelu(x)           - x if x >= 0 else alpha * x\n",
      " |      * ThresholdedRelu(x)     - x if x >= alpha else 0\n",
      " |      * ScaledTanh(x)          - alpha*Tanh(beta*x)\n",
      " |      * HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)\n",
      " |      * Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)\n",
      " |      * Softsign(x)            - x/(1 + |x|)\n",
      " |      * Softplus(x)            - log(1 + e^x)\n",
      " |      \n",
      " |      Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):\n",
      " |      \n",
      " |      * it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)\n",
      " |      * ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)\n",
      " |      * ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)\n",
      " |      * Ct = ft (.) Ct-1 + it (.) ct\n",
      " |      * ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)\n",
      " |      * Ht = ot (.) h(Ct)\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) The input sequences packed (and potentially padded) into\n",
      " |              one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor for the gates. Concatenation of\n",
      " |              `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The\n",
      " |              tensor has shape `[num_directions, 4*hidden_size, input_size]`.\n",
      " |      \n",
      " |          R: (differentiable) The recurrence weight tensor. Concatenation of `R[iofc]`\n",
      " |              and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has\n",
      " |              shape `[num_directions, 4*hidden_size, hidden_size]`.\n",
      " |      \n",
      " |          B: (optional, differentiable) The bias tensor for input gate. Concatenation\n",
      " |              of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if\n",
      " |              bidirectional) along dimension 0. This tensor has shape\n",
      " |              `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed\n",
      " |              to be 0.\n",
      " |      \n",
      " |          sequence_lens: (optional, non-differentiable) Optional tensor specifying\n",
      " |              lengths of the sequences in a batch. If not specified - assumed all\n",
      " |              sequences in the batch to have length `seq_length`. It has shape\n",
      " |              `[batch_size]`.\n",
      " |      \n",
      " |          initial_h: (optional, non-differentiable) Optional initial value of the\n",
      " |              hidden. If not specified - assumed to be 0. It has shape\n",
      " |              `[num_directions, batch_size, hidden_size]`.\n",
      " |      \n",
      " |          initial_c: (optional, non-differentiable) Optional initial value of the\n",
      " |              cell. If not specified - assumed to be 0. It has shape `[num_directions,\n",
      " |              batch_size, hidden_size]`.\n",
      " |      \n",
      " |          P: (optional, differentiable) The weight tensor for peepholes. Concatenation\n",
      " |              of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has\n",
      " |              shape `[num_directions, 3*hidde_size]`. Optional: If not specified -\n",
      " |              assumed to be 0.\n",
      " |      \n",
      " |          activation_alpha: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.For example with LeakyRelu, the default\n",
      " |              alpha is 0.01.\n",
      " |      \n",
      " |          activation_beta: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.\n",
      " |      \n",
      " |          activations: A list of 3 (or 6 if bidirectional) activation functions for\n",
      " |              input, output, forget, cell, and hidden. The activation functions must\n",
      " |              be one of the activation functions specified above. Optional: See the\n",
      " |              equations for default if not specified.\n",
      " |      \n",
      " |          clip: Cell clip threshold. Clipping bounds the elements of a tensor in the\n",
      " |              range of [-threshold, +threshold] and is applied to the input of\n",
      " |              activations. No clip if not specified.\n",
      " |      \n",
      " |          direction: Specify if the RNN is forward, reverse, or bidirectional. Must be\n",
      " |              one of forward (default), reverse, or bidirectional.\n",
      " |      \n",
      " |          hidden_size: Number of neurons in the hidden layer\n",
      " |      \n",
      " |          input_forget: Couple the input and forget gates if 1.\n",
      " |      \n",
      " |          layout: The shape format of inputs X, initial_h, initial_c and outputs Y,\n",
      " |              Y_h, Y_c. If 0, the following shapes are expected: X.shape =\n",
      " |              [seq_length, batch_size, input_size], Y.shape = [seq_length,\n",
      " |              num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape =\n",
      " |              initial_c.shape = Y_c.shape = [num_directions, batch_size, hidden_size].\n",
      " |              If 1, the following shapes are expected: X.shape = [batch_size,\n",
      " |              seq_length, input_size], Y.shape = [batch_size, seq_length,\n",
      " |              num_directions, hidden_size], initial_h.shape = Y_h.shape =\n",
      " |              initial_c.shape = Y_c.shape = [batch_size, num_directions, hidden_size].\n",
      " |  \n",
      " |  Mul(self, A: 'T_Mul', B: 'T_Mul') -> 'T_Mul'\n",
      " |      [üåê Mul(14)](https://onnx.ai/onnx/operators/onnx__Mul.html#mul-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      (Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) First operand.\n",
      " |      \n",
      " |          B: (differentiable) Second operand.\n",
      " |  \n",
      " |  RNN(self, X: 'T_RNN', W: 'T_RNN', R: 'T_RNN', B: 'Optional[T_RNN]' = None, sequence_lens: 'Optional[T1_RNN]' = None, initial_h: 'Optional[T_RNN]' = None, *, activation_alpha: 'Optional[Sequence[float]]' = None, activation_beta: 'Optional[Sequence[float]]' = None, activations: 'Sequence[str]' = ('Tanh', 'Tanh'), clip: 'Optional[float]' = None, direction: 'str' = 'forward', hidden_size: 'Optional[int]' = None, layout: 'int' = 0) -> 'Tuple[T_RNN, T_RNN]'\n",
      " |      [üåê RNN(14)](https://onnx.ai/onnx/operators/onnx__RNN.html#rnn-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes an one-layer simple RNN. This operator is usually supported\n",
      " |      via some custom implementation such as CuDNN.\n",
      " |      \n",
      " |      Notations:\n",
      " |      \n",
      " |      * `X` - input tensor\n",
      " |      * `i` - input gate\n",
      " |      * `t` - time step (t-1 means previous time step)\n",
      " |      * `Wi` - W parameter weight matrix for input gate\n",
      " |      * `Ri` - R recurrence weight matrix for input gate\n",
      " |      * `Wbi` - W parameter bias vector for input gate\n",
      " |      * `Rbi` - R parameter bias vector for input gate\n",
      " |      * `WBi` - W parameter weight matrix for backward input gate\n",
      " |      * `RBi` - R recurrence weight matrix for backward input gate\n",
      " |      * `WBbi` - WR bias vectors for backward input gate\n",
      " |      * `RBbi` - RR bias vectors for backward input gate\n",
      " |      * `H` - Hidden state\n",
      " |      * `num_directions` - 2 if direction == bidirectional else 1\n",
      " |      \n",
      " |      Activation functions:\n",
      " |      \n",
      " |      * Relu(x)                - max(0, x)\n",
      " |      * Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})\n",
      " |      * Sigmoid(x)             - 1/(1 + e^{-x})\n",
      " |      \n",
      " |      NOTE: Below are optional\n",
      " |      \n",
      " |      * Affine(x)              - alpha*x + beta\n",
      " |      * LeakyRelu(x)           - x if x >= 0 else alpha * x\n",
      " |      * ThresholdedRelu(x)     - x if x >= alpha else 0\n",
      " |      * ScaledTanh(x)          - alpha*Tanh(beta*x)\n",
      " |      * HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)\n",
      " |      * Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)\n",
      " |      * Softsign(x)            - x/(1 + |x|)\n",
      " |      * Softplus(x)            - log(1 + e^x)\n",
      " |      \n",
      " |      Equations (Default: f=Tanh):\n",
      " |      \n",
      " |      * Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) The input sequences packed (and potentially padded) into\n",
      " |              one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor for input gate. Concatenation of `Wi`\n",
      " |              and `WBi` (if bidirectional). The tensor has shape `[num_directions,\n",
      " |              hidden_size, input_size]`.\n",
      " |      \n",
      " |          R: (differentiable) The recurrence weight tensor. Concatenation of `Ri` and\n",
      " |              `RBi` (if bidirectional). The tensor has shape `[num_directions,\n",
      " |              hidden_size, hidden_size]`.\n",
      " |      \n",
      " |          B: (optional, differentiable) The bias tensor for input gate. Concatenation\n",
      " |              of `[Wbi, Rbi]` and `[WBbi, RBbi]` (if bidirectional). The tensor has\n",
      " |              shape `[num_directions, 2*hidden_size]`. Optional: If not specified -\n",
      " |              assumed to be 0.\n",
      " |      \n",
      " |          sequence_lens: (optional, non-differentiable) Optional tensor specifying\n",
      " |              lengths of the sequences in a batch. If not specified - assumed all\n",
      " |              sequences in the batch to have length `seq_length`. It has shape\n",
      " |              `[batch_size]`.\n",
      " |      \n",
      " |          initial_h: (optional, non-differentiable) Optional initial value of the\n",
      " |              hidden. If not specified - assumed to be 0. It has shape\n",
      " |              `[num_directions, batch_size, hidden_size]`.\n",
      " |      \n",
      " |          activation_alpha: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.For example with LeakyRelu, the default\n",
      " |              alpha is 0.01.\n",
      " |      \n",
      " |          activation_beta: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.\n",
      " |      \n",
      " |          activations: One (or two if bidirectional) activation function for input\n",
      " |              gate. The activation function must be one of the activation functions\n",
      " |              specified above. Optional: Default `Tanh` if not specified.\n",
      " |      \n",
      " |          clip: Cell clip threshold. Clipping bounds the elements of a tensor in the\n",
      " |              range of [-threshold, +threshold] and is applied to the input of\n",
      " |              activations. No clip if not specified.\n",
      " |      \n",
      " |          direction: Specify if the RNN is forward, reverse, or bidirectional. Must be\n",
      " |              one of forward (default), reverse, or bidirectional.\n",
      " |      \n",
      " |          hidden_size: Number of neurons in the hidden layer\n",
      " |      \n",
      " |          layout: The shape format of inputs X, initial_h and outputs Y, Y_h. If 0,\n",
      " |              the following shapes are expected: X.shape = [seq_length, batch_size,\n",
      " |              input_size], Y.shape = [seq_length, num_directions, batch_size,\n",
      " |              hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size,\n",
      " |              hidden_size]. If 1, the following shapes are expected: X.shape =\n",
      " |              [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length,\n",
      " |              num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size,\n",
      " |              num_directions, hidden_size].\n",
      " |  \n",
      " |  Relu(self, X: 'T_Relu') -> 'T_Relu'\n",
      " |      [üåê Relu(14)](https://onnx.ai/onnx/operators/onnx__Relu.html#relu-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Relu takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  Reshape(self, data: 'T_Reshape', shape: 'INT64', *, allowzero: 'int' = 0) -> 'T_Reshape'\n",
      " |      [üåê Reshape(14)](https://onnx.ai/onnx/operators/onnx__Reshape.html#reshape-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Reshape the input tensor similar to numpy.reshape.\n",
      " |      First input is the data tensor, second input is a shape tensor which specifies the output shape. It outputs the reshaped tensor.\n",
      " |      At most one dimension of the new shape can be -1. In this case, the value is\n",
      " |      inferred from the size of the tensor and the remaining dimensions. A dimension\n",
      " |      could also be 0, in which case the actual dimension value is unchanged (i.e. taken\n",
      " |      from the input tensor). If 'allowzero' is set, and the new shape includes 0, the\n",
      " |      dimension will be set explicitly to zero (i.e. not taken from input tensor).\n",
      " |      Shape (second input) could be an empty shape, which means converting to a scalar.\n",
      " |      The input tensor's shape and the output tensor's shape are required to have the same number of elements.\n",
      " |      \n",
      " |      If the attribute 'allowzero' is set, it is invalid for the specified shape to\n",
      " |      contain both a zero value and -1, as the value of the dimension corresponding\n",
      " |      to -1 cannot be determined uniquely.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          shape: (non-differentiable) Specified shape for output.\n",
      " |      \n",
      " |          allowzero: (Optional) By default, when any value in the 'shape' input is\n",
      " |              equal to zero the corresponding dimension value is copied from the input\n",
      " |              tensor dynamically. allowzero=1 indicates that if any value in the\n",
      " |              'shape' input is set to zero, the zero value is honored, similar to\n",
      " |              NumPy.\n",
      " |  \n",
      " |  Sub(self, A: 'T_Sub', B: 'T_Sub') -> 'T_Sub'\n",
      " |      [üåê Sub(14)](https://onnx.ai/onnx/operators/onnx__Sub.html#sub-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs element-wise binary subtraction (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      (Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) First operand.\n",
      " |      \n",
      " |          B: (differentiable) Second operand.\n",
      " |  \n",
      " |  Trilu(self, input: 'T_Trilu', k: 'Optional[INT64]' = None, *, upper: 'int' = 1) -> 'T_Trilu'\n",
      " |      [üåê Trilu(14)](https://onnx.ai/onnx/operators/onnx__Trilu.html#trilu-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given a 2-D matrix or batches of 2-D matrices, returns the upper or lower triangular part of the tensor(s).\n",
      " |      The attribute \"upper\" determines whether the upper or lower part is retained. If set to true,\n",
      " |      the upper triangular matrix is retained. Lower triangular matrix is retained otherwise.\n",
      " |      Default value for the \"upper\" attribute is true.\n",
      " |      Trilu takes one input tensor of shape [*, N, M], where * is zero or more batch dimensions. The upper triangular part consists\n",
      " |      of the elements on and above the given diagonal (k). The lower triangular part consists of elements on and below the diagonal.\n",
      " |      All other elements in the matrix are set to zero.\n",
      " |      If k = 0, the triangular part on and above/below the main diagonal is retained.\n",
      " |      If upper is set to true, a positive k retains the upper triangular matrix excluding the main diagonal and (k-1) diagonals above it.\n",
      " |      A negative k value retains the main diagonal and |k| diagonals below it.\n",
      " |      If upper is set to false, a positive k retains the lower triangular matrix including the main diagonal and k diagonals above it.\n",
      " |      A negative k value excludes the main diagonal and (|k|-1) diagonals below it.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of rank 2 or higher.\n",
      " |      \n",
      " |          k: (optional, non-differentiable) A 0-D tensor containing a single value\n",
      " |              corresponding to the number diagonals above or below the main diagonal\n",
      " |              to exclude or include. Default value is 0 if it's not specified.\n",
      " |      \n",
      " |          upper: Boolean. Indicates whether upper or lower part of matrix is retained.\n",
      " |              Default is true.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset14.Opset14:\n",
      " |  \n",
      " |  T1_GRU = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T1_LSTM = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T1_RNN = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T2_CumSum = ~T2_CumSum\n",
      " |  \n",
      " |  T_Add = ~T_Add\n",
      " |  \n",
      " |  T_CumSum = ~T_CumSum\n",
      " |  \n",
      " |  T_Div = ~T_Div\n",
      " |  \n",
      " |  T_GRU = ~T_GRU\n",
      " |  \n",
      " |  T_HardSwish = ~T_HardSwish\n",
      " |  \n",
      " |  T_LSTM = ~T_LSTM\n",
      " |  \n",
      " |  T_Mul = ~T_Mul\n",
      " |  \n",
      " |  T_RNN = ~T_RNN\n",
      " |  \n",
      " |  T_Relu = ~T_Relu\n",
      " |  \n",
      " |  T_Reshape = ~T_Reshape\n",
      " |  \n",
      " |  T_Sub = ~T_Sub\n",
      " |  \n",
      " |  T_Trilu = ~T_Trilu\n",
      " |  \n",
      " |  U_BatchNormalization = ~U_BatchNormalization\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset13.Opset13:\n",
      " |  \n",
      " |  Abs(self, X: 'T_Abs') -> 'T_Abs'\n",
      " |      [üåê Abs(13)](https://onnx.ai/onnx/operators/onnx__Abs.html#abs-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Absolute takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where absolute value, y = abs(x), is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  ArgMax(self, data: 'T_ArgMax', *, axis: 'int' = 0, keepdims: 'int' = 1, select_last_index: 'int' = 0) -> 'INT64'\n",
      " |      [üåê ArgMax(13)](https://onnx.ai/onnx/operators/onnx__ArgMax.html#argmax-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the indices of the max elements of the input tensor's element along the\n",
      " |      provided axis. The resulting tensor has the same rank as the input if keepdims equals 1.\n",
      " |      If keepdims equals 0, then the resulting tensor has the reduced dimension pruned.\n",
      " |      If select_last_index is True (default False), the index of the last occurrence of the max\n",
      " |      is selected if the max appears more than once in the input. Otherwise the index of the\n",
      " |      first occurrence is selected.\n",
      " |      The type of the output tensor is integer.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (non-differentiable) An input tensor.\n",
      " |      \n",
      " |          axis: The axis in which to compute the arg indices. Accepted range is [-r,\n",
      " |              r-1] where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          select_last_index: Whether to select the last index or the first index if\n",
      " |              the {name} appears in multiple indices, default is False (first index).\n",
      " |  \n",
      " |  ArgMin(self, data: 'T_ArgMin', *, axis: 'int' = 0, keepdims: 'int' = 1, select_last_index: 'int' = 0) -> 'INT64'\n",
      " |      [üåê ArgMin(13)](https://onnx.ai/onnx/operators/onnx__ArgMin.html#argmin-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the indices of the min elements of the input tensor's element along the\n",
      " |      provided axis. The resulting tensor has the same rank as the input if keepdims equals 1.\n",
      " |      If keepdims equals 0, then the resulting tensor has the reduced dimension pruned.\n",
      " |      If select_last_index is True (default False), the index of the last occurrence of the min\n",
      " |      is selected if the min appears more than once in the input. Otherwise the index of the\n",
      " |      first occurrence is selected.\n",
      " |      The type of the output tensor is integer.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (non-differentiable) An input tensor.\n",
      " |      \n",
      " |          axis: The axis in which to compute the arg indices. Accepted range is [-r,\n",
      " |              r-1] where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          select_last_index: Whether to select the last index or the first index if\n",
      " |              the {name} appears in multiple indices, default is False (first index).\n",
      " |  \n",
      " |  Cast(self, input: 'T1_Cast', *, to: 'int') -> 'T2_Cast'\n",
      " |      [üåê Cast(13)](https://onnx.ai/onnx/operators/onnx__Cast.html#cast-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator casts the elements of a given input tensor to a data type\n",
      " |      specified by the 'to' argument and returns an output tensor of the same size in\n",
      " |      the converted type. The 'to' argument must be one of the data types specified\n",
      " |      in the 'DataType' enum field in the TensorProto message.\n",
      " |      \n",
      " |      Casting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n",
      " |      (e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\n",
      " |      yield result 100. There are some string literals reserved for special floating-point values;\n",
      " |      \"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\n",
      " |      Any string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\n",
      " |      this case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\n",
      " |      to string tensors, plain floating-point representation (such as \"314.15926\") would be used.\n",
      " |      Converting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\n",
      " |      of converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n",
      " |      \n",
      " |      Conversion from a numerical type to any numerical type is always allowed.\n",
      " |      User must be aware of precision loss and value change caused by range difference between two types.\n",
      " |      For example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\n",
      " |      an integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
      " |      \n",
      " |      In more detail, the conversion among numerical types should follow these rules:\n",
      " |      \n",
      " |      * Casting from floating point to:\n",
      " |        * floating point: +/- infinity if OOR (out of range).\n",
      " |        * fixed point: undefined if OOR.\n",
      " |        * bool: +/- 0.0 to False; all else to True.\n",
      " |      * Casting from fixed point to:\n",
      " |        * floating point: +/- infinity if OOR. (+ infinity in the case of uint)\n",
      " |        * fixed point: when OOR, discard higher bits and reinterpret (with respect to two's complement representation for\n",
      " |          signed types). For example, 200 (int16) -> -56 (int8).\n",
      " |        * bool: zero to False; nonzero to True.\n",
      " |      * Casting from bool to:\n",
      " |        * floating point: `{1.0, 0.0}`.\n",
      " |        * fixed point: `{1, 0}`.\n",
      " |        * bool: no change.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor to be cast.\n",
      " |      \n",
      " |          to: The data type to which the elements of the input tensor are cast.\n",
      " |              Strictly must be one of the types from DataType enum in TensorProto\n",
      " |  \n",
      " |  Ceil(self, X: 'T_Ceil') -> 'T_Ceil'\n",
      " |      [üåê Ceil(13)](https://onnx.ai/onnx/operators/onnx__Ceil.html#ceil-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Ceil takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the ceil is, y = ceil(x), is applied to\n",
      " |      the tensor elementwise. If x is integral, +0, -0, NaN,  or infinite, x itself is returned.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  Clip(self, input: 'T_Clip', min: 'Optional[T_Clip]' = None, max: 'Optional[T_Clip]' = None) -> 'T_Clip'\n",
      " |      [üåê Clip(13)](https://onnx.ai/onnx/operators/onnx__Clip.html#clip-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Clip operator limits the given input within an interval. The interval is\n",
      " |      specified by the inputs 'min' and 'max'. They default to\n",
      " |      numeric_limits::lowest() and numeric_limits::max(), respectively.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor whose elements to be clipped\n",
      " |      \n",
      " |          min: (optional, non-differentiable) Minimum value, under which element is\n",
      " |              replaced by min. It must be a scalar(tensor of empty shape).\n",
      " |      \n",
      " |          max: (optional, non-differentiable) Maximum value, above which element is\n",
      " |              replaced by max. It must be a scalar(tensor of empty shape).\n",
      " |  \n",
      " |  Concat(self, *inputs: 'T_Concat', axis: 'int') -> 'T_Concat'\n",
      " |      [üåê Concat(13)](https://onnx.ai/onnx/operators/onnx__Concat.html#concat-13 \"Online Documentation\")\n",
      " |      \n",
      " |      Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: (variadic, differentiable) List of tensors for concatenation\n",
      " |      \n",
      " |          axis: Which axis to concat on. A negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-r, r-1] where r = rank(inputs)..\n",
      " |  \n",
      " |  Constant(self, *, sparse_value: 'Optional[SparseTensorProto]' = None, value: 'Optional[TensorProto]' = None, value_float: 'Optional[float]' = None, value_floats: 'Optional[Sequence[float]]' = None, value_int: 'Optional[int]' = None, value_ints: 'Optional[Sequence[int]]' = None, value_string: 'Optional[str]' = None, value_strings: 'Optional[Sequence[str]]' = None) -> 'T_Constant'\n",
      " |      [üåê Constant(13)](https://onnx.ai/onnx/operators/onnx__Constant.html#constant-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      This operator produces a constant tensor. Exactly one of the provided attributes, either value, sparse_value,\n",
      " |      or value_* must be specified.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          sparse_value: The value for the elements of the output tensor in sparse\n",
      " |              format.\n",
      " |      \n",
      " |          value: The value for the elements of the output tensor.\n",
      " |      \n",
      " |          value_float: The value for the sole element for the scalar, float32, output\n",
      " |              tensor.\n",
      " |      \n",
      " |          value_floats: The values for the elements for the 1D, float32, output\n",
      " |              tensor.\n",
      " |      \n",
      " |          value_int: The value for the sole element for the scalar, int64, output\n",
      " |              tensor.\n",
      " |      \n",
      " |          value_ints: The values for the elements for the 1D, int64, output tensor.\n",
      " |      \n",
      " |          value_string: The value for the sole element for the scalar, UTF-8 string,\n",
      " |              output tensor.\n",
      " |      \n",
      " |          value_strings: The values for the elements for the 1D, UTF-8 string, output\n",
      " |              tensor.\n",
      " |  \n",
      " |  DepthToSpace(self, input: 'T_DepthToSpace', *, blocksize: 'int', mode: 'str' = 'DCR') -> 'T_DepthToSpace'\n",
      " |      [üåê DepthToSpace(13)](https://onnx.ai/onnx/operators/onnx__DepthToSpace.html#depthtospace-13 \"Online Documentation\")\n",
      " |      \n",
      " |      DepthToSpace rearranges (permutes) data from depth into blocks of spatial data.\n",
      " |      This is the reverse transformation of SpaceToDepth. More specifically, this op outputs a copy of\n",
      " |      the input tensor where values from the depth dimension are moved in spatial blocks to the height\n",
      " |      and width dimensions. By default, `mode` = `DCR`.\n",
      " |      In the DCR mode, elements along the depth dimension from the input tensor are rearranged in the\n",
      " |      following order: depth, column, and then row. The output y is computed from the input x as below:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          b, c, h, w = x.shape\n",
      " |          tmp = np.reshape(x, [b, blocksize, blocksize, c // (blocksize**2), h, w])\n",
      " |          tmp = np.transpose(tmp, [0, 3, 4, 1, 5, 2])\n",
      " |          y = np.reshape(tmp, [b, c // (blocksize**2), h * blocksize, w * blocksize])\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      In the CRD mode, elements along the depth dimension from the input tensor are rearranged in the\n",
      " |      following order: column, row, and the depth. The output y is computed from the input x as below:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          b, c, h, w = x.shape\n",
      " |          tmp = np.reshape(x, [b, c // (blocksize ** 2), blocksize, blocksize, h, w])\n",
      " |          tmp = np.transpose(tmp, [0, 1, 4, 2, 5, 3])\n",
      " |          y = np.reshape(tmp, [b, c // (blocksize ** 2), h * blocksize, w * blocksize])\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of [N,C,H,W], where N is the batch\n",
      " |              axis, C is the channel or depth, H is the height and W is the width.\n",
      " |      \n",
      " |          blocksize: Blocks of [blocksize, blocksize] are moved.\n",
      " |      \n",
      " |          mode: DCR (default) for depth-column-row order re-arrangement. Use CRD for\n",
      " |              column-row-depth order.\n",
      " |  \n",
      " |  DequantizeLinear(self, x: 'T_DequantizeLinear', x_scale: 'FLOAT', x_zero_point: 'Optional[T_DequantizeLinear]' = None, *, axis: 'int' = 1) -> 'FLOAT'\n",
      " |      [üåê DequantizeLinear(13)](https://onnx.ai/onnx/operators/onnx__DequantizeLinear.html#dequantizelinear-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The linear dequantization operator. It consumes a quantized tensor, a scale, and a zero point to compute the full precision tensor.\n",
      " |      The dequantization formula is `y = (x - x_zero_point) * x_scale`. `x_scale` and `x_zero_point` must have same shape, and can be either a scalar\n",
      " |      for per-tensor / per layer quantization, or a 1-D tensor for per-axis quantization.\n",
      " |      `x_zero_point` and `x` must have same type. `x` and `y` must have same shape. In the case of dequantizing int32,\n",
      " |      there's no zero point (zero point is supposed to be 0).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: N-D quantized input tensor to be de-quantized.\n",
      " |      \n",
      " |          x_scale: Scale for input 'x'. It can be a scalar, which means a\n",
      " |              per-tensor/layer dequantization, or a 1-D tensor for per-axis\n",
      " |              dequantization.\n",
      " |      \n",
      " |          x_zero_point: (optional) Zero point for input 'x'. Shape must match x_scale.\n",
      " |              It's optional. Zero point is 0 when it's not specified.\n",
      " |      \n",
      " |          axis: (Optional) The axis of the dequantizing dimension of the input tensor.\n",
      " |              Ignored for per-tensor quantization. Negative value means counting\n",
      " |              dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |  \n",
      " |  Dropout(self, data: 'T_Dropout', ratio: 'Optional[T1_Dropout]' = None, training_mode: 'Optional[T2_Dropout]' = None, *, seed: 'Optional[int]' = None) -> 'Tuple[T_Dropout, T2_Dropout]'\n",
      " |      [üåê Dropout(13)](https://onnx.ai/onnx/operators/onnx__Dropout.html#dropout-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Dropout takes an input floating-point tensor, an optional input ratio (floating-point scalar) and an optional input training_mode (boolean scalar). It produces two tensor outputs,\n",
      " |      output (floating-point tensor) and mask (optional `Tensor<bool>`). If `training_mode` is true then the output Y will be a random dropout;\n",
      " |      Note that this Dropout scales the masked input data by the following equation, so to convert the trained model into inference mode,\n",
      " |      the user can simply not pass `training_mode` input or set it to false.\n",
      " |      ::\n",
      " |      \n",
      " |          output = scale * data * mask,\n",
      " |      \n",
      " |      \n",
      " |      where\n",
      " |      ::\n",
      " |      \n",
      " |          scale = 1. / (1. - ratio).\n",
      " |      \n",
      " |      \n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) The input data as Tensor.\n",
      " |      \n",
      " |          ratio: (optional, non-differentiable) The ratio of random dropout, with\n",
      " |              value in [0, 1). If this input was not set, or if it was set to 0, the\n",
      " |              output would be a simple copy of the input. If it's non-zero, output\n",
      " |              will be a random dropout of the scaled input, which is typically the\n",
      " |              case during training. It is an optional value, if not specified it will\n",
      " |              default to 0.5.\n",
      " |      \n",
      " |          training_mode: (optional, non-differentiable) If set to true then it\n",
      " |              indicates dropout is being used for training. It is an optional value\n",
      " |              hence unless specified explicitly, it is false. If it is false, ratio is\n",
      " |              ignored and the operation mimics inference mode where nothing will be\n",
      " |              dropped from the input data and if mask is requested as output it will\n",
      " |              contain all ones.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  Equal(self, A: 'T_Equal', B: 'T_Equal') -> 'T1_Equal'\n",
      " |      [üåê Equal(13)](https://onnx.ai/onnx/operators/onnx__Equal.html#equal-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `equal` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Erf(self, input: 'T_Erf') -> 'T_Erf'\n",
      " |      [üåê Erf(13)](https://onnx.ai/onnx/operators/onnx__Erf.html#erf-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the error function of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Exp(self, input: 'T_Exp') -> 'T_Exp'\n",
      " |      [üåê Exp(13)](https://onnx.ai/onnx/operators/onnx__Exp.html#exp-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the exponential of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Expand(self, input: 'T_Expand', shape: 'INT64') -> 'T_Expand'\n",
      " |      [üåê Expand(13)](https://onnx.ai/onnx/operators/onnx__Expand.html#expand-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Broadcast the input tensor following the given shape and the broadcast rule.\n",
      " |      The broadcast rule is similar to numpy.array(input) * numpy.ones(shape):\n",
      " |      Dimensions are right alignment;\n",
      " |      Two corresponding dimensions must have the same value, or one of them is equal to 1.\n",
      " |      Also, this operator is similar to numpy.broadcast_to(input, shape),\n",
      " |      but the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().\n",
      " |      It is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,\n",
      " |      or the shape.ndim < input.shape.ndim.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |      \n",
      " |          shape: (non-differentiable) A 1-D tensor indicates the shape you want to\n",
      " |              expand to, following the broadcast rule\n",
      " |  \n",
      " |  Flatten(self, input: 'T_Flatten', *, axis: 'int' = 1) -> 'T_Flatten'\n",
      " |      [üåê Flatten(13)](https://onnx.ai/onnx/operators/onnx__Flatten.html#flatten-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Flattens the input tensor into a 2D matrix. If input tensor has shape\n",
      " |      (d_0, d_1, ... d_n) then the output will have shape\n",
      " |      (d_0 X d_1 ... d_(axis-1), d_axis X d_(axis+1) ... X dn).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) A tensor of rank >= axis.\n",
      " |      \n",
      " |          axis: Indicate up to which input dimensions (exclusive) should be flattened\n",
      " |              to the outer dimension of the output. The value for axis must be in the\n",
      " |              range [-r, r], where r is the rank of the input tensor. Negative value\n",
      " |              means counting dimensions from the back. When axis = 0, the shape of the\n",
      " |              output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input\n",
      " |              tensor is (d_0, d_1, ... d_n).\n",
      " |  \n",
      " |  Floor(self, X: 'T_Floor') -> 'T_Floor'\n",
      " |      [üåê Floor(13)](https://onnx.ai/onnx/operators/onnx__Floor.html#floor-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Floor takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the floor is, y = floor(x), is applied to\n",
      " |      the tensor elementwise. If x is integral, +0, -0, NaN,  or infinite, x itself is returned.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  Gather(self, data: 'T_Gather', indices: 'Tind_Gather', *, axis: 'int' = 0) -> 'T_Gather'\n",
      " |      [üåê Gather(13)](https://onnx.ai/onnx/operators/onnx__Gather.html#gather-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given `data` tensor of rank r >= 1, and `indices` tensor of rank q, gather\n",
      " |      entries of the axis dimension of `data` (by default outer-most one as axis=0) indexed by `indices`, and concatenates\n",
      " |      them in an output tensor of rank q + (r - 1).\n",
      " |      \n",
      " |      If `axis = 0`, let `k = indices[i_{0}, ..., i_{q-1}]`\n",
      " |      then `output[i_{0}, ..., i_{q-1}, j_{0}, ..., j_{r-2}] = input[k , j_{0}, ..., j_{r-2}]`:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2],\n",
      " |              [2.3, 3.4],\n",
      " |              [4.5, 5.7],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [0, 1],\n",
      " |              [1, 2],\n",
      " |          ]\n",
      " |          output = [\n",
      " |              [\n",
      " |                  [1.0, 1.2],\n",
      " |                  [2.3, 3.4],\n",
      " |              ],\n",
      " |              [\n",
      " |                  [2.3, 3.4],\n",
      " |                  [4.5, 5.7],\n",
      " |              ],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      If `axis = 1`, let `k = indices[i_{0}, ..., i_{q-1}]`\n",
      " |      then `output[j_{0}, i_{0}, ..., i_{q-1}, j_{1}, ..., j_{r-2}] = input[j_{0}, k, j_{1}, ..., j_{r-2}]`:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2, 1.9],\n",
      " |              [2.3, 3.4, 3.9],\n",
      " |              [4.5, 5.7, 5.9],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [0, 2],\n",
      " |          ]\n",
      " |          axis = 1,\n",
      " |          output = [\n",
      " |                  [[1.0, 1.9]],\n",
      " |                  [[2.3, 3.9]],\n",
      " |                  [[4.5, 5.9]],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of int32/int64 indices, of any rank q.\n",
      " |              All index values are expected to be within bounds [-s, s-1] along axis\n",
      " |              of size s. It is an error if any of the index values are out of bounds.\n",
      " |      \n",
      " |          axis: Which axis to gather on. Negative value means counting dimensions from\n",
      " |              the back. Accepted range is [-r, r-1] where r = rank(data).\n",
      " |  \n",
      " |  GatherElements(self, data: 'T_GatherElements', indices: 'Tind_GatherElements', *, axis: 'int' = 0) -> 'T_GatherElements'\n",
      " |      [üåê GatherElements(13)](https://onnx.ai/onnx/operators/onnx__GatherElements.html#gatherelements-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      GatherElements takes two inputs `data` and `indices` of the same rank r >= 1\n",
      " |      and an optional attribute `axis` that identifies an axis of `data`\n",
      " |      (by default, the outer-most axis, that is axis 0). It is an indexing operation\n",
      " |      that produces its output by indexing into the input data tensor at index\n",
      " |      positions determined by elements of the `indices` tensor.\n",
      " |      Its output shape is the same as the shape of `indices` and consists of one value\n",
      " |      (gathered from the `data`) for each element in `indices`.\n",
      " |      \n",
      " |      For instance, in the 3-D case (r = 3), the output produced is determined\n",
      " |      by the following equations:\n",
      " |      ::\n",
      " |      \n",
      " |          out[i][j][k] = input[index[i][j][k]][j][k] if axis = 0,\n",
      " |          out[i][j][k] = input[i][index[i][j][k]][k] if axis = 1,\n",
      " |          out[i][j][k] = input[i][j][index[i][j][k]] if axis = 2,\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      This operator is also the inverse of ScatterElements. It is similar to Torch's gather operation.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1, 2],\n",
      " |              [3, 4],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [0, 0],\n",
      " |              [1, 0],\n",
      " |          ]\n",
      " |          axis = 1\n",
      " |          output = [\n",
      " |              [1, 1],\n",
      " |              [4, 3],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1, 2, 3],\n",
      " |              [4, 5, 6],\n",
      " |              [7, 8, 9],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [1, 2, 0],\n",
      " |              [2, 0, 0],\n",
      " |          ]\n",
      " |          axis = 0\n",
      " |          output = [\n",
      " |              [4, 8, 3],\n",
      " |              [7, 2, 3],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of int32/int64 indices, with the same\n",
      " |              rank r as the input. All index values are expected to be within bounds\n",
      " |              [-s, s-1] along axis of size s. It is an error if any of the index\n",
      " |              values are out of bounds.\n",
      " |      \n",
      " |          axis: Which axis to gather on. Negative value means counting dimensions from\n",
      " |              the back. Accepted range is [-r, r-1] where r = rank(data).\n",
      " |  \n",
      " |  GatherND(self, data: 'T_GatherND', indices: 'INT64', *, batch_dims: 'int' = 0) -> 'T_GatherND'\n",
      " |      [üåê GatherND(13)](https://onnx.ai/onnx/operators/onnx__GatherND.html#gathernd-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given `data` tensor of rank `r` >= 1, `indices` tensor of rank `q` >= 1, and `batch_dims` integer `b`, this operator gathers\n",
      " |      slices of `data` into an output tensor of rank `q + r - indices_shape[-1] - 1 - b`.\n",
      " |      \n",
      " |      `indices` is an q-dimensional integer tensor, best thought of as a `(q-1)`-dimensional tensor of index-tuples into `data`,\n",
      " |      where each element defines a slice of `data`\n",
      " |      \n",
      " |      `batch_dims` (denoted as `b`) is an integer indicating the number of batch dimensions, i.e the leading `b` number of dimensions of\n",
      " |      `data` tensor and `indices` are representing the batches, and the gather starts from the `b+1` dimension.\n",
      " |      \n",
      " |      Some salient points about the inputs' rank and shape:\n",
      " |      \n",
      " |      1) r >= 1 and q >= 1 are to be honored. There is no dependency condition to be met between ranks `r` and `q`\n",
      " |      \n",
      " |      2) The first `b` dimensions of the shape of `indices` tensor and `data` tensor must be equal.\n",
      " |      \n",
      " |      3) b < min(q, r) is to be honored.\n",
      " |      \n",
      " |      4) The `indices_shape[-1]` should have a value between 1 (inclusive) and rank `r-b` (inclusive)\n",
      " |      \n",
      " |      5) All values in `indices` are expected to be within bounds [-s, s-1] along axis of size `s` (i.e.) `-data_shape[i] <= indices[...,i] <= data_shape[i] - 1`.\n",
      " |         It is an error if any of the index values are out of bounds.\n",
      " |      \n",
      " |      The output is computed as follows:\n",
      " |      \n",
      " |      The output tensor is obtained by mapping each index-tuple in the `indices` tensor to the corresponding slice of the input `data`.\n",
      " |      \n",
      " |      1) If `indices_shape[-1] > r-b` => error condition\n",
      " |      \n",
      " |      2) If `indices_shape[-1] == r-b`, since the rank of `indices` is `q`, `indices` can be thought of as `N` `(q-b-1)`-dimensional tensors\n",
      " |         containing 1-D tensors of dimension `r-b`, where `N` is an integer equals to the product of 1 and all the elements in the batch dimensions\n",
      " |         of the indices_shape. Let us think of each such `r-b` ranked tensor as `indices_slice`. Each *scalar value* corresponding to `data[0:b-1,indices_slice]`\n",
      " |         is filled into the corresponding location of the `(q-b-1)`-dimensional tensor to form the `output` tensor (Example 1 below)\n",
      " |      \n",
      " |      3) If `indices_shape[-1] < r-b`, since the rank of `indices` is `q`, `indices` can be thought of as `N` `(q-b-1)`-dimensional tensor\n",
      " |         containing 1-D tensors of dimension `< r-b`. Let us think of each such tensors as `indices_slice`. Each *tensor slice* corresponding\n",
      " |         to `data[0:b-1, indices_slice , :]` is filled into the corresponding location of the `(q-b-1)`-dimensional tensor\n",
      " |         to form the `output` tensor (Examples 2, 3, 4 and 5 below)\n",
      " |      \n",
      " |      This operator is the inverse of `ScatterND`.\n",
      " |      \n",
      " |      `Example 1`\n",
      " |      \n",
      " |        batch_dims = 0\n",
      " |      \n",
      " |        data    = [[0,1],[2,3]]   # data_shape = [2, 2]\n",
      " |      \n",
      " |        indices = [[0,0],[1,1]]   # indices_shape = [2, 2]\n",
      " |      \n",
      " |        output  = [0,3]           # output_shape = [2]\n",
      " |      \n",
      " |      `Example 2`\n",
      " |      \n",
      " |        batch_dims = 0\n",
      " |      \n",
      " |        data    = [[0,1],[2,3]]  # data_shape = [2, 2]\n",
      " |      \n",
      " |        indices = [[1],[0]]      # indices_shape = [2, 1]\n",
      " |      \n",
      " |        output  = [[2,3],[0,1]]  # output_shape = [2, 2]\n",
      " |      \n",
      " |      `Example 3`\n",
      " |      \n",
      " |        batch_dims = 0\n",
      " |      \n",
      " |        data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]\n",
      " |      \n",
      " |        indices = [[0,1],[1,0]]                 # indices_shape = [2, 2]\n",
      " |      \n",
      " |        output  = [[2,3],[4,5]]                 # output_shape = [2, 2]\n",
      " |      \n",
      " |      `Example 4`\n",
      " |      \n",
      " |        batch_dims = 0\n",
      " |      \n",
      " |        data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]\n",
      " |      \n",
      " |        indices = [[[0,1]],[[1,0]]]             # indices_shape = [2, 1, 2]\n",
      " |      \n",
      " |        output  = [[[2,3]],[[4,5]]]             # output_shape = [2, 1, 2]\n",
      " |      \n",
      " |      `Example 5`\n",
      " |      \n",
      " |        batch_dims = 1\n",
      " |      \n",
      " |        data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]\n",
      " |      \n",
      " |        indices = [[1],[0]]             # indices_shape = [2, 1]\n",
      " |      \n",
      " |        output  = [[2,3],[4,5]]             # output_shape = [2, 2]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of rank q >= 1. All index values are\n",
      " |              expected to be within bounds [-s, s-1] along axis of size s. It is an\n",
      " |              error if any of the index values are out of bounds.\n",
      " |      \n",
      " |          batch_dims: The number of batch dimensions. The gather of indexing starts\n",
      " |              from dimension of data[batch_dims:]\n",
      " |  \n",
      " |  Gemm(self, A: 'T_Gemm', B: 'T_Gemm', C: 'Optional[T_Gemm]' = None, *, alpha: 'float' = 1.0, beta: 'float' = 1.0, transA: 'int' = 0, transB: 'int' = 0) -> 'T_Gemm'\n",
      " |      [üåê Gemm(13)](https://onnx.ai/onnx/operators/onnx__Gemm.html#gemm-13 \"Online Documentation\")\n",
      " |      \n",
      " |      General Matrix multiplication:\n",
      " |      https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3\n",
      " |      \n",
      " |      * A' = transpose(A) if transA else A\n",
      " |      * B' = transpose(B) if transB else B\n",
      " |      \n",
      " |      Compute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),\n",
      " |      input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),\n",
      " |      and output tensor Y has shape (M, N). A will be transposed before doing the\n",
      " |      computation if attribute transA is non-zero, same for B and transB.\n",
      " |      This operator supports **unidirectional broadcasting** (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) Input tensor A. The shape of A should be (M, K) if\n",
      " |              transA is 0, or (K, M) if transA is non-zero.\n",
      " |      \n",
      " |          B: (differentiable) Input tensor B. The shape of B should be (K, N) if\n",
      " |              transB is 0, or (N, K) if transB is non-zero.\n",
      " |      \n",
      " |          C: (optional, differentiable) Optional input tensor C. If not specified, the\n",
      " |              computation is done as if C is a scalar 0. The shape of C should be\n",
      " |              unidirectional broadcastable to (M, N).\n",
      " |      \n",
      " |          alpha: Scalar multiplier for the product of input tensors A * B.\n",
      " |      \n",
      " |          beta: Scalar multiplier for input tensor C.\n",
      " |      \n",
      " |          transA: Whether A should be transposed\n",
      " |      \n",
      " |          transB: Whether B should be transposed\n",
      " |  \n",
      " |  Greater(self, A: 'T_Greater', B: 'T_Greater') -> 'T1_Greater'\n",
      " |      [üåê Greater(13)](https://onnx.ai/onnx/operators/onnx__Greater.html#greater-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `greater` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Hardmax(self, input: 'T_Hardmax', *, axis: 'int' = -1) -> 'T_Hardmax'\n",
      " |      [üåê Hardmax(13)](https://onnx.ai/onnx/operators/onnx__Hardmax.html#hardmax-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator computes the hardmax values for the given input:\n",
      " |      \n",
      " |       Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise\n",
      " |      \n",
      " |      The \"axis\" attribute indicates the dimension along which Hardmax\n",
      " |      will be performed. The output tensor has the same shape\n",
      " |      and contains the Hardmax values of the corresponding input.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The input tensor of rank >= axis.\n",
      " |      \n",
      " |          axis:\n",
      " |      Describes the dimension Hardmax will be performed on.\n",
      " |      Negative value\n",
      " |              means counting dimensions\n",
      " |      from the back. Accepted range is [-r, r-1]\n",
      " |              where r = rank(input).\n",
      " |  \n",
      " |  IsNaN(self, X: 'T1_IsNaN') -> 'T2_IsNaN'\n",
      " |      [üåê IsNaN(13)](https://onnx.ai/onnx/operators/onnx__IsNaN.html#isnan-13 \"Online Documentation\")\n",
      " |      \n",
      " |      Returns which elements of the input are NaN.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) input\n",
      " |  \n",
      " |  LRN(self, X: 'T_LRN', *, alpha: 'float' = 9.999999747378752e-05, beta: 'float' = 0.75, bias: 'float' = 1.0, size: 'int') -> 'T_LRN'\n",
      " |      [üåê LRN(13)](https://onnx.ai/onnx/operators/onnx__LRN.html#lrn-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Local Response Normalization proposed in the [AlexNet paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
      " |      It normalizes over local input regions.\n",
      " |      The local region is defined across the channels. For an element `X[n, c, d1, ..., dk]` in a tensor\n",
      " |      of shape `(N x C x D1 x D2, ..., Dk)`, its region is\n",
      " |      `{X[n, i, d1, ..., dk] | max(0, c - floor((size - 1) / 2)) <= i <= min(C - 1, c + ceil((size - 1) / 2))}`.\n",
      " |      \n",
      " |      `square_sum[n, c, d1, ..., dk] = sum(X[n, i, d1, ..., dk] ^ 2)`,\n",
      " |      where `max(0, c - floor((size - 1) / 2)) <= i <= min(C - 1, c + ceil((size - 1) / 2))`.\n",
      " |      \n",
      " |      `Y[n, c, d1, ..., dk] = X[n, c, d1, ..., dk] / (bias + alpha / size * square_sum[n, c, d1, ..., dk] ) ^ beta`\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size. Optionally, if dimension\n",
      " |              denotation is in effect, the operation expects the input data tensor to\n",
      " |              arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL,\n",
      " |              DATA_FEATURE, DATA_FEATURE ...].\n",
      " |      \n",
      " |          alpha: Scaling parameter.\n",
      " |      \n",
      " |          beta: The exponent.\n",
      " |      \n",
      " |          size: The number of channels to sum over\n",
      " |  \n",
      " |  Less(self, A: 'T_Less', B: 'T_Less') -> 'T1_Less'\n",
      " |      [üåê Less(13)](https://onnx.ai/onnx/operators/onnx__Less.html#less-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `less` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Log(self, input: 'T_Log') -> 'T_Log'\n",
      " |      [üåê Log(13)](https://onnx.ai/onnx/operators/onnx__Log.html#log-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the natural log of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  LogSoftmax(self, input: 'T_LogSoftmax', *, axis: 'int' = -1) -> 'T_LogSoftmax'\n",
      " |      [üåê LogSoftmax(13)](https://onnx.ai/onnx/operators/onnx__LogSoftmax.html#logsoftmax-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator computes the log of softmax values for the given input:\n",
      " |      \n",
      " |       LogSoftmax(input, axis) = Log(Softmax(input, axis=axis))\n",
      " |      \n",
      " |      The \"axis\" attribute indicates the dimension along which LogSoftmax\n",
      " |      will be performed. The output tensor has the same shape\n",
      " |      and contains the LogSoftmax values of the corresponding input.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The input tensor of rank >= axis.\n",
      " |      \n",
      " |          axis:\n",
      " |      Describes the dimension LogSoftmax will be performed on.\n",
      " |      Negative\n",
      " |              value means counting dimensions\n",
      " |      from the back. Accepted range is [-r,\n",
      " |              r-1] where r = rank(input).\n",
      " |  \n",
      " |  MatMul(self, A: 'T_MatMul', B: 'T_MatMul') -> 'T_MatMul'\n",
      " |      [üåê MatMul(13)](https://onnx.ai/onnx/operators/onnx__MatMul.html#matmul-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) N-dimensional matrix A\n",
      " |      \n",
      " |          B: (differentiable) N-dimensional matrix B\n",
      " |  \n",
      " |  Max(self, *data_0: 'T_Max') -> 'T_Max'\n",
      " |      [üåê Max(13)](https://onnx.ai/onnx/operators/onnx__Max.html#max-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Element-wise max of each of the input tensors (with Numpy-style broadcasting support).\n",
      " |      All inputs and outputs must have the same data type.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data_0: (variadic, differentiable) List of tensors for max.\n",
      " |  \n",
      " |  Mean(self, *data_0: 'T_Mean') -> 'T_Mean'\n",
      " |      [üåê Mean(13)](https://onnx.ai/onnx/operators/onnx__Mean.html#mean-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Element-wise mean of each of the input tensors (with Numpy-style broadcasting support).\n",
      " |      All inputs and outputs must have the same data type.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data_0: (variadic, differentiable) List of tensors for mean.\n",
      " |  \n",
      " |  MeanVarianceNormalization(self, X: 'T_MeanVarianceNormalization', *, axes: 'Sequence[int]' = (0, 2, 3)) -> 'T_MeanVarianceNormalization'\n",
      " |      [üåê MeanVarianceNormalization(13)](https://onnx.ai/onnx/operators/onnx__MeanVarianceNormalization.html#meanvariancenormalization-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |            A MeanVarianceNormalization Function: Perform mean variance normalization\n",
      " |            on the input tensor X using formula: `(X-EX)/sqrt(E(X-EX)^2)`\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          axes: A list of integers, along which to reduce. The default is to caculate\n",
      " |              along axes [0,2,3] for calculating mean and variance along each channel.\n",
      " |              Two variables with the same C-coordinate are associated with the same\n",
      " |              mean and variance.\n",
      " |  \n",
      " |  Min(self, *data_0: 'T_Min') -> 'T_Min'\n",
      " |      [üåê Min(13)](https://onnx.ai/onnx/operators/onnx__Min.html#min-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Element-wise min of each of the input tensors (with Numpy-style broadcasting support).\n",
      " |      All inputs and outputs must have the same data type.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data_0: (variadic, differentiable) List of tensors for min.\n",
      " |  \n",
      " |  Mod(self, A: 'T_Mod', B: 'T_Mod', *, fmod: 'int' = 0) -> 'T_Mod'\n",
      " |      [üåê Mod(13)](https://onnx.ai/onnx/operators/onnx__Mod.html#mod-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |        Performs element-wise binary modulus (with Numpy-style broadcasting support).\n",
      " |        The sign of the remainder is the same as that of the Divisor.\n",
      " |      \n",
      " |        Mod operator can also behave like C fmod() or numpy.fmod. In this case, the sign of the remainder however, will be the same as the Dividend\n",
      " |        (in contrast to integer mod). To force a behavior like numpy.fmod() an 'fmod' Attribute is provided.\n",
      " |        This attribute is set to 0 by default causing the behavior to be like integer mod.\n",
      " |        Setting this attribute to 1 causes the remainder to be calculated similar to that of numpy.fmod().\n",
      " |      \n",
      " |        If the input type is floating point, then `fmod` attribute must be set to 1.\n",
      " |      \n",
      " |        In case of dividend being zero, the results will be platform dependent.\n",
      " |      \n",
      " |        This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) Dividend tensor\n",
      " |      \n",
      " |          B: (non-differentiable) Divisor tensor\n",
      " |      \n",
      " |          fmod: Whether the operator should behave like fmod (default=0 meaning it\n",
      " |              will do integer mods); Set this to 1 to force fmod treatment\n",
      " |  \n",
      " |  Neg(self, X: 'T_Neg') -> 'T_Neg'\n",
      " |      [üåê Neg(13)](https://onnx.ai/onnx/operators/onnx__Neg.html#neg-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Neg takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where each element flipped sign, y = -x, is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  NegativeLogLikelihoodLoss(self, input: 'T_NegativeLogLikelihoodLoss', target: 'Tind_NegativeLogLikelihoodLoss', weight: 'Optional[T_NegativeLogLikelihoodLoss]' = None, *, ignore_index: 'Optional[int]' = None, reduction: 'str' = 'mean') -> 'T_NegativeLogLikelihoodLoss'\n",
      " |      [üåê NegativeLogLikelihoodLoss(13)](https://onnx.ai/onnx/operators/onnx__NegativeLogLikelihoodLoss.html#negativeloglikelihoodloss-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      A NegativeLogLikelihoodLoss operator computes (weighted) negative log likelihood loss.\n",
      " |      Its \"input\" tensor has the shape of (N, C, d1, d2, ..., dk) where k >= 0.\n",
      " |      The \"input\" tensor contains log-probabilities for input[n, :, d_1, d_2,..., d_k] being in a class of [0, C).\n",
      " |      The operator's \"target\" input tensor has the shape of (N, d1, d2, ..., dk). It encodes class labels (one of C classes)\n",
      " |      or it may contain a special value (indicated by an attribute ignore_index) for N x d1 x d2 x ... x dk samples.\n",
      " |      The loss value for input[n, :, d_1, d_2,...d_k] being classified as class c = target[n][d_1][d_2]...[d_k] is computed as:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          loss[n][d_1][d_2]...[d_k] = -input[n][c][d_1][d_2]...[d_k].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      When an optional \"weight\" is provided, the sample loss is calculated as:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          loss[n][d_1][d_2]...[d_k] = -input[n][c][d_1][d_2]...[d_k] * weight[c].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      loss is zero for the case when target-value equals ignore_index.\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          loss[n][d_1][d_2]...[d_k] = 0, when target[n][d_1][d_2]...[d_k] = ignore_index\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      If \"reduction\" attribute is set to \"none\", the operator's output will be the above loss with shape (N, d1, d2, ..., dk).\n",
      " |      If \"reduction\" attribute is set to \"mean\" (the default attribute value), the output loss is (weight) averaged:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          mean(loss), if \"weight\" is not provided,\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      or if weight is provided,\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          sum(loss) / sum(weight[target[n][d_1][d_2]...[d_k]]]), for all samples.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      If \"reduction\" attribute is set to \"sum\", the output is a scalar: `sum(loss)`.\n",
      " |      \n",
      " |      See also https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          // negative log likelihood loss, \"none\" reduction\n",
      " |          N, C, d1 = 2, 3, 2\n",
      " |          input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],\n",
      " |                    [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]\n",
      " |          target = [[2, 1], [0, 2]]\n",
      " |      \n",
      " |          loss = np.zeros((N, d1))\n",
      " |          for n in range(N):\n",
      " |              for d_1 in range(d1):\n",
      " |                  c = target[n][d_1]\n",
      " |                  loss[n][d_1] = -input[n][c][d_1]\n",
      " |      \n",
      " |          // print(loss)\n",
      " |          // [[-3. -2.]\n",
      " |          //  [-0. -2.]]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          // weighted negative log likelihood loss, sum reduction\n",
      " |          N, C, d1 = 2, 3, 2\n",
      " |          input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],\n",
      " |                  [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]\n",
      " |          target = [[2, 1], [0, 2]]\n",
      " |          weight = [0.2, 0.3, 0.1]\n",
      " |          loss = np.zeros((N, d1))\n",
      " |          for n in range(N):\n",
      " |              for d_1 in range(d1):\n",
      " |                  c = target[n][d_1]\n",
      " |                  loss[n][d_1] = -input[n][c][d_1] * weight[c]\n",
      " |      \n",
      " |          loss = np.sum(loss)\n",
      " |          // print(loss)\n",
      " |          // -1.1\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 3:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          // weighted negative log likelihood loss, mean reduction\n",
      " |          N, C, d1 = 2, 3, 2\n",
      " |          input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],\n",
      " |                  [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]\n",
      " |          target = [[2, 1], [0, 2]]\n",
      " |          weight = [0.2, 0.3, 0.1]\n",
      " |          loss = np.zeros((N, d1))\n",
      " |          weight_total = 0\n",
      " |          for n in range(N):\n",
      " |              for d_1 in range(d1):\n",
      " |                  c = target[n][d_1]\n",
      " |                  loss[n][d_1] = -input[n][c][d_1] * weight[c]\n",
      " |                  weight_total = weight_total + weight[c]\n",
      " |      \n",
      " |          loss = np.sum(loss) / weight_total\n",
      " |          // print(loss)\n",
      " |          // -1.57\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of shape (N, C) or (N, C, d1, d2, ...,\n",
      " |              dk).\n",
      " |      \n",
      " |          target: (non-differentiable) Target tensor of shape (N) or (N, d1, d2, ...,\n",
      " |              dk). Target element value shall be in range of [0, C). If ignore_index\n",
      " |              is specified, it may have a value outside [0, C) and the target values\n",
      " |              should either be in the range [0, C) or have the value ignore_index.\n",
      " |      \n",
      " |          weight: (optional, non-differentiable) Optional rescaling weight tensor. If\n",
      " |              given, it has to be a tensor of size C. Otherwise, it is treated as if\n",
      " |              having all ones.\n",
      " |      \n",
      " |          ignore_index: Specifies a target value that is ignored and does not\n",
      " |              contribute to the input gradient. It's an optional value.\n",
      " |      \n",
      " |          reduction: Type of reduction to apply to loss: none, sum, mean (default).\n",
      " |              'none': the output is the loss for each sample. 'sum': the output will\n",
      " |              be summed. 'mean': the sum of the output will be divided by the sum of\n",
      " |              applied weights.\n",
      " |  \n",
      " |  NonZero(self, X: 'T_NonZero') -> 'INT64'\n",
      " |      [üåê NonZero(13)](https://onnx.ai/onnx/operators/onnx__NonZero.html#nonzero-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |          Returns the indices of the elements that are non-zero\n",
      " |          (in row-major order - by dimension).\n",
      " |          NonZero behaves similar to numpy.nonzero:\n",
      " |          https://docs.scipy.org/doc/numpy/reference/generated/numpy.nonzero.html,\n",
      " |          but for scalar input, NonZero produces output shape (0, N) instead of (1, N), which is different from Numpy's behavior.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) input\n",
      " |  \n",
      " |  QuantizeLinear(self, x: 'T1_QuantizeLinear', y_scale: 'FLOAT', y_zero_point: 'Optional[T2_QuantizeLinear]' = None, *, axis: 'int' = 1) -> 'T2_QuantizeLinear'\n",
      " |      [üåê QuantizeLinear(13)](https://onnx.ai/onnx/operators/onnx__QuantizeLinear.html#quantizelinear-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The linear quantization operator. It consumes a high precision tensor, a scale, and a zero point to compute the low precision / quantized tensor.\n",
      " |      The scale factor and zero point must have same shape, and can be either a scalar for per-tensor / per layer quantization, or a 1-D tensor for per-axis quantization.\n",
      " |      The quantization formula is y = saturate ((x / y_scale) + y_zero_point).\n",
      " |      For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\n",
      " |      For (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: N-D full precision Input tensor to be quantized.\n",
      " |      \n",
      " |          y_scale: Scale for doing quantization to get 'y'. It can be a scalar, which\n",
      " |              means per-tensor/layer quantization, or a 1-D Tensor for per-axis\n",
      " |              quantization.\n",
      " |      \n",
      " |          y_zero_point: (optional) Zero point for doing quantization to get 'y'. Shape\n",
      " |              must match y_scale. Default is uint8 with zero point of 0 if it's not\n",
      " |              specified.\n",
      " |      \n",
      " |          axis: (Optional) The axis of the quantization dimension of the input tensor.\n",
      " |              Ignored for per-tensor quantization. Negative value means counting\n",
      " |              dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |  \n",
      " |  Reciprocal(self, X: 'T_Reciprocal') -> 'T_Reciprocal'\n",
      " |      [üåê Reciprocal(13)](https://onnx.ai/onnx/operators/onnx__Reciprocal.html#reciprocal-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Reciprocal takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the reciprocal is, y = 1/x, is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  ReduceSum(self, data: 'T_ReduceSum', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceSum'\n",
      " |      [üåê ReduceSum(13)](https://onnx.ai/onnx/operators/onnx__ReduceSum.html#reducesum-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the sum of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  Sigmoid(self, X: 'T_Sigmoid') -> 'T_Sigmoid'\n",
      " |      [üåê Sigmoid(13)](https://onnx.ai/onnx/operators/onnx__Sigmoid.html#sigmoid-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Sigmoid takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\n",
      " |      tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  Sign(self, input: 'T_Sign') -> 'T_Sign'\n",
      " |      [üåê Sign(13)](https://onnx.ai/onnx/operators/onnx__Sign.html#sign-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculate the sign of the given input tensor element-wise.\n",
      " |      If input > 0, output 1. if input < 0, output -1. if input == 0, output 0.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  Size(self, data: 'T_Size') -> 'T1_Size'\n",
      " |      [üåê Size(13)](https://onnx.ai/onnx/operators/onnx__Size.html#size-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Takes a tensor as input and outputs a int64 scalar that equals to the total number of elements of the input tensor.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (non-differentiable) An input tensor.\n",
      " |  \n",
      " |  Slice(self, data: 'T_Slice', starts: 'Tind_Slice', ends: 'Tind_Slice', axes: 'Optional[Tind_Slice]' = None, steps: 'Optional[Tind_Slice]' = None) -> 'T_Slice'\n",
      " |      [üåê Slice(13)](https://onnx.ai/onnx/operators/onnx__Slice.html#slice-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Produces a slice of the input tensor along multiple axes. Similar to numpy:\n",
      " |      https://numpy.org/doc/stable/user/basics.indexing.html?highlight=slice#slicing-and-striding\n",
      " |      \n",
      " |      Slice uses the `starts`, `ends`, `axes` and `steps` inputs to select a sub-tensor\n",
      " |      of its input `data` tensor.\n",
      " |      \n",
      " |      An effective `start[i]`, `end[i]`, and `step[i]` must be computed for each `i`\n",
      " |      in `[0, ... r-1]` where `r = rank(input)` as follows:\n",
      " |      \n",
      " |      If `axes` are omitted, they are set to `[0, ..., r-1]`.\n",
      " |      If `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\n",
      " |      \n",
      " |      The effective values are initialized as `start[i] = 0`, `end[i] = dims[i]` where\n",
      " |      `dims` are the dimensions of `input` and `step[i] = `1.\n",
      " |      \n",
      " |      All negative elements of `axes` are made non-negatve by adding `r` to them, where\n",
      " |      `r =rank(input)`.\n",
      " |      \n",
      " |      All negative values in `starts[i]` and `ends[i]` have `dims[axes[i]]` added to them,\n",
      " |      where `dims` are the dimensions of `input`. Then `start[axes[i]]` is the adjusted\n",
      " |      `starts[i]` is clamped into the range `[0, dims[axes[i]]]` for positive stepping\n",
      " |      and `[0, dims[axes[i]]-1]` for negative stepping.\n",
      " |      \n",
      " |      The clamping for the adjusted `ends[i]` depends on the sign of `steps[i]` and must\n",
      " |      accommodate copying 0 through `dims[axes[i]]` elements, so for positive stepping\n",
      " |      `end[axes[i]]` is clamped to `[0, dims[axes[i]]]`, while for negative stepping it\n",
      " |      is clamped to `[-1, dims[axes[i]]-1]`.\n",
      " |      \n",
      " |      Finally, `step[axes[i]] = steps[i]`.\n",
      " |      \n",
      " |      For slicing to the end of a dimension with unknown size, it is recommended to pass\n",
      " |      in `INT_MAX` when slicing forward and 'INT_MIN' when slicing backward.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1, 2, 3, 4],\n",
      " |              [5, 6, 7, 8],\n",
      " |          ]\n",
      " |          axes = [0, 1]\n",
      " |          starts = [1, 0]\n",
      " |          ends = [2, 3]\n",
      " |          steps = [1, 2]\n",
      " |          result = [\n",
      " |              [5, 7],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1, 2, 3, 4],\n",
      " |              [5, 6, 7, 8],\n",
      " |          ]\n",
      " |          starts = [0, 1]\n",
      " |          ends = [-1, 1000]\n",
      " |          result = [\n",
      " |              [2, 3, 4],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of data to extract slices from.\n",
      " |      \n",
      " |          starts: (non-differentiable) 1-D tensor of starting indices of corresponding\n",
      " |              axis in `axes`\n",
      " |      \n",
      " |          ends: (non-differentiable) 1-D tensor of ending indices (exclusive) of\n",
      " |              corresponding axis in `axes`\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) 1-D tensor of axes that `starts` and\n",
      " |              `ends` apply to. Negative value means counting dimensions from the back.\n",
      " |              Accepted range is [-r, r-1] where r = rank(data). Behavior is undefined\n",
      " |              if an axis is repeated.\n",
      " |      \n",
      " |          steps: (optional, non-differentiable) 1-D tensor of slice step of\n",
      " |              corresponding axis in `axes`. Negative value means slicing backward.\n",
      " |              'steps' cannot be 0. Defaults to 1s.\n",
      " |  \n",
      " |  Softmax(self, input: 'T_Softmax', *, axis: 'int' = -1) -> 'T_Softmax'\n",
      " |      [üåê Softmax(13)](https://onnx.ai/onnx/operators/onnx__Softmax.html#softmax-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator computes the normalized exponential values for the given input:\n",
      " |      \n",
      " |       Softmax(input, axis) = Exp(input) / ReduceSum(Exp(input), axis=axis, keepdims=1)\n",
      " |      \n",
      " |      The \"axis\" attribute indicates the dimension along which Softmax\n",
      " |      will be performed. The output tensor has the same shape\n",
      " |      and contains the Softmax values of the corresponding input.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The input tensor of rank >= axis.\n",
      " |      \n",
      " |          axis:\n",
      " |      Describes the dimension Softmax will be performed on.\n",
      " |      Negative value\n",
      " |              means counting dimensions\n",
      " |      from the back. Accepted range is [-r, r-1]\n",
      " |              where r = rank(input).\n",
      " |  \n",
      " |  SoftmaxCrossEntropyLoss(self, scores: 'T_SoftmaxCrossEntropyLoss', labels: 'Tind_SoftmaxCrossEntropyLoss', weights: 'Optional[T_SoftmaxCrossEntropyLoss]' = None, *, ignore_index: 'Optional[int]' = None, reduction: 'str' = 'mean') -> 'Tuple[T_SoftmaxCrossEntropyLoss, T_SoftmaxCrossEntropyLoss]'\n",
      " |      [üåê SoftmaxCrossEntropyLoss(13)](https://onnx.ai/onnx/operators/onnx__SoftmaxCrossEntropyLoss.html#softmaxcrossentropyloss-13 \"Online Documentation\")\n",
      " |      \n",
      " |      Loss function that measures the softmax cross entropy\n",
      " |      between 'scores' and 'labels'.\n",
      " |      This operator first computes a loss tensor whose shape is identical to the labels input.\n",
      " |      If the input is 2-D with shape (N, C), the loss tensor may be a N-element vector L = (l_1, l_2, ..., l_N).\n",
      " |      If the input is N-D tensor with shape (N, C, D1, D2, ..., Dk),\n",
      " |      the loss tensor L may have (N, D1, D2, ..., Dk) as its shape and L[i,][j_1][j_2]...[j_k] denotes a scalar element in L.\n",
      " |      After L is available, this operator can optionally do a reduction operator.\n",
      " |      \n",
      " |      * shape(scores): (N, C) where C is the number of classes, or (N, C, D1, D2,..., Dk),\n",
      " |        with K >= 1 in case of K-dimensional loss.\n",
      " |      * shape(labels): (N) where each value is 0 <= labels[i] <= C-1, or (N, D1, D2,..., Dk),\n",
      " |        with K >= 1 in case of K-dimensional loss.\n",
      " |      \n",
      " |      The loss for one sample, l_i, can caculated as follows:\n",
      " |      ::\n",
      " |      \n",
      " |          l[i][d1][d2]...[dk] = -y[i][c][d1][d2]..[dk], where i is the index of classes.\n",
      " |      \n",
      " |      \n",
      " |      or\n",
      " |      ::\n",
      " |      \n",
      " |          l[i][d1][d2]...[dk] = -y[i][c][d1][d2]..[dk] * weights[c], if 'weights' is provided.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      loss is zero for the case when label-value equals ignore_index.\n",
      " |      ::\n",
      " |      \n",
      " |          l[i][d1][d2]...[dk]  = 0, when labels[n][d1][d2]...[dk] = ignore_index\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      where:\n",
      " |      ::\n",
      " |      \n",
      " |          p = Softmax(scores)\n",
      " |          y = Log(p)\n",
      " |          c = labels[i][d1][d2]...[dk]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Finally, L is optionally reduced:\n",
      " |      \n",
      " |      * If reduction = 'none', the output is L with shape (N, D1, D2, ..., Dk).\n",
      " |      * If reduction = 'sum', the output is scalar: Sum(L).\n",
      " |      * If reduction = 'mean', the output is scalar: ReduceMean(L), or if weight is provided: `ReduceSum(L) / ReduceSum(W)`,\n",
      " |        where tensor W is of shape `(N, D1, D2, ..., Dk)` and `W[n][d1][d2]...[dk] = weights[labels[i][d1][d2]...[dk]]`.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          scores: (differentiable) The predicted outputs with shape [batch_size,\n",
      " |              class_size], or [batch_size, class_size, D1, D2 , ..., Dk], where K is\n",
      " |              the number of dimensions.\n",
      " |      \n",
      " |          labels: (non-differentiable) The ground truth output tensor, with shape\n",
      " |              [batch_size], or [batch_size, D1, D2, ..., Dk], where K is the number of\n",
      " |              dimensions. Labels element value shall be in range of [0, C). If\n",
      " |              ignore_index is specified, it may have a value outside [0, C) and the\n",
      " |              label values should either be in the range [0, C) or have the value\n",
      " |              ignore_index.\n",
      " |      \n",
      " |          weights: (optional, non-differentiable) A manual rescaling weight given to\n",
      " |              each class. If given, it has to be a 1D Tensor assigning weight to each\n",
      " |              of the classes. Otherwise, it is treated as if having all ones.\n",
      " |      \n",
      " |          ignore_index: Specifies a target value that is ignored and does not\n",
      " |              contribute to the input gradient. It's an optional value.\n",
      " |      \n",
      " |          reduction: Type of reduction to apply to loss: none, sum, mean(default).\n",
      " |              'none': no reduction will be applied, 'sum': the output will be summed.\n",
      " |              'mean': the sum of the output will be divided by the number of elements\n",
      " |              in the output.\n",
      " |  \n",
      " |  SpaceToDepth(self, input: 'T_SpaceToDepth', *, blocksize: 'int') -> 'T_SpaceToDepth'\n",
      " |      [üåê SpaceToDepth(13)](https://onnx.ai/onnx/operators/onnx__SpaceToDepth.html#spacetodepth-13 \"Online Documentation\")\n",
      " |      \n",
      " |      SpaceToDepth rearranges blocks of spatial data into depth. More specifically,\n",
      " |      this op outputs a copy of the input tensor where values from the height and width dimensions\n",
      " |      are moved to the depth dimension.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of [N,C,H,W], where N is the batch\n",
      " |              axis, C is the channel or depth, H is the height and W is the width.\n",
      " |      \n",
      " |          blocksize: Blocks of [blocksize, blocksize] are moved.\n",
      " |  \n",
      " |  Sqrt(self, X: 'T_Sqrt') -> 'T_Sqrt'\n",
      " |      [üåê Sqrt(13)](https://onnx.ai/onnx/operators/onnx__Sqrt.html#sqrt-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Square root takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the square root is, y = x^0.5, is applied to\n",
      " |      the tensor elementwise. If x is negative, then it will return NaN.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  Squeeze(self, data: 'T_Squeeze', axes: 'Optional[INT64]' = None) -> 'T_Squeeze'\n",
      " |      [üåê Squeeze(13)](https://onnx.ai/onnx/operators/onnx__Squeeze.html#squeeze-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Remove single-dimensional entries from the shape of a tensor.\n",
      " |      Takes an input `axes` with a list of axes to squeeze.\n",
      " |      If `axes` is not provided, all the single dimensions will be removed from\n",
      " |      the shape. If an axis is selected with shape entry not equal to one, an error is raised.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensors with at least max(dims) dimensions.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) List of integers indicating the\n",
      " |              dimensions to squeeze. Negative value means counting dimensions from the\n",
      " |              back. Accepted range is [-r, r-1] where r = rank(data).\n",
      " |  \n",
      " |  Sum(self, *data_0: 'T_Sum') -> 'T_Sum'\n",
      " |      [üåê Sum(13)](https://onnx.ai/onnx/operators/onnx__Sum.html#sum-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Element-wise sum of each of the input tensors (with Numpy-style broadcasting support).\n",
      " |      All inputs and outputs must have the same data type.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data_0: (variadic, differentiable) List of tensors for sum.\n",
      " |  \n",
      " |  Tanh(self, input: 'T_Tanh') -> 'T_Tanh'\n",
      " |      [üåê Tanh(13)](https://onnx.ai/onnx/operators/onnx__Tanh.html#tanh-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic tangent of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Tile(self, input: 'T_Tile', repeats: 'T1_Tile') -> 'T_Tile'\n",
      " |      [üåê Tile(13)](https://onnx.ai/onnx/operators/onnx__Tile.html#tile-13 \"Online Documentation\")\n",
      " |      \n",
      " |      Constructs a tensor by tiling a given tensor.\n",
      " |      This is the same as function `tile` in Numpy, but no broadcast.\n",
      " |      For example A = [[1, 2], [3, 4]], B = [1, 2], tile(A, B) = [[1, 2, 1, 2], [3, 4, 3, 4]]\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of any shape.\n",
      " |      \n",
      " |          repeats: (non-differentiable) 1D int64 tensor of the same length as input's\n",
      " |              dimension number, includes numbers of repeated copies along input's\n",
      " |              dimensions.\n",
      " |  \n",
      " |  Transpose(self, data: 'T_Transpose', *, perm: 'Optional[Sequence[int]]' = None) -> 'T_Transpose'\n",
      " |      [üåê Transpose(13)](https://onnx.ai/onnx/operators/onnx__Transpose.html#transpose-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Transpose the input tensor similar to numpy.transpose. For example, when\n",
      " |      perm=(1, 0, 2), given an input tensor of shape (1, 2, 3), the output shape\n",
      " |      will be (2, 1, 3).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          perm: A list of integers. By default, reverse the dimensions, otherwise\n",
      " |              permute the axes according to the values given.\n",
      " |  \n",
      " |  Unsqueeze(self, data: 'T_Unsqueeze', axes: 'INT64') -> 'T_Unsqueeze'\n",
      " |      [üåê Unsqueeze(13)](https://onnx.ai/onnx/operators/onnx__Unsqueeze.html#unsqueeze-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Insert single-dimensional entries to the shape of an input tensor (`data`).\n",
      " |      Takes one required input `axes` - which contains a list of dimension indices and this operator will insert a dimension of value `1` into the corresponding index of the output tensor (`expanded`).\n",
      " |      \n",
      " |      For example, given an input tensor (`data`) of shape [3, 4, 5], then\n",
      " |      Unsqueeze(data, axes=[0, 4]) outputs a tensor (`expanded`) containing same data as `data` but with shape [1, 3, 4, 5, 1].\n",
      " |      \n",
      " |      The input `axes` should not contain any duplicate entries. It is an error if it contains duplicates.\n",
      " |      The rank of the output tensor (`output_rank`) is the rank of the input tensor (`data`) plus the number of values in `axes`.\n",
      " |      Each value in `axes` should be within the (inclusive) range [-output_rank , output_rank - 1].\n",
      " |      The order of values in `axes` does not matter and can come in any order.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Original tensor\n",
      " |      \n",
      " |          axes: (non-differentiable) List of integers indicating the dimensions to be\n",
      " |              inserted. Negative value means counting dimensions from the back.\n",
      " |              Accepted range is [-r, r-1] where r = rank(expanded).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset13.Opset13:\n",
      " |  \n",
      " |  T1_Cast = ~T1_Cast\n",
      " |  \n",
      " |  T1_Dropout = ~T1_Dropout\n",
      " |  \n",
      " |  T1_Equal = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_Greater = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_IsNaN = ~T1_IsNaN\n",
      " |  \n",
      " |  T1_Less = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_QuantizeLinear = ~T1_QuantizeLinear\n",
      " |  \n",
      " |  T1_Size = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T1_Tile = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T2_Cast = typing.Union[onnxscript.onnx_types.BFLOAT16, onn...t.onnx_ty...\n",
      " |  \n",
      " |  T2_Dropout = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T2_IsNaN = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T2_QuantizeLinear = ~T2_QuantizeLinear\n",
      " |  \n",
      " |  T_Abs = ~T_Abs\n",
      " |  \n",
      " |  T_ArgMax = ~T_ArgMax\n",
      " |  \n",
      " |  T_ArgMin = ~T_ArgMin\n",
      " |  \n",
      " |  T_Ceil = ~T_Ceil\n",
      " |  \n",
      " |  T_Clip = ~T_Clip\n",
      " |  \n",
      " |  T_Concat = ~T_Concat\n",
      " |  \n",
      " |  T_Constant = typing.Union[onnxscript.onnx_types.BFLOAT16, onn...t.onnx...\n",
      " |  \n",
      " |  T_DepthToSpace = ~T_DepthToSpace\n",
      " |  \n",
      " |  T_DequantizeLinear = ~T_DequantizeLinear\n",
      " |  \n",
      " |  T_Dropout = ~T_Dropout\n",
      " |  \n",
      " |  T_Equal = ~T_Equal\n",
      " |  \n",
      " |  T_Erf = ~T_Erf\n",
      " |  \n",
      " |  T_Exp = ~T_Exp\n",
      " |  \n",
      " |  T_Expand = ~T_Expand\n",
      " |  \n",
      " |  T_Flatten = ~T_Flatten\n",
      " |  \n",
      " |  T_Floor = ~T_Floor\n",
      " |  \n",
      " |  T_Gather = ~T_Gather\n",
      " |  \n",
      " |  T_GatherElements = ~T_GatherElements\n",
      " |  \n",
      " |  T_GatherND = ~T_GatherND\n",
      " |  \n",
      " |  T_Gemm = ~T_Gemm\n",
      " |  \n",
      " |  T_Greater = ~T_Greater\n",
      " |  \n",
      " |  T_Hardmax = ~T_Hardmax\n",
      " |  \n",
      " |  T_Identity = ~T_Identity\n",
      " |  \n",
      " |  T_LRN = ~T_LRN\n",
      " |  \n",
      " |  T_Less = ~T_Less\n",
      " |  \n",
      " |  T_Log = ~T_Log\n",
      " |  \n",
      " |  T_LogSoftmax = ~T_LogSoftmax\n",
      " |  \n",
      " |  T_MatMul = ~T_MatMul\n",
      " |  \n",
      " |  T_Max = ~T_Max\n",
      " |  \n",
      " |  T_Mean = ~T_Mean\n",
      " |  \n",
      " |  T_MeanVarianceNormalization = ~T_MeanVarianceNormalization\n",
      " |  \n",
      " |  T_Min = ~T_Min\n",
      " |  \n",
      " |  T_Mod = ~T_Mod\n",
      " |  \n",
      " |  T_Neg = ~T_Neg\n",
      " |  \n",
      " |  T_NegativeLogLikelihoodLoss = ~T_NegativeLogLikelihoodLoss\n",
      " |  \n",
      " |  T_NonZero = ~T_NonZero\n",
      " |  \n",
      " |  T_Reciprocal = ~T_Reciprocal\n",
      " |  \n",
      " |  T_ReduceSum = ~T_ReduceSum\n",
      " |  \n",
      " |  T_Sigmoid = ~T_Sigmoid\n",
      " |  \n",
      " |  T_Sign = ~T_Sign\n",
      " |  \n",
      " |  T_Size = ~T_Size\n",
      " |  \n",
      " |  T_Slice = ~T_Slice\n",
      " |  \n",
      " |  T_Softmax = ~T_Softmax\n",
      " |  \n",
      " |  T_SoftmaxCrossEntropyLoss = ~T_SoftmaxCrossEntropyLoss\n",
      " |  \n",
      " |  T_SpaceToDepth = ~T_SpaceToDepth\n",
      " |  \n",
      " |  T_Sqrt = ~T_Sqrt\n",
      " |  \n",
      " |  T_Squeeze = ~T_Squeeze\n",
      " |  \n",
      " |  T_Sum = ~T_Sum\n",
      " |  \n",
      " |  T_Tanh = ~T_Tanh\n",
      " |  \n",
      " |  T_Tile = ~T_Tile\n",
      " |  \n",
      " |  T_Transpose = ~T_Transpose\n",
      " |  \n",
      " |  T_Unsqueeze = ~T_Unsqueeze\n",
      " |  \n",
      " |  Tind_Gather = ~Tind_Gather\n",
      " |  \n",
      " |  Tind_GatherElements = ~Tind_GatherElements\n",
      " |  \n",
      " |  Tind_NegativeLogLikelihoodLoss = ~Tind_NegativeLogLikelihoodLoss\n",
      " |  \n",
      " |  Tind_Slice = ~Tind_Slice\n",
      " |  \n",
      " |  Tind_SoftmaxCrossEntropyLoss = ~Tind_SoftmaxCrossEntropyLoss\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset12.Opset12:\n",
      " |  \n",
      " |  Celu(self, X: 'T_Celu', *, alpha: 'float' = 1.0) -> 'T_Celu'\n",
      " |      [üåê Celu(12)](https://onnx.ai/onnx/operators/onnx__Celu.html#celu-12 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Continuously Differentiable Exponential Linear Units:\n",
      " |      Perform the linear unit element-wise on the input tensor X\n",
      " |      using formula:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          max(0,x) + min(0,alpha*(exp(x/alpha)-1))\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: The Alpha value in Celu formula which control the shape of the unit.\n",
      " |              The default value is 1.0.\n",
      " |  \n",
      " |  Einsum(self, *Inputs: 'T_Einsum', equation: 'str') -> 'T_Einsum'\n",
      " |      [üåê Einsum(12)](https://onnx.ai/onnx/operators/onnx__Einsum.html#einsum-12 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      An einsum of the form `term1, term2 -> output-term` produces an output tensor using the following equation\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          output[output-term] = reduce-sum( input1[term1] * input2[term] )\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      where the reduce-sum performs a summation over all the indices occurring in the input terms (term1, term2)\n",
      " |      that do not occur in the output-term.\n",
      " |      \n",
      " |      The Einsum operator evaluates algebraic tensor operations on a sequence of tensors, using the Einstein summation\n",
      " |      convention. The equation string contains a comma-separated sequence of lower case letters. Each term corresponds to\n",
      " |      an operand tensor, and the characters within the terms correspond to operands dimensions.\n",
      " |      \n",
      " |      This sequence may be followed by \"->\" to separate the left and right hand side of the equation.\n",
      " |      If the equation contains \"->\" followed by the right-hand side, the explicit (not classical) form of the Einstein\n",
      " |      summation is performed, and the right-hand side indices indicate output tensor dimensions. In other cases,\n",
      " |      output indices are (implicitly) set to the alphabetically sorted sequence of indices appearing exactly once in the\n",
      " |      equation.\n",
      " |      \n",
      " |      When a dimension character is repeated in the left-hand side, it represents summation along the dimension.\n",
      " |      \n",
      " |      The equation may contain ellipsis (\"...\") to enable broadcasting. Ellipsis must indicate a fixed number of dimensions.\n",
      " |      Specifically, every occurrence of ellipsis in the equation must represent the same number of dimensions.\n",
      " |      The right-hand side may contain exactly one ellipsis. In implicit mode, the ellipsis dimensions are set to the\n",
      " |      beginning of the output. The equation string may contain space (U+0020) character.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          Inputs: (variadic, differentiable) Operands\n",
      " |      \n",
      " |          equation: Einsum expression string.\n",
      " |  \n",
      " |  MaxPool(self, X: 'T_MaxPool', *, auto_pad: 'str' = 'NOTSET', ceil_mode: 'int' = 0, dilations: 'Optional[Sequence[int]]' = None, kernel_shape: 'Sequence[int]', pads: 'Optional[Sequence[int]]' = None, storage_order: 'int' = 0, strides: 'Optional[Sequence[int]]' = None) -> 'Tuple[T_MaxPool, I_MaxPool]'\n",
      " |      [üåê MaxPool(12)](https://onnx.ai/onnx/operators/onnx__MaxPool.html#maxpool-12 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       MaxPool consumes an input tensor X and applies max pooling across\n",
      " |       the tensor according to kernel sizes, stride sizes, and pad lengths.\n",
      " |       max pooling consisting of computing the max on all values of a\n",
      " |       subset of the input tensor according to the kernel size and downsampling the\n",
      " |       data into the output tensor Y for further processing. The output spatial shape will be following:\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       or\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       if ceil_mode is enabled `pad_shape[i]` is the sum of pads along axis `i`.\n",
      " |      \n",
      " |       `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n",
      " |       ```\n",
      " |       VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n",
      " |       SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n",
      " |       ```\n",
      " |       And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n",
      " |       ```\n",
      " |       pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n",
      " |       ```\n",
      " |       The output of each pooling window is maximum number of elements exclude pad.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size. Optionally, if dimension\n",
      " |              denotation is in effect, the operation expects the input data tensor to\n",
      " |              arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL,\n",
      " |              DATA_FEATURE, DATA_FEATURE ...].\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          ceil_mode: Whether to use ceil or floor (default) to compute the output\n",
      " |              shape.\n",
      " |      \n",
      " |          dilations: Dilation value along each spatial axis of filter. If not present,\n",
      " |              the dilation defaults to 1 along each spatial axis.\n",
      " |      \n",
      " |          kernel_shape: The size of the kernel along each axis.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          storage_order: The storage order of the tensor. 0 is row major, and 1 is\n",
      " |              column major. This attribute is used only to convert an n-tuple index\n",
      " |              value into a single integer value for producing the second output.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset12.Opset12:\n",
      " |  \n",
      " |  I_MaxPool = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T_Celu = <class 'onnxscript.onnx_types.FLOAT'>\n",
      " |  \n",
      " |  T_Einsum = ~T_Einsum\n",
      " |  \n",
      " |  T_MaxPool = ~T_MaxPool\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset11.Opset11:\n",
      " |  \n",
      " |  AveragePool(self, X: 'T_AveragePool', *, auto_pad: 'str' = 'NOTSET', ceil_mode: 'int' = 0, count_include_pad: 'int' = 0, kernel_shape: 'Sequence[int]', pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_AveragePool'\n",
      " |      [üåê AveragePool(11)](https://onnx.ai/onnx/operators/onnx__AveragePool.html#averagepool-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       AveragePool consumes an input tensor X and applies average pooling across\n",
      " |       the tensor according to kernel sizes, stride sizes, and pad lengths.\n",
      " |       average pooling consisting of computing the average on all values of a\n",
      " |       subset of the input tensor according to the kernel size and downsampling the\n",
      " |       data into the output tensor Y for further processing. The output spatial shape will be following:\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       or\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       if ceil_mode is enabled\n",
      " |      \n",
      " |       ```\n",
      " |       * pad_shape[i] is sum of pads along axis i\n",
      " |       ```\n",
      " |      \n",
      " |       `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n",
      " |       ```\n",
      " |       VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n",
      " |       SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n",
      " |       ```\n",
      " |       And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n",
      " |       ```\n",
      " |       pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n",
      " |       ```\n",
      " |       The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size. Optionally, if dimension\n",
      " |              denotation is in effect, the operation expects the input data tensor to\n",
      " |              arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL,\n",
      " |              DATA_FEATURE, DATA_FEATURE ...].\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          ceil_mode: Whether to use ceil or floor (default) to compute the output\n",
      " |              shape.\n",
      " |      \n",
      " |          count_include_pad: Whether include pad pixels when calculating values for\n",
      " |              the edges. Default is 0, doesn't count include pad.\n",
      " |      \n",
      " |          kernel_shape: The size of the kernel along each axis.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  BitShift(self, X: 'T_BitShift', Y: 'T_BitShift', *, direction: 'str') -> 'T_BitShift'\n",
      " |      [üåê BitShift(11)](https://onnx.ai/onnx/operators/onnx__BitShift.html#bitshift-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Bitwise shift operator performs element-wise operation. For each input element, if the\n",
      " |      attribute \"direction\" is \"RIGHT\", this operator moves its binary representation toward\n",
      " |      the right side so that the input value is effectively decreased. If the attribute \"direction\"\n",
      " |      is \"LEFT\", bits of binary representation moves toward the left side, which results the\n",
      " |      increase of its actual value. The input X is the tensor to be shifted and another input\n",
      " |      Y specifies the amounts of shifting. For example, if \"direction\" is \"Right\", X is [1, 4],\n",
      " |      and S is [1, 1], the corresponding output Z would be [0, 2]. If \"direction\" is \"LEFT\" with\n",
      " |      X=[1, 2] and S=[1, 2], the corresponding output Y would be [2, 8].\n",
      " |      \n",
      " |      Because this operator supports Numpy-style broadcasting, X's and Y's shapes are\n",
      " |      not necessarily identical.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) First operand, input to be shifted.\n",
      " |      \n",
      " |          Y: (non-differentiable) Second operand, amounts of shift.\n",
      " |      \n",
      " |          direction: Direction of moving bits. It can be either \"RIGHT\" (for right\n",
      " |              shift) or \"LEFT\" (for left shift).\n",
      " |  \n",
      " |  Compress(self, input: 'T_Compress', condition: 'T1_Compress', *, axis: 'Optional[int]' = None) -> 'T_Compress'\n",
      " |      [üåê Compress(11)](https://onnx.ai/onnx/operators/onnx__Compress.html#compress-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |          Selects slices from an input tensor along a given axis where condition evaluates to True for each axis index.\n",
      " |          In case axis is not provided, input is flattened before elements are selected.\n",
      " |          Compress behaves like numpy.compress: https://docs.scipy.org/doc/numpy/reference/generated/numpy.compress.html\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          condition: (non-differentiable) Rank 1 tensor of booleans to indicate which\n",
      " |              slices or data elements to be selected. Its length can be less than the\n",
      " |              input length along the axis or the flattened input size if axis is not\n",
      " |              specified. In such cases data slices or elements exceeding the condition\n",
      " |              length are discarded.\n",
      " |      \n",
      " |          axis: (Optional) Axis along which to take slices. If not specified, input is\n",
      " |              flattened before elements being selected. Negative value means counting\n",
      " |              dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |  \n",
      " |  ConcatFromSequence(self, input_sequence: 'S_ConcatFromSequence', *, axis: 'int', new_axis: 'int' = 0) -> 'T_ConcatFromSequence'\n",
      " |      [üåê ConcatFromSequence(11)](https://onnx.ai/onnx/operators/onnx__ConcatFromSequence.html#concatfromsequence-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Concatenate a sequence of tensors into a single tensor.\n",
      " |      All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.\n",
      " |      By default 'new_axis' is 0, the behavior is similar to numpy.concatenate.\n",
      " |      When 'new_axis' is 1, the behavior is similar to numpy.stack.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Sequence of tensors for concatenation\n",
      " |      \n",
      " |          axis: Which axis to concat on. Accepted range in `[-r, r - 1]`, where `r` is\n",
      " |              the rank of input tensors. When `new_axis` is 1, accepted range is `[-r\n",
      " |              - 1, r]`.\n",
      " |      \n",
      " |          new_axis: Insert and concatenate on a new axis or not, default 0 means do\n",
      " |              not insert new axis.\n",
      " |  \n",
      " |  Conv(self, X: 'T_Conv', W: 'T_Conv', B: 'Optional[T_Conv]' = None, *, auto_pad: 'str' = 'NOTSET', dilations: 'Optional[Sequence[int]]' = None, group: 'int' = 1, kernel_shape: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_Conv'\n",
      " |      [üåê Conv(11)](https://onnx.ai/onnx/operators/onnx__Conv.html#conv-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The convolution operator consumes an input tensor and a filter, and\n",
      " |      computes the output.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from previous layer; has size (N x C x\n",
      " |              H x W), where N is the batch size, C is the number of channels, and H\n",
      " |              and W are the height and width. Note that this is for the 2D image.\n",
      " |              Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if\n",
      " |              dimension denotation is in effect, the operation expects input data\n",
      " |              tensor to arrive with the dimension denotation of [DATA_BATCH,\n",
      " |              DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor that will be used in the convolutions;\n",
      " |              has size (M x C/group x kH x kW), where C is the number of channels, and\n",
      " |              kH and kW are the height and width of the kernel, and M is the number of\n",
      " |              feature maps. For more than 2 dimensions, the kernel shape will be (M x\n",
      " |              C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension\n",
      " |              of the kernel. Optionally, if dimension denotation is in effect, the\n",
      " |              operation expects the weight tensor to arrive with the dimension\n",
      " |              denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL,\n",
      " |              FILTER_SPATIAL ...]. Assuming zero based indices for the shape array,\n",
      " |              X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in\n",
      " |              other words FILTER_IN_CHANNEL multiplied by the number of groups should\n",
      " |              be equal to DATA_CHANNEL and the number of feature maps M should be a\n",
      " |              multiple of the number of groups G.\n",
      " |      \n",
      " |          B: (optional, differentiable) Optional 1D bias to be added to the\n",
      " |              convolution, has size of M.\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults is 1 along each spatial axis.\n",
      " |      \n",
      " |          group: number of groups input channels and output channels are divided into.\n",
      " |      \n",
      " |          kernel_shape: The shape of the convolution kernel. If not present, should be\n",
      " |              inferred from input W.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              is 1 along each spatial axis.\n",
      " |  \n",
      " |  ConvTranspose(self, X: 'T_ConvTranspose', W: 'T_ConvTranspose', B: 'Optional[T_ConvTranspose]' = None, *, auto_pad: 'str' = 'NOTSET', dilations: 'Optional[Sequence[int]]' = None, group: 'int' = 1, kernel_shape: 'Optional[Sequence[int]]' = None, output_padding: 'Optional[Sequence[int]]' = None, output_shape: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_ConvTranspose'\n",
      " |      [üåê ConvTranspose(11)](https://onnx.ai/onnx/operators/onnx__ConvTranspose.html#convtranspose-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The convolution transpose operator consumes an input tensor and a filter,\n",
      " |      and computes the output.\n",
      " |      \n",
      " |      If the pads parameter is provided the shape of the output is calculated via the following equation:\n",
      " |      \n",
      " |        output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]\n",
      " |      \n",
      " |      output_shape can also be explicitly specified in which case pads values are auto generated using these equations:\n",
      " |      \n",
      " |        total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]\n",
      " |        If (auto_pads == SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)\n",
      " |        Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from previous layer; has size (N x C x\n",
      " |              H x W), where N is the batch size, C is the number of channels, and H\n",
      " |              and W are the height and width. Note that this is for the 2D image.\n",
      " |              Otherwise the size is (N x C x D1 x D2 ... x Dn)\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor that will be used in the convolutions;\n",
      " |              has size (C x M/group x kH x kW), where C is the number of channels, and\n",
      " |              kH and kW are the height and width of the kernel, and M is the number of\n",
      " |              feature maps. For more than 2 dimensions, the weight shape will be (C x\n",
      " |              M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the\n",
      " |              dimension of the kernel. The number of channels in the output should be\n",
      " |              equal to W.shape[1] * group (assuming zero based indices of the shape\n",
      " |              array)\n",
      " |      \n",
      " |          B: (optional, differentiable) Optional 1D bias to be added to the\n",
      " |              convolution, has size of M.\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              input_shape[i] * strides[i]` for each axis `i`. The padding is split\n",
      " |              between the two sides equally or almost equally (depending on whether it\n",
      " |              is even or odd). In case the padding is an odd number, the extra padding\n",
      " |              is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults to 1 along each spatial axis.\n",
      " |      \n",
      " |          group: number of groups input channels and output channels are divided into.\n",
      " |      \n",
      " |          kernel_shape: The shape of the convolution kernel. If not present, should be\n",
      " |              inferred from input W.\n",
      " |      \n",
      " |          output_padding: Additional elements added to the side with higher coordinate\n",
      " |              indices in the output. Each padding value in \"output_padding\" must be\n",
      " |              less than the corresponding stride/dilation dimension. By default, this\n",
      " |              attribute is a zero vector. Note that this attribute doesn't directly\n",
      " |              affect the computed output values. It only controls the selection of the\n",
      " |              computed values, so changing this attribute only adds or removes output\n",
      " |              elements. If \"output_shape\" is explicitly provided, \"output_padding\"\n",
      " |              does not contribute additional size to \"output_shape\" but participates\n",
      " |              in the computation of the needed padding amount. This is also called\n",
      " |              adjs or adjustment in some frameworks.\n",
      " |      \n",
      " |          output_shape: The shape of the output can be explicitly set which will cause\n",
      " |              pads values to be auto generated. If output_shape is specified pads\n",
      " |              values are ignored. See doc for details for equations to generate pads\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  Det(self, X: 'T_Det') -> 'T_Det'\n",
      " |      [üåê Det(11)](https://onnx.ai/onnx/operators/onnx__Det.html#det-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Det calculates determinant of a square matrix or batches of square matrices.\n",
      " |      Det takes one input tensor of shape `[*, M, M]`, where `*` is zero or more batch dimensions,\n",
      " |      and the inner-most 2 dimensions form square matrices.\n",
      " |      The output is a tensor of shape `[*]`, containing the determinants of all input submatrices.\n",
      " |      e.g., When the input is 2-D, the output is a scalar(shape is empty: `[]`).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  DynamicQuantizeLinear(self, x: 'T1_DynamicQuantizeLinear') -> 'Tuple[T2_DynamicQuantizeLinear, FLOAT, T2_DynamicQuantizeLinear]'\n",
      " |      [üåê DynamicQuantizeLinear(11)](https://onnx.ai/onnx/operators/onnx__DynamicQuantizeLinear.html#dynamicquantizelinear-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      A Function to fuse calculation for Scale, Zero Point and FP32->8Bit convertion of FP32 Input data.\n",
      " |      Outputs Scale, ZeroPoint and Quantized Input for a given FP32 Input.\n",
      " |      Scale is calculated as:\n",
      " |      ::\n",
      " |      \n",
      " |          y_scale = (max(x) - min(x))/(qmax - qmin)\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      * where qmax and qmin are max and min values for quantization range .i.e [0, 255] in case of uint8\n",
      " |      * data range is adjusted to include 0.\n",
      " |      \n",
      " |      Zero point is calculated as:\n",
      " |      ::\n",
      " |      \n",
      " |          intermediate_zero_point = qmin - min(x)/y_scale\n",
      " |          y_zero_point = cast(round(saturate(itermediate_zero_point)))\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      * where qmax and qmin are max and min values for quantization range .i.e [0, 255] in case of uint8\n",
      " |      * for saturation, it saturates to [0, 255] if it's uint8, or [-127, 127] if it's int8. Right now only uint8 is supported.\n",
      " |      * rounding to nearest ties to even.\n",
      " |      \n",
      " |      Data quantization formula is:\n",
      " |      ::\n",
      " |      \n",
      " |          y = saturate (round (x / y_scale) + y_zero_point)\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      * for saturation, it saturates to [0, 255] if it's uint8, or [-127, 127] if it's int8. Right now only uint8 is supported.\n",
      " |      * rounding to nearest ties to even.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input tensor\n",
      " |  \n",
      " |  MaxUnpool(self, X: 'T1_MaxUnpool', I: 'T2_MaxUnpool', output_shape: 'Optional[T2_MaxUnpool]' = None, *, kernel_shape: 'Sequence[int]', pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T1_MaxUnpool'\n",
      " |      [üåê MaxUnpool(11)](https://onnx.ai/onnx/operators/onnx__MaxUnpool.html#maxunpool-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      MaxUnpool essentially computes the partial inverse of the MaxPool op.\n",
      " |       The input information to this op is typically the output information from a MaxPool op. The first\n",
      " |       input tensor X is the tensor that needs to be unpooled, which is typically the pooled tensor (first output)\n",
      " |       from MaxPool. The second input tensor, I, contains the indices to the (locally maximal) elements corrsponding\n",
      " |       to the elements in the first input tensor X. Input tensor I is typically the second output of the MaxPool op.\n",
      " |       The third (optional) input is a tensor that specifies the output size of the unpooling operation.\n",
      " |      \n",
      " |      MaxUnpool is intended to do 'partial' inverse of the MaxPool op. 'Partial' because all the non-maximal\n",
      " |       values from the original input to MaxPool are set to zero in the output of the MaxUnpool op. Pooling\n",
      " |       the result of an unpooling operation should give back the original input to the unpooling op.\n",
      " |      \n",
      " |      MaxUnpool can produce the same output size for several input sizes, which makes unpooling op ambiguous.\n",
      " |       The third input argument, output_size, is meant to disambiguate the op and produce output tensor of\n",
      " |       known/predictable size.\n",
      " |      \n",
      " |      In addition to the inputs, MaxUnpool takes three attributes, namely kernel_shape, strides, and pads,\n",
      " |       which define the exact unpooling op. The attributes typically have the same values as the corrsponding\n",
      " |       pooling op that the unpooling op is trying to invert.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor that has to be unpooled. This tensor\n",
      " |              is typically the first output of the MaxPool op.Dimensions for image\n",
      " |              case are (N x C x H x W), where N is the batch size, C is the number of\n",
      " |              channels, and H and W are the height and the width of the data. For\n",
      " |              non-image case, the dimensions are in the form of (N x C x D1 x D2 ...\n",
      " |              Dn), where N is the batch size. Optionally, if dimension denotation is\n",
      " |              in effect, the operation expects the input data tensor to arrive with\n",
      " |              the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE,\n",
      " |              DATA_FEATURE ...].\n",
      " |      \n",
      " |          I: (non-differentiable) Input data tensor containing the indices\n",
      " |              corresponding to elements in the first input tensor X.This tensor is\n",
      " |              typically the second output of the MaxPool op.Dimensions must be the\n",
      " |              same as input tensor X. The indices are linear, i.e. computed\n",
      " |              considering the tensor as flattened 1-D tensor, assuming row-major\n",
      " |              storage. Also, the linear indices should not consider padding. So the\n",
      " |              values in indices are in the range [0, N x C x D1 x ... x Dn).\n",
      " |      \n",
      " |          output_shape: (optional, non-differentiable) The shape of the output can be\n",
      " |              explicitly set which will cause pads values to be auto generated. If\n",
      " |              'output_shape' is specified, 'pads' values are ignored.\n",
      " |      \n",
      " |          kernel_shape: The size of the kernel along each axis.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  NonMaxSuppression(self, boxes: 'FLOAT', scores: 'FLOAT', max_output_boxes_per_class: 'Optional[INT64]' = None, iou_threshold: 'Optional[FLOAT]' = None, score_threshold: 'Optional[FLOAT]' = None, *, center_point_box: 'int' = 0) -> 'INT64'\n",
      " |      [üåê NonMaxSuppression(11)](https://onnx.ai/onnx/operators/onnx__NonMaxSuppression.html#nonmaxsuppression-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Filter out boxes that have high intersection-over-union (IOU) overlap with previously selected boxes.\n",
      " |      Bounding boxes with score less than score_threshold are removed. Bounding box format is indicated by attribute center_point_box.\n",
      " |      Note that this algorithm is agnostic to where the origin is in the coordinate system and more generally is invariant to\n",
      " |      orthogonal transformations and translations of the coordinate system; thus translating or reflections of the coordinate system\n",
      " |      result in the same boxes being selected by the algorithm.\n",
      " |      The selected_indices output is a set of integers indexing into the input collection of bounding boxes representing the selected boxes.\n",
      " |      The bounding box coordinates corresponding to the selected indices can then be obtained using the Gather or GatherND operation.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          boxes: An input tensor with shape [num_batches, spatial_dimension, 4]. The\n",
      " |              single box data format is indicated by center_point_box.\n",
      " |      \n",
      " |          scores: An input tensor with shape [num_batches, num_classes,\n",
      " |              spatial_dimension]\n",
      " |      \n",
      " |          max_output_boxes_per_class: (optional) Integer representing the maximum\n",
      " |              number of boxes to be selected per batch per class. It is a scalar.\n",
      " |              Default to 0, which means no output.\n",
      " |      \n",
      " |          iou_threshold: (optional) Float representing the threshold for deciding\n",
      " |              whether boxes overlap too much with respect to IOU. It is scalar. Value\n",
      " |              range [0, 1]. Default to 0.\n",
      " |      \n",
      " |          score_threshold: (optional) Float representing the threshold for deciding\n",
      " |              when to remove boxes based on score. It is a scalar.\n",
      " |      \n",
      " |          center_point_box: Integer indicate the format of the box data. The default\n",
      " |              is 0. 0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1)\n",
      " |              and (y2, x2) are the coordinates of any diagonal pair of box corners and\n",
      " |              the coordinates can be provided as normalized (i.e., lying in the\n",
      " |              interval [0, 1]) or absolute. Mostly used for TF models. 1 - the box\n",
      " |              data is supplied as [x_center, y_center, width, height]. Mostly used for\n",
      " |              Pytorch models.\n",
      " |  \n",
      " |  OneHot(self, indices: 'T1_OneHot', depth: 'T2_OneHot', values: 'T3_OneHot', *, axis: 'int' = -1) -> 'T3_OneHot'\n",
      " |      [üåê OneHot(11)](https://onnx.ai/onnx/operators/onnx__OneHot.html#onehot-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |          Produces a one-hot tensor based on inputs.\n",
      " |          The locations represented by the index values in the 'indices' input tensor will have 'on_value'\n",
      " |          and the other locations will have 'off_value' in the output tensor, where 'on_value' and 'off_value'\n",
      " |          are specified as part of required input argument 'values', which is a two-element tensor of format\n",
      " |          [off_value, on_value]. The rank of the output tensor will be one greater than the rank of the\n",
      " |          input tensor. The additional dimension is for one-hot representation. The additional dimension will\n",
      " |          be inserted at the position specified by 'axis'. If 'axis' is not specified then then additional\n",
      " |          dimension will be inserted as the innermost dimension, i.e. axis=-1. The size of the additional\n",
      " |          dimension is specified by required scalar input 'depth'. The type of the output tensor is the same\n",
      " |          as the type of the 'values' input. Any entries in the 'indices' input tensor with values outside\n",
      " |          the range [-depth, depth-1] will result in one-hot representation with all 'off_value' values in the\n",
      " |          output tensor.\n",
      " |      \n",
      " |          when axis = 0:\n",
      " |          output[input[i, j, k], i, j, k] = 1 for all i, j, k and 0 otherwise.\n",
      " |      \n",
      " |          when axis = -1:\n",
      " |          output[i, j, k, input[i, j, k]] = 1 for all i, j, k and 0 otherwise.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          indices: (non-differentiable) Input tensor containing indices. Any entries\n",
      " |              in the 'indices' input tensor with values outside the range [-depth,\n",
      " |              depth-1] will result in one-hot representation with all 'off_value'\n",
      " |              values in the output tensor.In case 'indices' is of non-integer type,\n",
      " |              the values will be casted to int64 before use.\n",
      " |      \n",
      " |          depth: (non-differentiable) Scalar or Rank 1 tensor containing exactly one\n",
      " |              element, specifying the number of classes in one-hot tensor. This is\n",
      " |              also the size of the one-hot dimension (specified by 'axis' attribute)\n",
      " |              added on in the output tensor. The values in the 'indices' input tensor\n",
      " |              are expected to be in the range [-depth, depth-1]. In case 'depth' is of\n",
      " |              non-integer type, it will be casted to int64 before use.\n",
      " |      \n",
      " |          values: (non-differentiable) Rank 1 tensor containing exactly two elements,\n",
      " |              in the format [off_value, on_value], where 'on_value' is the value used\n",
      " |              for filling locations specified in 'indices' input tensor, and\n",
      " |              'off_value' is the value used for filling locations other than those\n",
      " |              specified in 'indices' input tensor.\n",
      " |      \n",
      " |          axis: (Optional) Axis along which one-hot representation in added. Default:\n",
      " |              axis=-1. axis=-1 means that the additional dimension will be inserted as\n",
      " |              the innermost/last dimension in the output tensor. Negative value means\n",
      " |              counting dimensions from the back. Accepted range is [-r-1, r] where r =\n",
      " |              rank(indices).\n",
      " |  \n",
      " |  Range(self, start: 'T_Range', limit: 'T_Range', delta: 'T_Range') -> 'T_Range'\n",
      " |      [üåê Range(11)](https://onnx.ai/onnx/operators/onnx__Range.html#range-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor containing a sequence of numbers that begin at `start` and extends by increments of `delta`\n",
      " |      up to `limit` (exclusive).\n",
      " |      \n",
      " |      The number of elements in the output of range is computed as below:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          number_of_elements = max( ceil( (limit - start) / delta ) , 0 )\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      The pseudocode determining the contents of the output is shown below:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          for(int i=0; i<number_of_elements; ++i) {\n",
      " |            output[i] =  start + (i * delta);\n",
      " |          }\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 1\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Inputs: start = 3, limit = 9, delta = 3\n",
      " |          Output: [3, 6]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Inputs: start = 10, limit = 4, delta = -2\n",
      " |          Output: [10, 8, 6]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          start: Scalar. First entry for the range of output values.\n",
      " |      \n",
      " |          limit: Scalar. Exclusive upper limit for the range of output values.\n",
      " |      \n",
      " |          delta: Scalar. Value to step by.\n",
      " |  \n",
      " |  Round(self, X: 'T_Round') -> 'T_Round'\n",
      " |      [üåê Round(11)](https://onnx.ai/onnx/operators/onnx__Round.html#round-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Round takes one input Tensor and rounds the values, element-wise, meaning\n",
      " |      it finds the nearest integer for each value.\n",
      " |      In case of halfs, the rule is to round them to the nearest even integer.\n",
      " |      If input x is integral, +0, -0, NaN,  or infinite, x itself is returned.\n",
      " |      The output tensor has the same shape and type as the input.\n",
      " |      \n",
      " |      Examples:\n",
      " |      ::\n",
      " |      \n",
      " |          round([0.9]) = [1.0]\n",
      " |          round([2.5]) = [2.0]\n",
      " |          round([2.3]) = [2.0]\n",
      " |          round([1.5]) = [2.0]\n",
      " |          round([-4.5]) = [-4.0]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  SequenceAt(self, input_sequence: 'S_SequenceAt', position: 'I_SequenceAt') -> 'T_SequenceAt'\n",
      " |      [üåê SequenceAt(11)](https://onnx.ai/onnx/operators/onnx__SequenceAt.html#sequenceat-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Outputs a tensor copy from the tensor at 'position' in 'input_sequence'.\n",
      " |      Accepted range for 'position' is in `[-n, n - 1]`, where `n` is the number of tensors in 'input_sequence'.\n",
      " |      Negative value means counting positions from the back.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |      \n",
      " |          position: Position of the tensor in the sequence. Negative value means\n",
      " |              counting positions from the back. Accepted range in `[-n, n - 1]`, where\n",
      " |              `n` is the number of tensors in 'input_sequence'. It is an error if any\n",
      " |              of the index values are out of bounds. It must be a scalar(tensor of\n",
      " |              empty shape).\n",
      " |  \n",
      " |  SequenceConstruct(self, *inputs: 'T_SequenceConstruct') -> 'S_SequenceConstruct'\n",
      " |      [üåê SequenceConstruct(11)](https://onnx.ai/onnx/operators/onnx__SequenceConstruct.html#sequenceconstruct-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Construct a tensor sequence containing 'inputs' tensors.\n",
      " |      All tensors in 'inputs' must have the same data type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: (variadic) Tensors.\n",
      " |  \n",
      " |  SequenceEmpty(self, *, dtype: 'Optional[int]' = None) -> 'S_SequenceEmpty'\n",
      " |      [üåê SequenceEmpty(11)](https://onnx.ai/onnx/operators/onnx__SequenceEmpty.html#sequenceempty-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Construct an empty tensor sequence, with given data type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          dtype: (Optional) The data type of the tensors in the output sequence. The\n",
      " |              default type is 'float'.\n",
      " |  \n",
      " |  SequenceErase(self, input_sequence: 'S_SequenceErase', position: 'Optional[I_SequenceErase]' = None) -> 'S_SequenceErase'\n",
      " |      [üåê SequenceErase(11)](https://onnx.ai/onnx/operators/onnx__SequenceErase.html#sequenceerase-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Outputs a tensor sequence that removes the tensor at 'position' from 'input_sequence'.\n",
      " |      Accepted range for 'position' is in `[-n, n - 1]`, where `n` is the number of tensors in 'input_sequence'.\n",
      " |      Negative value means counting positions from the back.\n",
      " |      'position' is optional, by default it erases the last tensor from 'input_sequence'.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |      \n",
      " |          position: (optional) Position of the tensor in the sequence. Negative value\n",
      " |              means counting positions from the back. Accepted range in `[-n, n - 1]`,\n",
      " |              where `n` is the number of tensors in 'input_sequence'. It is an error\n",
      " |              if any of the index values are out of bounds. It must be a scalar(tensor\n",
      " |              of empty shape).\n",
      " |  \n",
      " |  SequenceInsert(self, input_sequence: 'S_SequenceInsert', tensor: 'T_SequenceInsert', position: 'Optional[I_SequenceInsert]' = None) -> 'S_SequenceInsert'\n",
      " |      [üåê SequenceInsert(11)](https://onnx.ai/onnx/operators/onnx__SequenceInsert.html#sequenceinsert-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Outputs a tensor sequence that inserts 'tensor' into 'input_sequence' at 'position'.\n",
      " |      'tensor' must have the same data type as 'input_sequence'.\n",
      " |      Accepted range for 'position' is in `[-n, n]`, where `n` is the number of tensors in 'input_sequence'.\n",
      " |      Negative value means counting positions from the back.\n",
      " |      'position' is optional, by default it inserts 'tensor' to the back of 'input_sequence'.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |      \n",
      " |          tensor: Input tensor to be inserted into the input sequence.\n",
      " |      \n",
      " |          position: (optional) Position in the sequence where the new tensor is\n",
      " |              inserted. It is optional and default is to insert to the back of the\n",
      " |              sequence. Negative value means counting positions from the back.\n",
      " |              Accepted range in `[-n, n]`, where `n` is the number of tensors in\n",
      " |              'input_sequence'. It is an error if any of the index values are out of\n",
      " |              bounds. It must be a scalar(tensor of empty shape).\n",
      " |  \n",
      " |  SequenceLength(self, input_sequence: 'S_SequenceLength') -> 'I_SequenceLength'\n",
      " |      [üåê SequenceLength(11)](https://onnx.ai/onnx/operators/onnx__SequenceLength.html#sequencelength-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Produces a scalar(tensor of empty shape) containing the number of tensors in 'input_sequence'.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |  \n",
      " |  SplitToSequence(self, input: 'T_SplitToSequence', split: 'Optional[I_SplitToSequence]' = None, *, axis: 'int' = 0, keepdims: 'int' = 1) -> 'S_SplitToSequence'\n",
      " |      [üåê SplitToSequence(11)](https://onnx.ai/onnx/operators/onnx__SplitToSequence.html#splittosequence-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Split a tensor into a sequence of tensors, along the specified 'axis'.\n",
      " |      Lengths of the parts can be specified using the optional argument 'split'.\n",
      " |      If the argument `split' is not specified, a default scalar value of 1\n",
      " |      is used as the value of `split'.\n",
      " |      'split' must contain only positive numbers.\n",
      " |      'split' is either a scalar (tensor of empty shape), or a 1-D tensor.\n",
      " |      If 'split' is a scalar, then 'input' will be split into chunks all of size 'split'\n",
      " |      if possible. The last chunk alone may be smaller than 'split' if the 'input' size\n",
      " |      along the given axis 'axis' is not divisible by 'split'.\n",
      " |      If 'split' is a 1-dimensional tensor, the input tensor is split into 'size(split)' chunks,\n",
      " |      with lengths of the parts on 'axis' specified in 'split'. In this scenario, the sum of entries\n",
      " |      in 'split' must be equal to the dimension size of input tensor on 'axis'.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: The tensor to split\n",
      " |      \n",
      " |          split: (optional) Length of each output. It can be either a scalar(tensor of\n",
      " |              empty shape), or a 1-D tensor. All values must be >= 0.\n",
      " |      \n",
      " |          axis: Which axis to split on. A negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-rank, rank-1].\n",
      " |      \n",
      " |          keepdims: Keep the split dimension or not. Default 1, which means we keep\n",
      " |              split dimension. If input 'split' is specified, this attribute is\n",
      " |              ignored.\n",
      " |  \n",
      " |  TopK(self, X: 'T_TopK', K: 'INT64', *, axis: 'int' = -1, largest: 'int' = 1, sorted: 'int' = 1) -> 'Tuple[T_TopK, I_TopK]'\n",
      " |      [üåê TopK(11)](https://onnx.ai/onnx/operators/onnx__TopK.html#topk-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Retrieve the top-K largest or smallest elements along a specified axis. Given an input tensor of\n",
      " |      shape [a_1, a_2, ..., a_n, r] and integer argument k, return two outputs:\n",
      " |      \n",
      " |      * Value tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n]\n",
      " |        which contains the values of the top k elements along the specified axis\n",
      " |      * Index tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] which\n",
      " |        contains the indices of the top k elements (original indices from the input\n",
      " |        tensor).\n",
      " |      \n",
      " |      * If \"largest\" is 1 (the default value) then the k largest elements are returned.\n",
      " |      * If \"sorted\" is 1 (the default value) then the resulting k elements will be sorted.\n",
      " |      * If \"sorted\" is 0, order of returned 'Values' and 'Indices' are undefined.\n",
      " |      \n",
      " |      Given two equivalent values, this operator uses the indices along the axis as\n",
      " |      a tiebreaker. That is, the element with the lower index will appear first.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Tensor of shape [a_1, a_2, ..., a_n, r]\n",
      " |      \n",
      " |          K: (non-differentiable) A 1-D tensor containing a single positive value\n",
      " |              corresponding to the number of top elements to retrieve\n",
      " |      \n",
      " |          axis: Dimension on which to do the sort. Negative value means counting\n",
      " |              dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |      \n",
      " |          largest: Whether to return the top-K largest or smallest elements.\n",
      " |      \n",
      " |          sorted: Whether to return the elements in sorted order.\n",
      " |  \n",
      " |  Unique(self, X: 'T_Unique', *, axis: 'Optional[int]' = None, sorted: 'int' = 1) -> 'Tuple[T_Unique, INT64, INT64, INT64]'\n",
      " |      [üåê Unique(11)](https://onnx.ai/onnx/operators/onnx__Unique.html#unique-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Find the unique elements of a tensor. When an optional attribute 'axis' is provided, unique subtensors sliced along the 'axis' are returned.\n",
      " |      Otherwise the input tensor is flattened and unique values of the flattened tensor are returned.\n",
      " |      \n",
      " |      This operator returns the unique values or sliced unique subtensors of the input tensor and three optional outputs.\n",
      " |      The first output tensor 'Y' contains all unique values or subtensors of the input.\n",
      " |      The second optional output tensor 'indices' contains indices of 'Y' elements' first occurance in 'X'..\n",
      " |      The third optional output tensor 'inverse_indices' contains, for elements of 'X', its corresponding indices in 'Y'. \".\n",
      " |      The fourth optional output tensor 'counts' contains the count of each element of 'Y' in the input.\n",
      " |      \n",
      " |      Outputs are either sorted in ascending order or optionally in the order of the first occurrence of the values in the input.\n",
      " |      \n",
      " |      https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html\n",
      " |      \n",
      " |      Example 1:\n",
      " |      ::\n",
      " |      \n",
      " |          input_X = [2, 1, 1, 3, 4, 3]\n",
      " |          attribute_sorted = 0\n",
      " |          attribute_axis = None\n",
      " |          output_Y = [2, 1, 3, 4]\n",
      " |          output_indices = [0, 1, 3, 4]\n",
      " |          output_inverse_indices = [0, 1, 1, 2, 3, 2]\n",
      " |          output_counts = [1, 2, 2, 1]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      ::\n",
      " |      \n",
      " |          input_X = [[1, 3], [2, 3]]\n",
      " |          attribute_sorted = 1\n",
      " |          attribute_axis = None\n",
      " |          output_Y = [1, 2, 3]\n",
      " |          output_indices = [0, 2, 1]\n",
      " |          output_inverse_indices = [0, 2, 1, 2]\n",
      " |          output_counts = [1, 1, 2]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 3:\n",
      " |      ::\n",
      " |      \n",
      " |          input_X = [[1, 0, 0], [1, 0, 0], [2, 3, 4]]\n",
      " |          attribute_sorted = 1\n",
      " |          attribute_axis = 0\n",
      " |          output_Y = [[1, 0, 0], [2, 3, 4]]\n",
      " |          output_indices = [0, 2]\n",
      " |          output_inverse_indices = [0, 0, 1]\n",
      " |          output_counts = [2, 1]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 4:\n",
      " |      ::\n",
      " |      \n",
      " |          input_x = [[[1., 1.], [0., 1.], [2., 1.], [0., 1.]],\n",
      " |                      [[1., 1.], [0., 1.], [2., 1.], [0., 1.]]]\n",
      " |          attribute_sorted = 1\n",
      " |          attribute_axis = 1\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      intermediate data are presented below for better understanding:\n",
      " |      there are 4 subtensors sliced along axis 1 of input_x (shape = (2, 4, 2)):\n",
      " |      ::\n",
      " |      \n",
      " |          A: [[1, 1], [1, 1]],\n",
      " |             [[0, 1], [0, 1]],\n",
      " |             [[2, 1], [2, 1]],\n",
      " |             [[0, 1], [0, 1]].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      there are 3 unique subtensors:\n",
      " |      ::\n",
      " |      \n",
      " |          [[1, 1], [1, 1]],\n",
      " |          [[0, 1], [0, 1]],\n",
      " |          [[2, 1], [2, 1]].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      sorted unique subtensors:\n",
      " |      ::\n",
      " |      \n",
      " |          B: [[0, 1], [0, 1]],\n",
      " |             [[1, 1], [1, 1]],\n",
      " |             [[2, 1], [2, 1]].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      output_Y is constructed from B:\n",
      " |      ::\n",
      " |      \n",
      " |          [[[0. 1.], [1. 1.], [2. 1.]],\n",
      " |           [[0. 1.], [1. 1.], [2. 1.]]]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      output_indices is to map from B to A:\n",
      " |      ::\n",
      " |      \n",
      " |          [1, 0, 2]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      output_inverse_indices is to map from A to B:\n",
      " |      ::\n",
      " |      \n",
      " |          [1, 0, 2, 0]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      output_counts:\n",
      " |      ::\n",
      " |      \n",
      " |          [2, 1, 1]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) A N-D input tensor that is to be processed.\n",
      " |      \n",
      " |          axis: (Optional) The dimension to apply unique. If not specified, the unique\n",
      " |              elements of the flattened input are returned. Negative value means\n",
      " |              counting dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |      \n",
      " |          sorted: (Optional) Whether to sort the unique elements in ascending order\n",
      " |              before returning as output. Must be one of 0, or 1 (default).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset11.Opset11:\n",
      " |  \n",
      " |  I_SequenceAt = ~I_SequenceAt\n",
      " |  \n",
      " |  I_SequenceErase = ~I_SequenceErase\n",
      " |  \n",
      " |  I_SequenceInsert = ~I_SequenceInsert\n",
      " |  \n",
      " |  I_SequenceLength = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  I_SplitToSequence = ~I_SplitToSequence\n",
      " |  \n",
      " |  I_TopK = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  S_ConcatFromSequence = ~S_ConcatFromSequence\n",
      " |  \n",
      " |  S_SequenceAt = ~S_SequenceAt\n",
      " |  \n",
      " |  S_SequenceConstruct = typing.Union[typing.Sequence[onnxscript.onnx_typ...\n",
      " |  \n",
      " |  S_SequenceEmpty = typing.Union[typing.Sequence[onnxscript.onnx_typ...4...\n",
      " |  \n",
      " |  S_SequenceErase = ~S_SequenceErase\n",
      " |  \n",
      " |  S_SequenceInsert = ~S_SequenceInsert\n",
      " |  \n",
      " |  S_SequenceLength = ~S_SequenceLength\n",
      " |  \n",
      " |  S_SplitToSequence = typing.Union[typing.Sequence[onnxscript.onnx_typ.....\n",
      " |  \n",
      " |  T1_Compress = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_DynamicQuantizeLinear = <class 'onnxscript.onnx_types.FLOAT'>\n",
      " |  \n",
      " |  T1_MaxUnpool = ~T1_MaxUnpool\n",
      " |  \n",
      " |  T1_OneHot = ~T1_OneHot\n",
      " |  \n",
      " |  T2_DynamicQuantizeLinear = <class 'onnxscript.onnx_types.UINT8'>\n",
      " |  \n",
      " |  T2_MaxUnpool = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T2_OneHot = ~T2_OneHot\n",
      " |  \n",
      " |  T3_OneHot = ~T3_OneHot\n",
      " |  \n",
      " |  T_AveragePool = ~T_AveragePool\n",
      " |  \n",
      " |  T_BitShift = ~T_BitShift\n",
      " |  \n",
      " |  T_Compress = ~T_Compress\n",
      " |  \n",
      " |  T_ConcatFromSequence = typing.Union[onnxscript.onnx_types.BOOL, onnxsc...\n",
      " |  \n",
      " |  T_Conv = ~T_Conv\n",
      " |  \n",
      " |  T_ConvTranspose = ~T_ConvTranspose\n",
      " |  \n",
      " |  T_Det = ~T_Det\n",
      " |  \n",
      " |  T_Range = ~T_Range\n",
      " |  \n",
      " |  T_Round = ~T_Round\n",
      " |  \n",
      " |  T_SequenceAt = typing.Union[onnxscript.onnx_types.BOOL, onnxscr...t.on...\n",
      " |  \n",
      " |  T_SequenceConstruct = ~T_SequenceConstruct\n",
      " |  \n",
      " |  T_SequenceInsert = ~T_SequenceInsert\n",
      " |  \n",
      " |  T_SplitToSequence = ~T_SplitToSequence\n",
      " |  \n",
      " |  T_TopK = ~T_TopK\n",
      " |  \n",
      " |  T_Unique = ~T_Unique\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset10.Opset10:\n",
      " |  \n",
      " |  ConvInteger(self, x: 'T1_ConvInteger', w: 'T2_ConvInteger', x_zero_point: 'Optional[T1_ConvInteger]' = None, w_zero_point: 'Optional[T2_ConvInteger]' = None, *, auto_pad: 'str' = 'NOTSET', dilations: 'Optional[Sequence[int]]' = None, group: 'int' = 1, kernel_shape: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T3_ConvInteger'\n",
      " |      [üåê ConvInteger(10)](https://onnx.ai/onnx/operators/onnx__ConvInteger.html#convinteger-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The integer convolution operator consumes an input tensor, its zero-point, a filter, and its zero-point,\n",
      " |      and computes the output. The production MUST never overflow. The accumulation may overflow if and only if in 32 bits.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data tensor from previous layer; has size (N x C x H x W), where N\n",
      " |              is the batch size, C is the number of channels, and H and W are the\n",
      " |              height and width. Note that this is for the 2D image. Otherwise the size\n",
      " |              is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in\n",
      " |              effect, the operation expects input data tensor to arrive with the\n",
      " |              dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE,\n",
      " |              DATA_FEATURE ...].\n",
      " |      \n",
      " |          w: The weight tensor that will be used in the convolutions; has size (M x\n",
      " |              C/group x kH x kW), where C is the number of channels, and kH and kW are\n",
      " |              the height and width of the kernel, and M is the number of feature maps.\n",
      " |              For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x\n",
      " |              k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel.\n",
      " |              Optionally, if dimension denotation is in effect, the operation expects\n",
      " |              the weight tensor to arrive with the dimension denotation of\n",
      " |              [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL\n",
      " |              ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based\n",
      " |              indices for the shape array). Or in other words FILTER_IN_CHANNEL should\n",
      " |              be equal to DATA_CHANNEL.\n",
      " |      \n",
      " |          x_zero_point: (optional) Zero point tensor for input 'x'. It's optional and\n",
      " |              default value is 0. It's a scalar, which means a per-tensor/layer\n",
      " |              quantization.\n",
      " |      \n",
      " |          w_zero_point: (optional) Zero point tensor for input 'w'. It's optional and\n",
      " |              default value is 0.  It could be a scalar or a 1-D tensor, which means a\n",
      " |              per-tensor/layer or per output channel quantization. If it's a 1-D\n",
      " |              tensor, its number of elements should be equal to the number of output\n",
      " |              channels (M)\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults to 1 along each axis.\n",
      " |      \n",
      " |          group: number of groups input channels and output channels are divided into.\n",
      " |              default is 1.\n",
      " |      \n",
      " |          kernel_shape: The shape of the convolution kernel. If not present, should be\n",
      " |              inferred from input 'w'.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0.The value represent the number\n",
      " |              of pixels added to the beginning and end part of the corresponding\n",
      " |              axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end,\n",
      " |              x2_end,...], where xi_begin the number ofpixels added at the beginning\n",
      " |              of axis `i` and xi_end, the number of pixels added at the end of axis\n",
      " |              `i`.This attribute cannot be used simultaneously with auto_pad\n",
      " |              attribute. If not present, the padding defaultsto 0 along start and end\n",
      " |              of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each axis.\n",
      " |  \n",
      " |  IsInf(self, X: 'T1_IsInf', *, detect_negative: 'int' = 1, detect_positive: 'int' = 1) -> 'T2_IsInf'\n",
      " |      [üåê IsInf(10)](https://onnx.ai/onnx/operators/onnx__IsInf.html#isinf-10 \"Online Documentation\")\n",
      " |      \n",
      " |      Map infinity to true and other values to false.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) input\n",
      " |      \n",
      " |          detect_negative: (Optional) Whether map negative infinity to true. Default\n",
      " |              to 1 so that negative infinity induces true. Set this attribute to 0 if\n",
      " |              negative infinity should be mapped to false.\n",
      " |      \n",
      " |          detect_positive: (Optional) Whether map positive infinity to true. Default\n",
      " |              to 1 so that positive infinity induces true. Set this attribute to 0 if\n",
      " |              positive infinity should be mapped to false.\n",
      " |  \n",
      " |  MatMulInteger(self, A: 'T1_MatMulInteger', B: 'T2_MatMulInteger', a_zero_point: 'Optional[T1_MatMulInteger]' = None, b_zero_point: 'Optional[T2_MatMulInteger]' = None) -> 'T3_MatMulInteger'\n",
      " |      [üåê MatMulInteger(10)](https://onnx.ai/onnx/operators/onnx__MatMulInteger.html#matmulinteger-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html.\n",
      " |      The production MUST never overflow. The accumulation may overflow if and only if in 32 bits.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) N-dimensional matrix A\n",
      " |      \n",
      " |          B: (non-differentiable) N-dimensional matrix B\n",
      " |      \n",
      " |          a_zero_point: (optional, non-differentiable) Zero point tensor for input\n",
      " |              'A'. It's optional and default value is 0. It could be a scalar or N-D\n",
      " |              tensor. Scalar refers to per tensor quantization whereas N-D refers to\n",
      " |              per row quantization. If the input is 2D of shape [M, K] then zero point\n",
      " |              tensor may be an M element vector [zp_1, zp_2, ..., zp_M]. If the input\n",
      " |              is N-D tensor with shape [D1, D2, M, K] then zero point tensor may have\n",
      " |              shape [D1, D2, M, 1].\n",
      " |      \n",
      " |          b_zero_point: (optional, non-differentiable) Zero point tensor for input\n",
      " |              'B'. It's optional and default value is 0. It could be a scalar or a N-D\n",
      " |              tensor, Scalar refers to per tensor quantization whereas N-D refers to\n",
      " |              per col quantization. If the input is 2D of shape [K, N] then zero point\n",
      " |              tensor may be an N element vector [zp_1, zp_2, ..., zp_N]. If the input\n",
      " |              is N-D tensor with shape [D1, D2, K, N] then zero point tensor may have\n",
      " |              shape [D1, D2, 1, N].\n",
      " |  \n",
      " |  QLinearConv(self, x: 'T1_QLinearConv', x_scale: 'FLOAT', x_zero_point: 'T1_QLinearConv', w: 'T2_QLinearConv', w_scale: 'FLOAT', w_zero_point: 'T2_QLinearConv', y_scale: 'FLOAT', y_zero_point: 'T3_QLinearConv', B: 'Optional[T4_QLinearConv]' = None, *, auto_pad: 'str' = 'NOTSET', dilations: 'Optional[Sequence[int]]' = None, group: 'int' = 1, kernel_shape: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T3_QLinearConv'\n",
      " |      [üåê QLinearConv(10)](https://onnx.ai/onnx/operators/onnx__QLinearConv.html#qlinearconv-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The convolution operator consumes a quantized input tensor, its scale and zero point,\n",
      " |      a quantized filter, its scale and zero point, and output's scale and zero point,\n",
      " |      and computes the quantized output. Each scale and zero-point pair must have same shape.\n",
      " |      It means they must be either scalars (per tensor) or 1-D tensors (per output channel).\n",
      " |      Each input or output and its related zero point must have same type.\n",
      " |      When bias is present it must be quantized using scale = input scale * weight scale and\n",
      " |      zero point as 0.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data tensor from previous layer; has size (N x C x H x W), where N\n",
      " |              is the batch size, C is the number of channels, and H and W are the\n",
      " |              height and width. Note that this is for the 2D image. Otherwise the size\n",
      " |              is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in\n",
      " |              effect, the operation expects input data tensor to arrive with the\n",
      " |              dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE,\n",
      " |              DATA_FEATURE ...].\n",
      " |      \n",
      " |          x_scale: Scale tensor for input 'x'. It's a scalar, which means a\n",
      " |              per-tensor/layer quantization.\n",
      " |      \n",
      " |          x_zero_point: Zero point tensor for input 'x'. It's a scalar, which means a\n",
      " |              per-tensor/layer quantization.\n",
      " |      \n",
      " |          w: The weight tensor that will be used in the convolutions; has size (M x\n",
      " |              C/group x kH x kW), where C is the number of channels, and kH and kW are\n",
      " |              the height and width of the kernel, and M is the number of feature maps.\n",
      " |              For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x\n",
      " |              k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel.\n",
      " |              Optionally, if dimension denotation is in effect, the operation expects\n",
      " |              the weight tensor to arrive with the dimension denotation of\n",
      " |              [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL\n",
      " |              ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based\n",
      " |              indices for the shape array). Or in other words FILTER_IN_CHANNEL should\n",
      " |              be equal to DATA_CHANNEL.\n",
      " |      \n",
      " |          w_scale: Scale tensor for input 'w'. It could be a scalar or a 1-D tensor,\n",
      " |              which means a per-tensor/layer or per output channel quantization. If\n",
      " |              it's a 1-D tensor, its number of elements should be equal to the number\n",
      " |              of output channels (M).\n",
      " |      \n",
      " |          w_zero_point: Zero point tensor for input 'w'. It could be a scalar or a 1-D\n",
      " |              tensor, which means a per-tensor/layer or per output channel\n",
      " |              quantization. If it's a 1-D tensor, its number of elements should be\n",
      " |              equal to the number of output channels (M).\n",
      " |      \n",
      " |          y_scale: Scale tensor for output 'y'. It's a scalar, which means a\n",
      " |              per-tensor/layer quantization.\n",
      " |      \n",
      " |          y_zero_point: Zero point tensor for output 'y'. It's a scalar, which means a\n",
      " |              per-tensor/layer quantization.\n",
      " |      \n",
      " |          B: (optional) Optional 1D bias to be added to the convolution, has size of\n",
      " |              M. Bias must be quantized using scale = x_scale * w_scale and zero_point\n",
      " |              = 0\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults to 1 along each spatial axis.\n",
      " |      \n",
      " |          group: number of groups input channels and output channels are divided into.\n",
      " |              default is 1.\n",
      " |      \n",
      " |          kernel_shape: The shape of the convolution kernel. If not present, should be\n",
      " |              inferred from input 'w'.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0.The value represent the number\n",
      " |              of pixels added to the beginning and end part of the corresponding\n",
      " |              axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end,\n",
      " |              x2_end,...], where xi_begin the number ofpixels added at the beginning\n",
      " |              of axis `i` and xi_end, the number of pixels added at the end of axis\n",
      " |              `i`.This attribute cannot be used simultaneously with auto_pad\n",
      " |              attribute. If not present, the padding defaultsto 0 along start and end\n",
      " |              of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  QLinearMatMul(self, a: 'T1_QLinearMatMul', a_scale: 'FLOAT', a_zero_point: 'T1_QLinearMatMul', b: 'T2_QLinearMatMul', b_scale: 'FLOAT', b_zero_point: 'T2_QLinearMatMul', y_scale: 'FLOAT', y_zero_point: 'T3_QLinearMatMul') -> 'T3_QLinearMatMul'\n",
      " |      [üåê QLinearMatMul(10)](https://onnx.ai/onnx/operators/onnx__QLinearMatMul.html#qlinearmatmul-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html.\n",
      " |      It consumes two quantized input tensors, their scales and zero points, scale and zero point of output,\n",
      " |      and computes the quantized output. The quantization formula is y = saturate((x / y_scale) + y_zero_point).\n",
      " |      For (x / y_scale), it is rounding to nearest ties to even. Refer to https://en.wikipedia.org/wiki/Rounding for details.\n",
      " |      Scale and zero point must have same shape. They must be either scalar (per tensor) or N-D tensor\n",
      " |      (per row for 'a' and per column for 'b'). Scalar refers to per tensor quantization whereas N-D refers to per row\n",
      " |      or per column quantization. If the input is 2D of shape [M, K] then zero point and scale tensor may be\n",
      " |      an M element vector [v_1, v_2, ..., v_M] for per row quantization and K element vector of shape [v_1, v_2, ..., v_K]\n",
      " |      for per column quantization. If the input is N-D tensor with shape [D1, D2, M, K] then zero point and scale tensor may\n",
      " |      have shape [D1, D2, M, 1] for per row quantization and shape [D1, D2, 1, K] for per column quantization.\n",
      " |      Production must never overflow, and accumulation may overflow if and only if in 32 bits.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          a: (non-differentiable) N-dimensional quantized matrix a\n",
      " |      \n",
      " |          a_scale: (non-differentiable) scale of quantized input a\n",
      " |      \n",
      " |          a_zero_point: (non-differentiable) zero point of quantized input a\n",
      " |      \n",
      " |          b: (non-differentiable) N-dimensional quantized matrix b\n",
      " |      \n",
      " |          b_scale: (non-differentiable) scale of quantized input b\n",
      " |      \n",
      " |          b_zero_point: (non-differentiable) zero point of quantized input b\n",
      " |      \n",
      " |          y_scale: (non-differentiable) scale of quantized output y\n",
      " |      \n",
      " |          y_zero_point: (non-differentiable) zero point of quantized output y\n",
      " |  \n",
      " |  ReverseSequence(self, input: 'T_ReverseSequence', sequence_lens: 'INT64', *, batch_axis: 'int' = 1, time_axis: 'int' = 0) -> 'T_ReverseSequence'\n",
      " |      [üåê ReverseSequence(10)](https://onnx.ai/onnx/operators/onnx__ReverseSequence.html#reversesequence-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Reverse batch of sequences having different lengths specified by `sequence_lens`.\n",
      " |      \n",
      " |      For each slice i iterating on batch axis, the operator reverses the first sequence_lens[i] elements on time axis,\n",
      " |      and copies elements whose index's beyond sequence_lens[i] to the output. So the output slice i contains reversed\n",
      " |      sequences on the first sequence_lens[i] elements, then have original values copied for the other elements.\n",
      " |      \n",
      " |      Example 1:\n",
      " |        input = [[0.0, 4.0, 8.0,  12.0],\n",
      " |                 [1.0, 5.0, 9.0,  13.0],\n",
      " |                 [2.0, 6.0, 10.0, 14.0],\n",
      " |                 [3.0, 7.0, 11.0, 15.0]]\n",
      " |        sequence_lens = [4, 3, 2, 1]\n",
      " |        time_axis = 0\n",
      " |        batch_axis = 1\n",
      " |      \n",
      " |        output = [[3.0, 6.0, 9.0,  12.0],\n",
      " |                  [2.0, 5.0, 8.0,  13.0],\n",
      " |                  [1.0, 4.0, 10.0, 14.0],\n",
      " |                  [0.0, 7.0, 11.0, 15.0]]\n",
      " |      \n",
      " |      Example 2:\n",
      " |        input = [[0.0,  1.0,  2.0,  3.0 ],\n",
      " |                 [4.0,  5.0,  6.0,  7.0 ],\n",
      " |                 [8.0,  9.0,  10.0, 11.0],\n",
      " |                 [12.0, 13.0, 14.0, 15.0]]\n",
      " |        sequence_lens = [1, 2, 3, 4]\n",
      " |        time_axis = 1\n",
      " |        batch_axis = 0\n",
      " |      \n",
      " |        output = [[0.0,  1.0,  2.0,  3.0 ],\n",
      " |                  [5.0,  4.0,  6.0,  7.0 ],\n",
      " |                  [10.0, 9.0,  8.0,  11.0],\n",
      " |                  [15.0, 14.0, 13.0, 12.0]]\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: Tensor of rank r >= 2.\n",
      " |      \n",
      " |          sequence_lens: Tensor specifying lengths of the sequences in a batch. It has\n",
      " |              shape `[batch_size]`.\n",
      " |      \n",
      " |          batch_axis: (Optional) Specify which axis is batch axis. Must be one of 1\n",
      " |              (default), or 0.\n",
      " |      \n",
      " |          time_axis: (Optional) Specify which axis is time axis. Must be one of 0\n",
      " |              (default), or 1.\n",
      " |  \n",
      " |  StringNormalizer(self, X: 'STRING', *, case_change_action: 'str' = 'NONE', is_case_sensitive: 'int' = 0, locale: 'Optional[str]' = None, stopwords: 'Optional[Sequence[str]]' = None) -> 'STRING'\n",
      " |      [üåê StringNormalizer(10)](https://onnx.ai/onnx/operators/onnx__StringNormalizer.html#stringnormalizer-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      StringNormalization performs string operations for basic cleaning.\n",
      " |      This operator has only one input (denoted by X) and only one output\n",
      " |      (denoted by Y). This operator first examines the elements in the X,\n",
      " |      and removes elements specified in \"stopwords\" attribute.\n",
      " |      After removing stop words, the intermediate result can be further lowercased,\n",
      " |      uppercased, or just returned depending the \"case_change_action\" attribute.\n",
      " |      This operator only accepts [C]- and [1, C]-tensor.\n",
      " |      If all elements in X are dropped, the output will be the empty value of string tensor with shape [1]\n",
      " |      if input shape is [C] and shape [1, 1] if input shape is [1, C].\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: UTF-8 strings to normalize\n",
      " |      \n",
      " |          case_change_action: string enum that cases output to be\n",
      " |              lowercased/uppercases/unchanged. Valid values are \"LOWER\", \"UPPER\",\n",
      " |              \"NONE\". Default is \"NONE\"\n",
      " |      \n",
      " |          is_case_sensitive: Boolean. Whether the identification of stop words in X is\n",
      " |              case-sensitive. Default is false\n",
      " |      \n",
      " |          locale: Environment dependent string that denotes the locale according to\n",
      " |              which output strings needs to be upper/lowercased.Default en_US or\n",
      " |              platform specific equivalent as decided by the implementation.\n",
      " |      \n",
      " |          stopwords: List of stop words. If not set, no word would be removed from X.\n",
      " |  \n",
      " |  ThresholdedRelu(self, X: 'T_ThresholdedRelu', *, alpha: 'float' = 1.0) -> 'T_ThresholdedRelu'\n",
      " |      [üåê ThresholdedRelu(10)](https://onnx.ai/onnx/operators/onnx__ThresholdedRelu.html#thresholdedrelu-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      ThresholdedRelu takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the rectified linear function, y = x for x > alpha, y = 0 otherwise,\n",
      " |      is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: Threshold value\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset10.Opset10:\n",
      " |  \n",
      " |  T1_ConvInteger = ~T1_ConvInteger\n",
      " |  \n",
      " |  T1_IsInf = ~T1_IsInf\n",
      " |  \n",
      " |  T1_MatMulInteger = ~T1_MatMulInteger\n",
      " |  \n",
      " |  T1_QLinearConv = ~T1_QLinearConv\n",
      " |  \n",
      " |  T1_QLinearMatMul = ~T1_QLinearMatMul\n",
      " |  \n",
      " |  T2_ConvInteger = ~T2_ConvInteger\n",
      " |  \n",
      " |  T2_IsInf = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T2_MatMulInteger = ~T2_MatMulInteger\n",
      " |  \n",
      " |  T2_QLinearConv = ~T2_QLinearConv\n",
      " |  \n",
      " |  T2_QLinearMatMul = ~T2_QLinearMatMul\n",
      " |  \n",
      " |  T3_ConvInteger = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T3_MatMulInteger = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T3_QLinearConv = ~T3_QLinearConv\n",
      " |  \n",
      " |  T3_QLinearMatMul = ~T3_QLinearMatMul\n",
      " |  \n",
      " |  T4_QLinearConv = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T_Resize = ~T_Resize\n",
      " |  \n",
      " |  T_ReverseSequence = ~T_ReverseSequence\n",
      " |  \n",
      " |  T_ThresholdedRelu = ~T_ThresholdedRelu\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset9.Opset9:\n",
      " |  \n",
      " |  Acosh(self, input: 'T_Acosh') -> 'T_Acosh'\n",
      " |      [üåê Acosh(9)](https://onnx.ai/onnx/operators/onnx__Acosh.html#acosh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic arccosine of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Asinh(self, input: 'T_Asinh') -> 'T_Asinh'\n",
      " |      [üåê Asinh(9)](https://onnx.ai/onnx/operators/onnx__Asinh.html#asinh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic arcsine of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Atanh(self, input: 'T_Atanh') -> 'T_Atanh'\n",
      " |      [üåê Atanh(9)](https://onnx.ai/onnx/operators/onnx__Atanh.html#atanh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic arctangent of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  ConstantOfShape(self, input: 'T1_ConstantOfShape', *, value: 'Optional[TensorProto]' = None) -> 'T2_ConstantOfShape'\n",
      " |      [üåê ConstantOfShape(9)](https://onnx.ai/onnx/operators/onnx__ConstantOfShape.html#constantofshape-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with given value and shape.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: 1D tensor. The shape of the expected output tensor. If empty tensor\n",
      " |              is given, the output would be a scalar. All values must be >= 0.\n",
      " |      \n",
      " |          value: (Optional) The value of the output elements.Should be a one-element\n",
      " |              tensor. If not specified, it defaults to a tensor of value 0 and\n",
      " |              datatype float32\n",
      " |  \n",
      " |  Cosh(self, input: 'T_Cosh') -> 'T_Cosh'\n",
      " |      [üåê Cosh(9)](https://onnx.ai/onnx/operators/onnx__Cosh.html#cosh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic cosine of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  EyeLike(self, input: 'T1_EyeLike', *, dtype: 'Optional[int]' = None, k: 'int' = 0) -> 'T2_EyeLike'\n",
      " |      [üåê EyeLike(9)](https://onnx.ai/onnx/operators/onnx__EyeLike.html#eyelike-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a 2D tensor (matrix) with ones on the diagonal and zeros everywhere else. Only 2D\n",
      " |      tensors are supported, i.e. input T1 must be of rank 2. The shape of the output tensor is the\n",
      " |      same as the input tensor. The data type can be specified by the 'dtype' argument. If\n",
      " |      'dtype' is not specified, then the type of input tensor is used. By default, the main diagonal\n",
      " |      is populated with ones, but attribute 'k' can be used to populate upper or lower diagonals.\n",
      " |      The 'dtype' argument must be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message and be valid as an output type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: 2D input tensor to copy shape, and optionally, type information from.\n",
      " |      \n",
      " |          dtype: (Optional) The data type for the elements of the output tensor. If\n",
      " |              not specified,the data type of the input tensor T1 is used. If input\n",
      " |              tensor T1 is also notspecified, then type defaults to 'float'.\n",
      " |      \n",
      " |          k: (Optional) Index of the diagonal to be populated with ones. Default is 0.\n",
      " |              If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the\n",
      " |              main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a\n",
      " |              lower diagonal.\n",
      " |  \n",
      " |  Scatter(self, data: 'T_Scatter', indices: 'Tind_Scatter', updates: 'T_Scatter', *, axis: 'int' = 0) -> 'T_Scatter'\n",
      " |      [üåê Scatter(9)](https://onnx.ai/onnx/operators/onnx__Scatter.html#scatter-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given `data`, `updates` and `indices` input tensors of rank r >= 1, write the values provided by `updates`\n",
      " |      into the first input, `data`, along `axis` dimension of `data` (by default outer-most one as axis=0) at corresponding `indices`.\n",
      " |      For each entry in `updates`, the target index in `data` is specified by corresponding entry in `indices`\n",
      " |      for dimension = axis, and index in source for dimension != axis. For instance, in a 2-D tensor case,\n",
      " |      data[indices[i][j]][j] = updates[i][j] if axis = 0, or data[i][indices[i][j]] = updates[i][j] if axis = 1,\n",
      " |      where i and j are loop counters from 0 up to the respective size in `updates` - 1.\n",
      " |      Example 1:\n",
      " |        data = [\n",
      " |            [0.0, 0.0, 0.0],\n",
      " |            [0.0, 0.0, 0.0],\n",
      " |            [0.0, 0.0, 0.0],\n",
      " |        ]\n",
      " |        indices = [\n",
      " |            [1, 0, 2],\n",
      " |            [0, 2, 1],\n",
      " |        ]\n",
      " |        updates = [\n",
      " |            [1.0, 1.1, 1.2],\n",
      " |            [2.0, 2.1, 2.2],\n",
      " |        ]\n",
      " |        output = [\n",
      " |            [2.0, 1.1, 0.0]\n",
      " |            [1.0, 0.0, 2.2]\n",
      " |            [0.0, 2.1, 1.2]\n",
      " |        ]\n",
      " |      Example 2:\n",
      " |        data = [[1.0, 2.0, 3.0, 4.0, 5.0]]\n",
      " |        indices = [[1, 3]]\n",
      " |        updates = [[1.1, 2.1]]\n",
      " |        axis = 1\n",
      " |        output = [[1.0, 1.1, 3.0, 2.1, 5.0]]\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: Tensor of int32/int64 indices, of r >= 1 (same rank as input).\n",
      " |      \n",
      " |          updates: Tensor of rank r >=1 (same rank and shape as indices)\n",
      " |      \n",
      " |          axis: Which axis to scatter on. Negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-r, r-1]\n",
      " |  \n",
      " |  Shrink(self, input: 'T_Shrink', *, bias: 'float' = 0.0, lambd: 'float' = 0.5) -> 'T_Shrink'\n",
      " |      [üåê Shrink(9)](https://onnx.ai/onnx/operators/onnx__Shrink.html#shrink-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Shrink takes one input data (Tensor<numeric>) and produces one Tensor output,\n",
      " |      having same datatype and shape with input. It has two attributes, lambd and\n",
      " |      bias. The formula of this operator is: If x < -lambd, y = x + bias;\n",
      " |      If x > lambd, y = x - bias; Otherwise, y = 0.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The input data as Tensor.\n",
      " |      \n",
      " |          bias: The bias value added to output. Default is 0.\n",
      " |      \n",
      " |          lambd: The lambd value for the Shrink formulation. Default is 0.5.\n",
      " |  \n",
      " |  Sinh(self, input: 'T_Sinh') -> 'T_Sinh'\n",
      " |      [üåê Sinh(9)](https://onnx.ai/onnx/operators/onnx__Sinh.html#sinh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic sine of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  TfIdfVectorizer(self, X: 'T_TfIdfVectorizer', *, max_gram_length: 'int', max_skip_count: 'int', min_gram_length: 'int', mode: 'str', ngram_counts: 'Sequence[int]', ngram_indexes: 'Sequence[int]', pool_int64s: 'Optional[Sequence[int]]' = None, pool_strings: 'Optional[Sequence[str]]' = None, weights: 'Optional[Sequence[float]]' = None) -> 'T1_TfIdfVectorizer'\n",
      " |      [üåê TfIdfVectorizer(9)](https://onnx.ai/onnx/operators/onnx__TfIdfVectorizer.html#tfidfvectorizer-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      This transform extracts n-grams from the input sequence and save them as a vector. Input can\n",
      " |      be either a 1-D or 2-D tensor. For 1-D input, output is the n-gram representation of that input.\n",
      " |      For 2-D input, the output is also a  2-D tensor whose i-th row is the n-gram representation of the i-th input row.\n",
      " |      More specifically, if input shape is [C], the corresponding output shape would be [max(ngram_indexes) + 1].\n",
      " |      If input shape is [N, C], this operator produces a [N, max(ngram_indexes) + 1]-tensor.\n",
      " |      \n",
      " |      In contrast to standard n-gram extraction, here, the indexes of extracting an n-gram from the original\n",
      " |      sequence are not necessarily consecutive numbers. The discontinuity between indexes are controlled by the number of skips.\n",
      " |      If the number of skips is 2, we should skip two tokens when scanning through the original sequence.\n",
      " |      Let's consider an example. Assume that input sequence is [94, 17, 36, 12, 28] and the number of skips is 2.\n",
      " |      The associated 2-grams are [94, 12] and [17, 28] respectively indexed by [0, 3] and [1, 4].\n",
      " |      If the number of skips becomes 0, the 2-grams generated are [94, 17], [17, 36], [36, 12], [12, 28]\n",
      " |      indexed by [0, 1], [1, 2], [2, 3], [3, 4], respectively.\n",
      " |      \n",
      " |      The output vector (denoted by Y) stores the count of each n-gram;\n",
      " |      Y[ngram_indexes[i]] indicates the times that the i-th n-gram is found. The attribute ngram_indexes is used to determine the mapping\n",
      " |      between index i and the corresponding n-gram's output coordinate. If pool_int64s is [94, 17, 17, 36], ngram_indexes is [1, 0],\n",
      " |      ngram_counts=[0, 0], then the Y[0] (first element in Y) and Y[1] (second element in Y) are the counts of [17, 36] and [94, 17],\n",
      " |      respectively. An n-gram which cannot be found in pool_strings/pool_int64s should be ignored and has no effect on the output.\n",
      " |      Note that we may consider all skips up to S when generating the n-grams.\n",
      " |      \n",
      " |      The examples used above are true if mode is \"TF\". If mode is \"IDF\", all the counts larger than 1 would be truncated to 1 and\n",
      " |      the i-th element in weights would be used to scale (by multiplication) the count of the i-th n-gram in pool. If mode is \"TFIDF\",\n",
      " |      this operator first computes the counts of all n-grams and then scale them by the associated values in the weights attribute.\n",
      " |      \n",
      " |      Only one of pool_strings and pool_int64s can be set. If pool_int64s is set, the input should be an integer tensor.\n",
      " |      If pool_strings is set, the input must be a string tensor.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input for n-gram extraction\n",
      " |      \n",
      " |          max_gram_length: Maximum n-gram length. If this value is 3, 3-grams will be\n",
      " |              used to generate the output.\n",
      " |      \n",
      " |          max_skip_count: Maximum number of items (integers/strings) to be skipped\n",
      " |              when constructing an n-gram from X. If max_skip_count=1,\n",
      " |              min_gram_length=2, max_gram_length=3, this operator may generate 2-grams\n",
      " |              with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and\n",
      " |              skip_count=1\n",
      " |      \n",
      " |          min_gram_length: Minimum n-gram length. If this value is 2 and\n",
      " |              max_gram_length is 3, output may contain counts of 2-grams and 3-grams.\n",
      " |      \n",
      " |          mode: The weighting criteria. It can be one of \"TF\" (term frequency), \"IDF\"\n",
      " |              (inverse document frequency), and \"TFIDF\" (the combination of TF and\n",
      " |              IDF)\n",
      " |      \n",
      " |          ngram_counts: The starting indexes of 1-grams, 2-grams, and so on in pool.\n",
      " |              It is useful when determining the boundary between two consecutive\n",
      " |              collections of n-grams. For example, if ngram_counts is [0, 17, 36], the\n",
      " |              first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36.\n",
      " |              This format is essentially identical to CSR (or CSC) sparse matrix\n",
      " |              format, and we choose to use this due to its popularity.\n",
      " |      \n",
      " |          ngram_indexes: list of int64s (type: AttributeProto::INTS). This list is\n",
      " |              parallel to the specified 'pool_*' attribute. The i-th element in\n",
      " |              ngram_indexes indicate the coordinate of the i-th n-gram in the output\n",
      " |              tensor.\n",
      " |      \n",
      " |          pool_int64s: List of int64 n-grams learned from the training set. Either\n",
      " |              this or pool_strings attributes must be present but not both. It's an\n",
      " |              1-D tensor starting with the collections of all 1-grams and ending with\n",
      " |              the collections of n-grams. The i-th element in pool stores the n-gram\n",
      " |              that should be mapped to coordinate ngram_indexes[i] in the output\n",
      " |              vector.\n",
      " |      \n",
      " |          pool_strings: List of strings n-grams learned from the training set. Either\n",
      " |              this or pool_int64s attributes must be present but not both. It's an 1-D\n",
      " |              tensor starting with the collections of all 1-grams and ending with the\n",
      " |              collections of n-grams. The i-th element in pool stores the n-gram that\n",
      " |              should be mapped to coordinate ngram_indexes[i] in the output vector.\n",
      " |      \n",
      " |          weights: list of floats. This attribute stores the weight of each n-gram in\n",
      " |              pool. The i-th element in weights is the weight of the i-th n-gram in\n",
      " |              pool. Its length equals to the size of ngram_indexes. By default,\n",
      " |              weights is an all-one tensor.This attribute is used when mode is \"IDF\"\n",
      " |              or \"TFIDF\" to scale the associated word counts.\n",
      " |  \n",
      " |  Upsample(self, X: 'T_Upsample', scales: 'FLOAT', *, mode: 'str' = 'nearest') -> 'T_Upsample'\n",
      " |      [üåê Upsample(9)](https://onnx.ai/onnx/operators/onnx__Upsample.html#upsample-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Upsample the input tensor.\n",
      " |      Each dimension value of the output tensor is:\n",
      " |        output_dimension = floor(input_dimension * scale).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: N-D tensor\n",
      " |      \n",
      " |          scales: The scale array along each dimension. It takes value greater than or\n",
      " |              equal to 1. The number of elements of 'scales' should be the same as the\n",
      " |              rank of input 'X'.\n",
      " |      \n",
      " |          mode: Two interpolation modes: nearest (default), and linear (including\n",
      " |              bilinear, trilinear, etc)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset9.Opset9:\n",
      " |  \n",
      " |  T1_ConstantOfShape = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T1_EyeLike = ~T1_EyeLike\n",
      " |  \n",
      " |  T1_TfIdfVectorizer = <class 'onnxscript.onnx_types.FLOAT'>\n",
      " |  \n",
      " |  T2_ConstantOfShape = typing.Union[onnxscript.onnx_types.BOOL, onnxscr....\n",
      " |  \n",
      " |  T2_EyeLike = typing.Union[onnxscript.onnx_types.BOOL, onnxscr...t.onnx...\n",
      " |  \n",
      " |  T_Acosh = ~T_Acosh\n",
      " |  \n",
      " |  T_Asinh = ~T_Asinh\n",
      " |  \n",
      " |  T_Atanh = ~T_Atanh\n",
      " |  \n",
      " |  T_Cosh = ~T_Cosh\n",
      " |  \n",
      " |  T_Scatter = ~T_Scatter\n",
      " |  \n",
      " |  T_Shrink = ~T_Shrink\n",
      " |  \n",
      " |  T_Sinh = ~T_Sinh\n",
      " |  \n",
      " |  T_TfIdfVectorizer = ~T_TfIdfVectorizer\n",
      " |  \n",
      " |  T_Upsample = ~T_Upsample\n",
      " |  \n",
      " |  Tind_Scatter = ~Tind_Scatter\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset8.Opset8:\n",
      " |  \n",
      " |  I_Scan = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset7.Opset7:\n",
      " |  \n",
      " |  Acos(self, input: 'T_Acos') -> 'T_Acos'\n",
      " |      [üåê Acos(7)](https://onnx.ai/onnx/operators/onnx__Acos.html#acos-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the arccosine (inverse of cosine) of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  And(self, A: 'T_And', B: 'T_And') -> 'T1_And'\n",
      " |      [üåê And(7)](https://onnx.ai/onnx/operators/onnx__And.html#and-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `and` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Asin(self, input: 'T_Asin') -> 'T_Asin'\n",
      " |      [üåê Asin(7)](https://onnx.ai/onnx/operators/onnx__Asin.html#asin-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the arcsine (inverse of sine) of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Atan(self, input: 'T_Atan') -> 'T_Atan'\n",
      " |      [üåê Atan(7)](https://onnx.ai/onnx/operators/onnx__Atan.html#atan-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the arctangent (inverse of tangent) of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Cos(self, input: 'T_Cos') -> 'T_Cos'\n",
      " |      [üåê Cos(7)](https://onnx.ai/onnx/operators/onnx__Cos.html#cos-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the cosine of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Multinomial(self, input: 'T1_Multinomial', *, dtype: 'int' = 6, sample_size: 'int' = 1, seed: 'Optional[float]' = None) -> 'T2_Multinomial'\n",
      " |      [üåê Multinomial(7)](https://onnx.ai/onnx/operators/onnx__Multinomial.html#multinomial-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor of samples from a multinomial distribution according to the probabilities\n",
      " |      of each of the possible outcomes.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: Input tensor with shape [batch_size, class_size], where class_size is\n",
      " |              the number of all possible outcomes. Each value along the axis zero\n",
      " |              represents the unnormalized log-probability of each corresponding\n",
      " |              outcome in a batch.\n",
      " |      \n",
      " |          dtype: (Optional) The data type for the elements of the output tensor, if\n",
      " |              not specified, we will use int32.\n",
      " |      \n",
      " |          sample_size: Number of times to sample.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  Or(self, A: 'T_Or', B: 'T_Or') -> 'T1_Or'\n",
      " |      [üåê Or(7)](https://onnx.ai/onnx/operators/onnx__Or.html#or-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `or` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Sin(self, input: 'T_Sin') -> 'T_Sin'\n",
      " |      [üåê Sin(7)](https://onnx.ai/onnx/operators/onnx__Sin.html#sin-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the sine of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Tan(self, input: 'T_Tan') -> 'T_Tan'\n",
      " |      [üåê Tan(7)](https://onnx.ai/onnx/operators/onnx__Tan.html#tan-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the tangent of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Xor(self, A: 'T_Xor', B: 'T_Xor') -> 'T1_Xor'\n",
      " |      [üåê Xor(7)](https://onnx.ai/onnx/operators/onnx__Xor.html#xor-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `xor` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset7.Opset7:\n",
      " |  \n",
      " |  T1_And = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_Multinomial = ~T1_Multinomial\n",
      " |  \n",
      " |  T1_Or = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_Xor = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T2_Multinomial = typing.Union[onnxscript.onnx_types.INT32, onnxscript....\n",
      " |  \n",
      " |  T_Acos = ~T_Acos\n",
      " |  \n",
      " |  T_And = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T_Asin = ~T_Asin\n",
      " |  \n",
      " |  T_Atan = ~T_Atan\n",
      " |  \n",
      " |  T_Cos = ~T_Cos\n",
      " |  \n",
      " |  T_Or = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T_Sin = ~T_Sin\n",
      " |  \n",
      " |  T_Tan = ~T_Tan\n",
      " |  \n",
      " |  T_Xor = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset6.Opset6:\n",
      " |  \n",
      " |  Elu(self, X: 'T_Elu', *, alpha: 'float' = 1.0) -> 'T_Elu'\n",
      " |      [üåê Elu(6)](https://onnx.ai/onnx/operators/onnx__Elu.html#elu-6 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Elu takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the function `f(x) = alpha * (exp(x) - 1.) for x <\n",
      " |      0`, `f(x) = x for x >= 0`., is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) 1D input tensor\n",
      " |      \n",
      " |          alpha: Coefficient of ELU.\n",
      " |  \n",
      " |  HardSigmoid(self, X: 'T_HardSigmoid', *, alpha: 'float' = 0.20000000298023224, beta: 'float' = 0.5) -> 'T_HardSigmoid'\n",
      " |      [üåê HardSigmoid(6)](https://onnx.ai/onnx/operators/onnx__HardSigmoid.html#hardsigmoid-6 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      HardSigmoid takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the HardSigmoid function, y = max(0, min(1, alpha * x + beta)),\n",
      " |      is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: Value of alpha.\n",
      " |      \n",
      " |          beta: Value of beta.\n",
      " |  \n",
      " |  InstanceNormalization(self, input: 'T_InstanceNormalization', scale: 'T_InstanceNormalization', B: 'T_InstanceNormalization', *, epsilon: 'float' = 9.999999747378752e-06) -> 'T_InstanceNormalization'\n",
      " |      [üåê InstanceNormalization(6)](https://onnx.ai/onnx/operators/onnx__InstanceNormalization.html#instancenormalization-6 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Carries out instance normalization as described in the paper\n",
      " |      https://arxiv.org/abs/1607.08022.\n",
      " |      \n",
      " |      y = scale * (x - mean) / sqrt(variance + epsilon) + B,\n",
      " |      where mean and variance are computed per instance per channel.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input data tensor from the previous operator;\n",
      " |              dimensions for image case are (N x C x H x W), where N is the batch\n",
      " |              size, C is the number of channels, and H and W are the height and the\n",
      " |              width of the data. For non image case, the dimensions are in the form of\n",
      " |              (N x C x D1 x D2 ... Dn), where N is the batch size.\n",
      " |      \n",
      " |          scale: (differentiable) The input 1-dimensional scale tensor of size C.\n",
      " |      \n",
      " |          B: (differentiable) The input 1-dimensional bias tensor of size C.\n",
      " |      \n",
      " |          epsilon: The epsilon value to use to avoid division by zero.\n",
      " |  \n",
      " |  Selu(self, X: 'T_Selu', *, alpha: 'float' = 1.6732631921768188, gamma: 'float' = 1.0507010221481323) -> 'T_Selu'\n",
      " |      [üåê Selu(6)](https://onnx.ai/onnx/operators/onnx__Selu.html#selu-6 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Selu takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the scaled exponential linear unit function,\n",
      " |      `y = gamma * (alpha * e^x - alpha) for x <= 0`, `y = gamma * x for x > 0`,\n",
      " |      is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: Coefficient of SELU default to 1.67326319217681884765625 (i.e.,\n",
      " |              float32 approximation of 1.6732632423543772848170429916717).\n",
      " |      \n",
      " |          gamma: Coefficient of SELU default to 1.05070102214813232421875 (i.e.,\n",
      " |              float32 approximation of 1.0507009873554804934193349852946).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset6.Opset6:\n",
      " |  \n",
      " |  T_Elu = ~T_Elu\n",
      " |  \n",
      " |  T_HardSigmoid = ~T_HardSigmoid\n",
      " |  \n",
      " |  T_InstanceNormalization = ~T_InstanceNormalization\n",
      " |  \n",
      " |  T_Selu = ~T_Selu\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset2.Opset2:\n",
      " |  \n",
      " |  GlobalLpPool(self, X: 'T_GlobalLpPool', *, p: 'int' = 2) -> 'T_GlobalLpPool'\n",
      " |      [üåê GlobalLpPool(2)](https://onnx.ai/onnx/operators/onnx__GlobalLpPool.html#globallppool-2 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       GlobalLpPool consumes an input tensor X and applies lp pool pooling across\n",
      " |       the values in the same channel. This is equivalent to LpPool with kernel size\n",
      " |       equal to the spatial dimension of input tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size.\n",
      " |      \n",
      " |          p: p value of the Lp norm used to pool over the input data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset2.Opset2:\n",
      " |  \n",
      " |  T_GlobalLpPool = ~T_GlobalLpPool\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset1.Opset1:\n",
      " |  \n",
      " |  GlobalAveragePool(self, X: 'T_GlobalAveragePool') -> 'T_GlobalAveragePool'\n",
      " |      [üåê GlobalAveragePool(1)](https://onnx.ai/onnx/operators/onnx__GlobalAveragePool.html#globalaveragepool-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       GlobalAveragePool consumes an input tensor X and applies average pooling across\n",
      " |       the values in the same channel. This is equivalent to AveragePool with kernel size\n",
      " |       equal to the spatial dimension of input tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size.\n",
      " |  \n",
      " |  GlobalMaxPool(self, X: 'T_GlobalMaxPool') -> 'T_GlobalMaxPool'\n",
      " |      [üåê GlobalMaxPool(1)](https://onnx.ai/onnx/operators/onnx__GlobalMaxPool.html#globalmaxpool-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       GlobalMaxPool consumes an input tensor X and applies max pooling across\n",
      " |       the values in the same channel. This is equivalent to MaxPool with kernel size\n",
      " |       equal to the spatial dimension of input tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size.\n",
      " |  \n",
      " |  LpNormalization(self, input: 'T_LpNormalization', *, axis: 'int' = -1, p: 'int' = 2) -> 'T_LpNormalization'\n",
      " |      [üåê LpNormalization(1)](https://onnx.ai/onnx/operators/onnx__LpNormalization.html#lpnormalization-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given a matrix, apply Lp-normalization along the provided axis.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input matrix\n",
      " |      \n",
      " |          axis: The axis on which to apply normalization, -1 mean last axis.\n",
      " |      \n",
      " |          p: The order of the normalization, only 1 or 2 are supported.\n",
      " |  \n",
      " |  MaxRoiPool(self, X: 'T_MaxRoiPool', rois: 'T_MaxRoiPool', *, pooled_shape: 'Sequence[int]', spatial_scale: 'float' = 1.0) -> 'T_MaxRoiPool'\n",
      " |      [üåê MaxRoiPool(1)](https://onnx.ai/onnx/operators/onnx__MaxRoiPool.html#maxroipool-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       ROI max pool consumes an input tensor X and region of interests (RoIs) to\n",
      " |       apply max pooling across each RoI, to produce output 4-D tensor of shape\n",
      " |       (num_rois, channels, pooled_shape[0], pooled_shape[1]).\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data.\n",
      " |      \n",
      " |          rois: (non-differentiable) RoIs (Regions of Interest) to pool over. Should\n",
      " |              be a 2-D tensor of shape (num_rois, 5) given as [[batch_id, x1, y1, x2,\n",
      " |              y2], ...].\n",
      " |      \n",
      " |          pooled_shape: ROI pool output shape (height, width).\n",
      " |      \n",
      " |          spatial_scale: Multiplicative spatial scale factor to translate ROI\n",
      " |              coordinates from their input scale to the scale used when pooling.\n",
      " |  \n",
      " |  Not(self, X: 'T_Not') -> 'T_Not'\n",
      " |      [üåê Not(1)](https://onnx.ai/onnx/operators/onnx__Not.html#not-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the negation of the input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  RandomNormal(self, *, dtype: 'int' = 1, mean: 'float' = 0.0, scale: 'float' = 1.0, seed: 'Optional[float]' = None, shape: 'Sequence[int]') -> 'T_RandomNormal'\n",
      " |      [üåê RandomNormal(1)](https://onnx.ai/onnx/operators/onnx__RandomNormal.html#randomnormal-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with random values drawn from a normal distribution. The shape\n",
      " |      of the tensor is specified by the `shape` argument and the parameter of the normal distribution\n",
      " |      specified by `mean` and `scale`.\n",
      " |      \n",
      " |      The data type is specified by the 'dtype' argument. The 'dtype' argument must\n",
      " |      be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          dtype: The data type for the elements of the output tensor. Default is\n",
      " |              TensorProto::FLOAT.\n",
      " |      \n",
      " |          mean: The mean of the normal distribution.\n",
      " |      \n",
      " |          scale: The standard deviation of the normal distribution.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |      \n",
      " |          shape: The shape of the output tensor.\n",
      " |  \n",
      " |  RandomNormalLike(self, input: 'T1_RandomNormalLike', *, dtype: 'Optional[int]' = None, mean: 'float' = 0.0, scale: 'float' = 1.0, seed: 'Optional[float]' = None) -> 'T2_RandomNormalLike'\n",
      " |      [üåê RandomNormalLike(1)](https://onnx.ai/onnx/operators/onnx__RandomNormalLike.html#randomnormallike-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with random values drawn from a normal distribution.\n",
      " |      The shape of the output tensor is copied from the shape of the input tensor,\n",
      " |      and the parameters of the normal distribution are specified by `mean` and `scale`.\n",
      " |      \n",
      " |      The data type is specified by the 'dtype' argument, or copied from the input tensor if not provided.\n",
      " |      The 'dtype' argument must be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message, and be valid as an output type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: Input tensor to copy shape and optionally type information from.\n",
      " |      \n",
      " |          dtype: (Optional) The data type for the elements of the output tensor, if\n",
      " |              not specified, we will use the data type of the input tensor.\n",
      " |      \n",
      " |          mean: The mean of the normal distribution.\n",
      " |      \n",
      " |          scale: The standard deviation of the normal distribution.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  RandomUniform(self, *, dtype: 'int' = 1, high: 'float' = 1.0, low: 'float' = 0.0, seed: 'Optional[float]' = None, shape: 'Sequence[int]') -> 'T_RandomUniform'\n",
      " |      [üåê RandomUniform(1)](https://onnx.ai/onnx/operators/onnx__RandomUniform.html#randomuniform-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with random values drawn from a uniform distribution. The shape\n",
      " |      of the tensor is specified by the `shape` argument and the range by `low` and `high`.\n",
      " |      \n",
      " |      The data type is specified by the 'dtype' argument. The 'dtype' argument must\n",
      " |      be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          dtype: The data type for the elements of the output tensor. If not\n",
      " |              specified, default is TensorProto::FLOAT.\n",
      " |      \n",
      " |          high: Upper boundary of the output values.\n",
      " |      \n",
      " |          low: Lower boundary of the output values.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |      \n",
      " |          shape: The shape of the output tensor.\n",
      " |  \n",
      " |  RandomUniformLike(self, input: 'T1_RandomUniformLike', *, dtype: 'Optional[int]' = None, high: 'float' = 1.0, low: 'float' = 0.0, seed: 'Optional[float]' = None) -> 'T2_RandomUniformLike'\n",
      " |      [üåê RandomUniformLike(1)](https://onnx.ai/onnx/operators/onnx__RandomUniformLike.html#randomuniformlike-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with random values drawn from a uniform distribution.\n",
      " |      The shape of the output tensor is copied from the shape of the input tensor,\n",
      " |      and the parameters of the uniform distribution are specified by `low` and `high`.\n",
      " |      \n",
      " |      The data type is specified by the 'dtype' argument, or copied from the input tensor if not provided.\n",
      " |      The 'dtype' argument must be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message and be valid as an output type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: Input tensor to copy shape and optionally type information from.\n",
      " |      \n",
      " |          dtype: (Optional) The data type for the elements of the output tensor, if\n",
      " |              not specified, we will use the data type of the input tensor.\n",
      " |      \n",
      " |          high: Upper boundary of the output values.\n",
      " |      \n",
      " |          low: Lower boundary of the output values.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  Softplus(self, X: 'T_Softplus') -> 'T_Softplus'\n",
      " |      [üåê Softplus(1)](https://onnx.ai/onnx/operators/onnx__Softplus.html#softplus-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Softplus takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the softplus function, y = ln(exp(x) + 1), is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) 1D input tensor\n",
      " |  \n",
      " |  Softsign(self, input: 'T_Softsign') -> 'T_Softsign'\n",
      " |      [üåê Softsign(1)](https://onnx.ai/onnx/operators/onnx__Softsign.html#softsign-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the softsign (x/(1+|x|)) of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset1.Opset1:\n",
      " |  \n",
      " |  T1_RandomNormalLike = ~T1_RandomNormalLike\n",
      " |  \n",
      " |  T1_RandomUniformLike = ~T1_RandomUniformLike\n",
      " |  \n",
      " |  T2_RandomNormalLike = typing.Union[onnxscript.onnx_types.DOUBLE, onnxs...\n",
      " |  \n",
      " |  T2_RandomUniformLike = typing.Union[onnxscript.onnx_types.DOUBLE, onnx...\n",
      " |  \n",
      " |  T_GlobalAveragePool = ~T_GlobalAveragePool\n",
      " |  \n",
      " |  T_GlobalMaxPool = ~T_GlobalMaxPool\n",
      " |  \n",
      " |  T_LpNormalization = ~T_LpNormalization\n",
      " |  \n",
      " |  T_MaxRoiPool = ~T_MaxRoiPool\n",
      " |  \n",
      " |  T_Not = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T_RandomNormal = typing.Union[onnxscript.onnx_types.DOUBLE, onnxs....o...\n",
      " |  \n",
      " |  T_RandomUniform = typing.Union[onnxscript.onnx_types.DOUBLE, onnxs.......\n",
      " |  \n",
      " |  T_Softplus = ~T_Softplus\n",
      " |  \n",
      " |  T_Softsign = ~T_Softsign\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.values.Opset:\n",
      " |  \n",
      " |  __contains__(self, opname)\n",
      " |  \n",
      " |  __getattr__(self, attr: 'str')\n",
      " |  \n",
      " |  __getitem__(self, opname)\n",
      " |  \n",
      " |  __init__(self, domain: 'Optional[str]' = None, version: 'Optional[int]' = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add_function_def(self, fun)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from onnxscript.values.Opset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.values.Opset:\n",
      " |  \n",
      " |  cache = {(<class 'onnxscript.onnx_opset._impl.opset1.Opset1'>, '', 1):...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_SQRT1_2 = math.sqrt(0.5)\n",
    "\n",
    "@script()\n",
    "def gelu(X: FLOAT[...]):\n",
    "    phiX = 0.5* (op.Erf(M_SQRT1_2)*X+1.0)\n",
    "    return X * phiX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gelu_model = gelu.to_model_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"gelu.onnx\", \"wb\") as f:\n",
    "    f.write(gelu_model.SerializeToString(\"gelu.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxscript import STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Opset18 in module onnxscript.onnx_opset._impl.opset18 object:\n",
      "\n",
      "class Opset18(onnxscript.onnx_opset._impl.opset17.Opset17)\n",
      " |  Method resolution order:\n",
      " |      Opset18\n",
      " |      onnxscript.onnx_opset._impl.opset17.Opset17\n",
      " |      onnxscript.onnx_opset._impl.opset16.Opset16\n",
      " |      onnxscript.onnx_opset._impl.opset15.Opset15\n",
      " |      onnxscript.onnx_opset._impl.opset14.Opset14\n",
      " |      onnxscript.onnx_opset._impl.opset13.Opset13\n",
      " |      onnxscript.onnx_opset._impl.opset12.Opset12\n",
      " |      onnxscript.onnx_opset._impl.opset11.Opset11\n",
      " |      onnxscript.onnx_opset._impl.opset10.Opset10\n",
      " |      onnxscript.onnx_opset._impl.opset9.Opset9\n",
      " |      onnxscript.onnx_opset._impl.opset8.Opset8\n",
      " |      onnxscript.onnx_opset._impl.opset7.Opset7\n",
      " |      onnxscript.onnx_opset._impl.opset6.Opset6\n",
      " |      onnxscript.onnx_opset._impl.opset5.Opset5\n",
      " |      onnxscript.onnx_opset._impl.opset4.Opset4\n",
      " |      onnxscript.onnx_opset._impl.opset3.Opset3\n",
      " |      onnxscript.onnx_opset._impl.opset2.Opset2\n",
      " |      onnxscript.onnx_opset._impl.opset1.Opset1\n",
      " |      onnxscript.values.Opset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  BitwiseAnd(self, A: 'T_BitwiseAnd', B: 'T_BitwiseAnd') -> 'T_BitwiseAnd'\n",
      " |      [üåê BitwiseAnd(18)](https://onnx.ai/onnx/operators/onnx__BitwiseAnd.html#bitwiseand-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulting from performing the bitwise `and` operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the bitwise operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the bitwise operator.\n",
      " |  \n",
      " |  BitwiseNot(self, X: 'T_BitwiseNot') -> 'T_BitwiseNot'\n",
      " |      [üåê BitwiseNot(18)](https://onnx.ai/onnx/operators/onnx__BitwiseNot.html#bitwisenot-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the bitwise not of the input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  BitwiseOr(self, A: 'T_BitwiseOr', B: 'T_BitwiseOr') -> 'T_BitwiseOr'\n",
      " |      [üåê BitwiseOr(18)](https://onnx.ai/onnx/operators/onnx__BitwiseOr.html#bitwiseor-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulting from performing the bitwise `or` operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the bitwise operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the bitwise operator.\n",
      " |  \n",
      " |  BitwiseXor(self, A: 'T_BitwiseXor', B: 'T_BitwiseXor') -> 'T_BitwiseXor'\n",
      " |      [üåê BitwiseXor(18)](https://onnx.ai/onnx/operators/onnx__BitwiseXor.html#bitwisexor-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulting from performing the bitwise `xor` operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the bitwise operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the bitwise operator.\n",
      " |  \n",
      " |  CenterCropPad(self, input_data: 'T_CenterCropPad', shape: 'Tind_CenterCropPad', *, axes: 'Optional[Sequence[int]]' = None) -> 'T_CenterCropPad'\n",
      " |      [üåê CenterCropPad(18)](https://onnx.ai/onnx/operators/onnx__CenterCropPad.html#centercroppad-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Center crop or pad an input to given dimensions.\n",
      " |      \n",
      " |      The crop/pad dimensions can be specified for a subset of the `axes`. Non-specified dimensions will not be\n",
      " |      cropped or padded.\n",
      " |      \n",
      " |      If the input dimensions are bigger than the crop shape, a centered cropping window is extracted from the input.\n",
      " |      If the input dimensions are smaller than the crop shape, the input is padded on each side equally,\n",
      " |      so that the input is centered in the output.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_data: (differentiable) Input to extract the centered crop from.\n",
      " |      \n",
      " |          shape: (non-differentiable) 1-D tensor representing the cropping window\n",
      " |              dimensions.\n",
      " |      \n",
      " |          axes: If provided, it specifies a subset of axes that 'shape' refer to. If\n",
      " |              not provided, all axes are assumed [0, 1, ..., r-1], where r =\n",
      " |              rank(data). Negative value means counting dimensions from the back.\n",
      " |              Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined\n",
      " |              if an axis is repeated.\n",
      " |  \n",
      " |  Col2Im(self, input: 'T_Col2Im', image_shape: 'INT64', block_shape: 'INT64', *, dilations: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_Col2Im'\n",
      " |      [üåê Col2Im(18)](https://onnx.ai/onnx/operators/onnx__Col2Im.html#col2im-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator rearranges column blocks back into a multidimensional image\n",
      " |      \n",
      " |      Col2Im behaves similarly to PyTorch's fold https://pytorch.org/docs/stable/generated/torch.nn.Fold.html,\n",
      " |      but it only supports *batched* multi-dimensional image tensors.\n",
      " |      Another implementation in Python with N-dimension support can be found at https://github.com/f-dangel/unfoldNd/.\n",
      " |      \n",
      " |      NOTE:\n",
      " |        Although specifying image_shape looks redundant because it could be calculated from\n",
      " |        convolution formulas, it is required as input for more advanced scenarios as explained\n",
      " |        at PyTorch's implementation (https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Col2Im.cpp#L10)\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input data tensor to be rearranged from column\n",
      " |              blocks back into an image. This is a 3-dimensional tensor containing [N,\n",
      " |              C * n-ary-product(block_shape), L], where N is batch dimension, C is\n",
      " |              image channel dimension and L is number of blocks.The blocks are\n",
      " |              enumerated in increasing lexicographic-order of their indices.For\n",
      " |              example, with an image-size 10*20 and block-size 9*18, there would be\n",
      " |              2*3 blocks, enumerated in the order block(0, 0), block(0, 1), block(0,\n",
      " |              2), block(1, 0), block(1, 1), block(1, 2).\n",
      " |      \n",
      " |          image_shape: (non-differentiable) The shape of the spatial dimensions of the\n",
      " |              image after rearranging the column blocks.This is a 1-dimensional tensor\n",
      " |              with size of at least 2, containing the value [H_img, W_img]  for a 2-D\n",
      " |              image or [dim_i1, dim_i2, ..., dim_iN] for a N-D image.\n",
      " |      \n",
      " |          block_shape: (non-differentiable) The shape of the block to apply on the\n",
      " |              input.This is a 1-dimensional tensor of size of at least 2, containing\n",
      " |              the value [H_block, W_block]  for a 2-D image or [dim_b1, dim_b2, ...,\n",
      " |              dim_bN] for a N-D block.This is the block-shape before dilation is\n",
      " |              applied to it.\n",
      " |      \n",
      " |          dilations: 1-dimensional tensor with dilation value along each spatial axis\n",
      " |              of the image. If not present, the dilation defaults to 1 along each\n",
      " |              spatial axis of the image.\n",
      " |      \n",
      " |          pads: 1-dimensional tensor with padding value for the beginning and ending\n",
      " |              along each spatial axis, it can take any value greater than or equal to\n",
      " |              0. The value represent the number of pixels added to the beginning and\n",
      " |              end part of the corresponding axis. `pads` format should be as follow\n",
      " |              [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin is the number\n",
      " |              of pixels added at the beginning of axis `i` and xi_end is the number of\n",
      " |              pixels added at the end of axis `i`. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: 1-dimensional tensor with stride value along each spatial axis. If\n",
      " |              not present, the stride defaults to 1 along each spatial axis.\n",
      " |  \n",
      " |  GroupNormalization(self, X: 'T_GroupNormalization', scale: 'T_GroupNormalization', bias: 'T_GroupNormalization', *, epsilon: 'float' = 9.999999747378752e-06, num_groups: 'int') -> 'T_GroupNormalization'\n",
      " |      [üåê GroupNormalization(18)](https://onnx.ai/onnx/operators/onnx__GroupNormalization.html#groupnormalization-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      A GroupNormalization function. Carries out group normalization as described in\n",
      " |      the paper https://arxiv.org/abs/1803.08494\n",
      " |      \n",
      " |      This operator transforms input according to\n",
      " |      ::\n",
      " |      \n",
      " |          y = scale * (x - mean) / sqrt(variance + epsilon) + bias,\n",
      " |      \n",
      " |      \n",
      " |      where the mean and variance are computed per instance per group of channels, and\n",
      " |      `scale` and `bias` should be specified for each group of channels. The number of\n",
      " |      groups `num_groups` should be divisible by the number of channels so that there are\n",
      " |      an equal number of channels per group.\n",
      " |      \n",
      " |      When the number of groups is the same as the number of channels, this operator is\n",
      " |      equivalent to InstanceNormalization. When there is only one group, this operator\n",
      " |      is equivalent to LayerNormalization.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor. Dimensions for image cases are `(N x\n",
      " |              C x H x W)`, where `N` is the batch size, `C` is the number of channels,\n",
      " |              and `H` and `W` are the height and width of the data. Statistics are\n",
      " |              computed for every group of channels over `C`, `H`, and `W`. For\n",
      " |              non-image cases, the dimensions are in the form of `(N x C x D1 x D2 ...\n",
      " |              Dn)`.\n",
      " |      \n",
      " |          scale: (differentiable) Scale tensor of shape `(num_groups)`.\n",
      " |      \n",
      " |          bias: (differentiable) Bias tensor of shape `(num_groups)`.\n",
      " |      \n",
      " |          epsilon: The epsilon value to use to avoid division by zero.\n",
      " |      \n",
      " |          num_groups: The number of groups of channels. It should be a divisor of the\n",
      " |              number of channels `C`.\n",
      " |  \n",
      " |  LpPool(self, X: 'T_LpPool', *, auto_pad: 'str' = 'NOTSET', ceil_mode: 'int' = 0, dilations: 'Optional[Sequence[int]]' = None, kernel_shape: 'Sequence[int]', p: 'int' = 2, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_LpPool'\n",
      " |      [üåê LpPool(18)](https://onnx.ai/onnx/operators/onnx__LpPool.html#lppool-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       LpPool consumes an input tensor X and applies Lp pooling across\n",
      " |       the tensor according to kernel sizes, stride sizes, and pad lengths.\n",
      " |       Lp pooling consisting of computing the Lp norm on all values of a subset\n",
      " |       of the input tensor according to the kernel size and downsampling the\n",
      " |       data into the output tensor Y for further processing. The output spatial shape will be following:\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - {kernelSpatialShape}) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       or\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - {kernelSpatialShape}) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       if ceil_mode is enabled `pad_shape[i]` is the sum of pads along axis `i`.\n",
      " |      \n",
      " |       `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n",
      " |       ```\n",
      " |       VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - {kernelSpatialShape} + 1) / strides_spatial_shape[i])\n",
      " |       SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n",
      " |       ```\n",
      " |       And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n",
      " |       ```\n",
      " |       pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + {kernelSpatialShape} - input_spatial_shape[i]\n",
      " |       ```\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size.\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          ceil_mode: Whether to use ceil or floor (default) to compute the output\n",
      " |              shape.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults is 1 along each spatial axis.\n",
      " |      \n",
      " |          kernel_shape: The size of the kernel along each axis.\n",
      " |      \n",
      " |          p: p value of the Lp norm used to pool over the input data.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  Mish(self, X: 'T_Mish') -> 'T_Mish'\n",
      " |      [üåê Mish(18)](https://onnx.ai/onnx/operators/onnx__Mish.html#mish-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Mish: A Self Regularized Non-Monotonic Neural Activation Function.\n",
      " |      \n",
      " |      Perform the linear unit element-wise on the input tensor X using formula:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  OptionalGetElement(self, input: 'O_OptionalGetElement') -> 'V_OptionalGetElement'\n",
      " |      [üåê OptionalGetElement(18)](https://onnx.ai/onnx/operators/onnx__OptionalGetElement.html#optionalgetelement-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      If the input is a tensor or sequence type, it returns the input.\n",
      " |      If the input is an optional type, it outputs the element in the input.\n",
      " |      It is an error if the input is an empty optional-type (i.e. does not have an element) and the behavior is undefined in this case.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: The optional input.\n",
      " |  \n",
      " |  OptionalHasElement(self, input: 'Optional[O_OptionalHasElement]' = None) -> 'B_OptionalHasElement'\n",
      " |      [üåê OptionalHasElement(18)](https://onnx.ai/onnx/operators/onnx__OptionalHasElement.html#optionalhaselement-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns true if (1) the input is an optional-type and contains an element,\n",
      " |      or, (2) the input is a tensor or sequence type.\n",
      " |      If the input is not provided or is an empty optional-type, this op returns false.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (optional) The optional input.\n",
      " |  \n",
      " |  Pad(self, data: 'T_Pad', pads: 'INT64', constant_value: 'Optional[T_Pad]' = None, axes: 'Optional[Tind_Pad]' = None, *, mode: 'str' = 'constant') -> 'T_Pad'\n",
      " |      [üåê Pad(18)](https://onnx.ai/onnx/operators/onnx__Pad.html#pad-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given a tensor containing the data to be padded (`data`), a tensor containing the number of start and end pad values for axis (`pads`), (optionally) a `mode`, and (optionally) `constant_value`,\n",
      " |      a padded tensor (`output`) is generated.\n",
      " |      \n",
      " |      The three supported `modes` are (similar to corresponding modes supported by `numpy.pad`):\n",
      " |      \n",
      " |      1) `constant`(default) - pads with a given constant value as specified by `constant_value` (which defaults to 0, empty string, or False)\n",
      " |      \n",
      " |      2) `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis\n",
      " |      \n",
      " |      3) `edge` - pads with the edge values of array\n",
      " |      \n",
      " |      \n",
      " |      Example 1 (`constant` mode):\n",
      " |      \n",
      " |      Insert 0 pads to the beginning of the second dimension.\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2],\n",
      " |              [2.3, 3.4],\n",
      " |              [4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |          pads = [0, 2, 0, 0]\n",
      " |      \n",
      " |          mode = 'constant'\n",
      " |      \n",
      " |          constant_value = 0.0\n",
      " |      \n",
      " |          output = [\n",
      " |              [0.0, 0.0, 1.0, 1.2],\n",
      " |              [0.0, 0.0, 2.3, 3.4],\n",
      " |              [0.0, 0.0, 4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2 (`reflect` mode):\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2],\n",
      " |              [2.3, 3.4],\n",
      " |              [4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |          pads = [0, 2, 0, 0]\n",
      " |      \n",
      " |          mode = 'reflect'\n",
      " |      \n",
      " |          output = [\n",
      " |              [1.0, 1.2, 1.0, 1.2],\n",
      " |              [2.3, 3.4, 2.3, 3.4],\n",
      " |              [4.5, 5.7, 4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 3 (`edge` mode):\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2],\n",
      " |              [2.3, 3.4],\n",
      " |              [4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |          pads = [0, 2, 0, 0]\n",
      " |      \n",
      " |          mode = 'edge'\n",
      " |      \n",
      " |          output = [\n",
      " |              [1.0, 1.0, 1.0, 1.2],\n",
      " |              [2.3, 2.3, 2.3, 3.4],\n",
      " |              [4.5, 4.5, 4.5, 5.7],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Input tensor.\n",
      " |      \n",
      " |          pads: (non-differentiable) Tensor of integers indicating the number of\n",
      " |              padding elements to add or remove (if negative) at the beginning and end\n",
      " |              of each axis. For 2D input tensor, it is the number of pixels. `pads`\n",
      " |              should be a 1D tensor of shape [2 * num_axes] where `num_axes` refers to\n",
      " |              the number of elements in the `axes` input or the input rank if `axes`\n",
      " |              are not provided explicitly. `pads` format should be: [x1_begin,\n",
      " |              x2_begin, ..., x1_end, x2_end,...], where xi_begin is the number of pad\n",
      " |              values added at the beginning of axis `axes[i]` and xi_end, the number\n",
      " |              of pad values added at the end of axis `axes[i]`.\n",
      " |      \n",
      " |          constant_value: (optional, non-differentiable) (Optional) A scalar value to\n",
      " |              be used if the mode chosen is `constant` (by default it is 0, empty\n",
      " |              string or False).\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) 1-D tensor of axes that `pads` apply\n",
      " |              to. Negative value means counting dimensions from the back. Accepted\n",
      " |              range is [-r, r-1] where r = rank(data). Behavior is undefined if an\n",
      " |              axis is repeated. If not provided, all axes are assumed (`[0, 1, ...,\n",
      " |              input_rank-1]`).\n",
      " |      \n",
      " |          mode: Supported modes: `constant`(default), `reflect`, `edge`\n",
      " |  \n",
      " |  ReduceL1(self, data: 'T_ReduceL1', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceL1'\n",
      " |      [üåê ReduceL1(18)](https://onnx.ai/onnx/operators/onnx__ReduceL1.html#reducel1-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the L1 norm of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceL2(self, data: 'T_ReduceL2', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceL2'\n",
      " |      [üåê ReduceL2(18)](https://onnx.ai/onnx/operators/onnx__ReduceL2.html#reducel2-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the L2 norm of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceLogSum(self, data: 'T_ReduceLogSum', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceLogSum'\n",
      " |      [üåê ReduceLogSum(18)](https://onnx.ai/onnx/operators/onnx__ReduceLogSum.html#reducelogsum-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the log sum of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceLogSumExp(self, data: 'T_ReduceLogSumExp', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceLogSumExp'\n",
      " |      [üåê ReduceLogSumExp(18)](https://onnx.ai/onnx/operators/onnx__ReduceLogSumExp.html#reducelogsumexp-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the log sum exponent of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceMax(self, data: 'T_ReduceMax', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceMax'\n",
      " |      [üåê ReduceMax(18)](https://onnx.ai/onnx/operators/onnx__ReduceMax.html#reducemax-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the max of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceMean(self, data: 'T_ReduceMean', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceMean'\n",
      " |      [üåê ReduceMean(18)](https://onnx.ai/onnx/operators/onnx__ReduceMean.html#reducemean-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the mean of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceMin(self, data: 'T_ReduceMin', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceMin'\n",
      " |      [üåê ReduceMin(18)](https://onnx.ai/onnx/operators/onnx__ReduceMin.html#reducemin-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the min of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceProd(self, data: 'T_ReduceProd', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceProd'\n",
      " |      [üåê ReduceProd(18)](https://onnx.ai/onnx/operators/onnx__ReduceProd.html#reduceprod-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the product of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  ReduceSumSquare(self, data: 'T_ReduceSumSquare', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceSumSquare'\n",
      " |      [üåê ReduceSumSquare(18)](https://onnx.ai/onnx/operators/onnx__ReduceSumSquare.html#reducesumsquare-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the sum square of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  Resize(self, X: 'T1_Resize', roi: 'Optional[T2_Resize]' = None, scales: 'Optional[FLOAT]' = None, sizes: 'Optional[INT64]' = None, *, antialias: 'int' = 0, axes: 'Optional[Sequence[int]]' = None, coordinate_transformation_mode: 'str' = 'half_pixel', cubic_coeff_a: 'float' = -0.75, exclude_outside: 'int' = 0, extrapolation_value: 'float' = 0.0, keep_aspect_ratio_policy: 'str' = 'stretch', mode: 'str' = 'nearest', nearest_mode: 'str' = 'round_prefer_floor') -> 'T1_Resize'\n",
      " |      [üåê Resize(18)](https://onnx.ai/onnx/operators/onnx__Resize.html#resize-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\n",
      " |      Each dimension value of the output tensor is: <br/>\n",
      " |        `output_dimension = floor(input_dimension * (roi_end - roi_start) * scale)` <br/>\n",
      " |      if input \\\"sizes\\\" is not specified.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) N-D tensor\n",
      " |      \n",
      " |          roi: (optional, non-differentiable) 1-D tensor given as [start1, ...,\n",
      " |              startN, end1, ..., endN], where N is the rank of X or the length of\n",
      " |              axes, if provided. The RoIs' coordinates are normalized in the\n",
      " |              coordinate system of the input image. It only takes effect when\n",
      " |              coordinate_transformation_mode is \"tf_crop_and_resize\"\n",
      " |      \n",
      " |          scales: (optional, non-differentiable) The scale array along each dimension.\n",
      " |              It takes value greater than 0. If it's less than 1, it's sampling down,\n",
      " |              otherwise, it's upsampling. The number of elements of 'scales' should be\n",
      " |              the same as the rank of input 'X' or the length of 'axes', if provided.\n",
      " |              One of 'scales' and 'sizes' MUST be specified and it is an error if both\n",
      " |              are specified. If 'sizes' is needed, the user can use an empty string as\n",
      " |              the name of 'scales' in this operator's input list.\n",
      " |      \n",
      " |          sizes: (optional, non-differentiable) Target size of the output tensor. Its\n",
      " |              interpretation depends on the 'keep_aspect_ratio_policy' value.The\n",
      " |              number of elements of 'sizes' should be the same as the rank of input\n",
      " |              'X', or the length of 'axes', if provided. Only one of 'scales' and\n",
      " |              'sizes' can be specified.\n",
      " |      \n",
      " |          antialias: If set to 1, \"linear\" and \"cubic\" interpolation modes will use an\n",
      " |              antialiasing filter when downscaling. Antialiasing is achieved by\n",
      " |              stretching the resampling filter by a factor max(1, 1 / scale), which\n",
      " |              means that when downsampling, more input pixels contribute to an output\n",
      " |              pixel.\n",
      " |      \n",
      " |          axes: If provided, it specifies a subset of axes that 'roi', 'scales' and\n",
      " |              'sizes' refer to. If not provided, all axes are assumed [0, 1, ...,\n",
      " |              r-1], where r = rank(data). Non-specified dimensions are interpreted as\n",
      " |              non-resizable. Negative value means counting dimensions from the back.\n",
      " |              Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined\n",
      " |              if an axis is repeated.\n",
      " |      \n",
      " |          coordinate_transformation_mode:\n",
      " |      This attribute describes how to transform\n",
      " |              the coordinate in the resized tensor to the coordinate in the original\n",
      " |              tensor. <br/>\n",
      " |      \n",
      " |      The coordinate of each dimension is transformed\n",
      " |              individually. Let's describe a case using axis x as an example.\n",
      " |      Denote\n",
      " |              x_resized as the coordinate of axis x in the resized tensor, x_original\n",
      " |              as the coordinate of axis x in the original tensor, `length_original` as\n",
      " |              the length of the original tensor in axis x, length_resized as the\n",
      " |              length of the resized tensor in axis x, roi_x = (start_x, end_x) of the\n",
      " |              axis x in input \"roi\", `scale = length_resized / length_original`, <br/>\n",
      " |              if coordinate_transformation_mode is `\"half_pixel\"`, <br/>\n",
      " |      `x_original =\n",
      " |              (x_resized + 0.5) / scale - 0.5` <br/>\n",
      " |      \n",
      " |      if\n",
      " |              coordinate_transformation_mode is `\"pytorch_half_pixel\"`, <br/>\n",
      " |              `x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0`\n",
      " |              <br/>\n",
      " |      \n",
      " |      if coordinate_transformation_mode is `\"align_corners\"`, <br/>\n",
      " |              `x_original = x_resized * (length_original - 1) / (length_resized - 1)`\n",
      " |              <br/>\n",
      " |      \n",
      " |      if coordinate_transformation_mode is `\"asymmetric\"`, <br/>\n",
      " |              `x_original = x_resized / scale` <br/>\n",
      " |      \n",
      " |      if\n",
      " |              coordinate_transformation_mode is `\"tf_crop_and_resize\"`, <br/>\n",
      " |              `x_original = length_resized > 1 ? start_x * (length_original - 1) +\n",
      " |              x_resized * (end_x - start_x) * (length_original - 1) / (length_resized\n",
      " |              - 1) : 0.5 * (start_x + end_x) * (length_original - 1)`\n",
      " |      .\n",
      " |      \n",
      " |          cubic_coeff_a: The coefficient 'a' used in cubic interpolation. Two common\n",
      " |              choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch).\n",
      " |              Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711\n",
      " |              for the details. This attribute is valid only if mode is \"cubic\".\n",
      " |      \n",
      " |          exclude_outside: If set to 1, the weight of sampling locations outside the\n",
      " |              tensor will be set to 0 and the weight will be renormalized so that\n",
      " |              their sum is 1.0. The default value is 0.\n",
      " |      \n",
      " |          extrapolation_value: When coordinate_transformation_mode is\n",
      " |              \"tf_crop_and_resize\" and x_original is outside the range [0,\n",
      " |              length_original - 1], this value is used as the corresponding output\n",
      " |              value. Default is 0.0f.\n",
      " |      \n",
      " |          keep_aspect_ratio_policy:\n",
      " |      This attribute describes how to interpret the\n",
      " |              `sizes` input with regard to keeping the original aspect ratio of the\n",
      " |              input, and it is not applicable when\n",
      " |      the `scales` input is used. <br/>\n",
      " |              Given a set of `sizes`, associated with a subset of `axes` (explicitly\n",
      " |              provided or default), and assuming `d = axes[i]`, with `i` being the\n",
      " |              index of the provided `sizes`. <br/>\n",
      " |      \n",
      " |      If `keep_aspect_ratio_policy` is\n",
      " |              `\"stretch\"`, the original aspect ratio is disregarded, and the input is\n",
      " |              resized to the specified size: <br/>\n",
      " |      `out_size[d] = sizes[i]` <br/>\n",
      " |      \n",
      " |      If\n",
      " |              `keep_aspect_ratio_policy` is `\"not_larger\"`, the sizes are adjusted so\n",
      " |              that no extent of the output is larger than the specified size, while\n",
      " |              keeping the original aspect ratio: <br/>\n",
      " |      `scale = Min(sizes[i] /\n",
      " |              in_size[d])` <br/>\n",
      " |      `out_size[d] = round_int(scale * in_size[i])` <br/>\n",
      " |              If `keep_aspect_ratio_policy` is `\"not_smaller\"`, the sizes are adjusted\n",
      " |              so that no extent of the output is smaller than the specified size,\n",
      " |              while keeping the original aspect ratio: <br/>\n",
      " |      `scale = Max(sizes[i] /\n",
      " |              in_size[d])` <br/>\n",
      " |      `out_size[d] = round_int(scale * in_size[i])` <br/>\n",
      " |              For non-resizable axes (those not specified in `axes`), the output size\n",
      " |              will be equal to the input size.\n",
      " |      \n",
      " |      Note: `round_int` stands for computing\n",
      " |              the nearest integer value, rounding halfway cases up.\n",
      " |      \n",
      " |          mode: Three interpolation modes: \"nearest\" (default), \"linear\" and \"cubic\".\n",
      " |              The \"linear\" mode includes linear interpolation for 1D tensor and\n",
      " |              N-linear interpolation for N-D tensor (for example, bilinear\n",
      " |              interpolation for 2D tensor). The \"cubic\" mode includes cubic\n",
      " |              interpolation for 1D tensor and N-cubic interpolation for N-D tensor\n",
      " |              (for example, bicubic interpolation for 2D tensor).\n",
      " |      \n",
      " |          nearest_mode: Four modes: \"round_prefer_floor\" (default, as known as round\n",
      " |              half down), \"round_prefer_ceil\" (as known as round half up), \"floor\",\n",
      " |              \"ceil\". Only used by nearest interpolation. It indicates how to get\n",
      " |              \"nearest\" pixel in input tensor from x_original, so this attribute is\n",
      " |              valid only if \"mode\" is \"nearest\".\n",
      " |  \n",
      " |  ScatterElements(self, data: 'T_ScatterElements', indices: 'Tind_ScatterElements', updates: 'T_ScatterElements', *, axis: 'int' = 0, reduction: 'str' = 'none') -> 'T_ScatterElements'\n",
      " |      [üåê ScatterElements(18)](https://onnx.ai/onnx/operators/onnx__ScatterElements.html#scatterelements-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      ScatterElements takes three inputs `data`, `updates`, and `indices` of the same\n",
      " |      rank r >= 1 and an optional attribute axis that identifies an axis of `data`\n",
      " |      (by default, the outer-most axis, that is axis 0). The output of the operation\n",
      " |      is produced by creating a copy of the input `data`, and then updating its value\n",
      " |      to values specified by `updates` at specific index positions specified by\n",
      " |      `indices`. Its output shape is the same as the shape of `data`.\n",
      " |      \n",
      " |      For each entry in `updates`, the target index in `data` is obtained by combining\n",
      " |      the corresponding entry in `indices` with the index of the entry itself: the\n",
      " |      index-value for dimension = axis is obtained from the value of the corresponding\n",
      " |      entry in `indices` and the index-value for dimension != axis is obtained from the\n",
      " |      index of the entry itself.\n",
      " |      \n",
      " |      `reduction` allows specification of an optional reduction operation, which is applied to all values in `updates`\n",
      " |      tensor into `output` at the specified `indices`.\n",
      " |      In cases where `reduction` is set to \"none\", indices should not have duplicate entries: that is, if idx1 != idx2,\n",
      " |      then indices[idx1] != indices[idx2]. For instance, in a 2-D tensor case, the update\n",
      " |      corresponding to the [i][j] entry is performed as below:\n",
      " |      ::\n",
      " |      \n",
      " |          output[indices[i][j]][j] = updates[i][j] if axis = 0,\n",
      " |          output[i][indices[i][j]] = updates[i][j] if axis = 1,\n",
      " |      \n",
      " |      \n",
      " |      When `reduction` is set to some reduction function `f`, the update corresponding to the [i][j] entry is performed as below:\n",
      " |      ::\n",
      " |      \n",
      " |          output[indices[i][j]][j] += f(output[indices[i][j]][j], updates[i][j]) if axis = 0,\n",
      " |          output[i][indices[i][j]] += f(output[i][indices[i][j]], updates[i][j]) if axis = 1,\n",
      " |      \n",
      " |      \n",
      " |      where the `f` is `+`, `*`, `max` or `min` as specified.\n",
      " |      \n",
      " |      This operator is the inverse of GatherElements. It is similar to Torch's Scatter operation.\n",
      " |      \n",
      " |      (Opset 18 change): Adds max/min to the set of allowed reduction ops.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [0.0, 0.0, 0.0],\n",
      " |              [0.0, 0.0, 0.0],\n",
      " |              [0.0, 0.0, 0.0],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [1, 0, 2],\n",
      " |              [0, 2, 1],\n",
      " |          ]\n",
      " |          updates = [\n",
      " |              [1.0, 1.1, 1.2],\n",
      " |              [2.0, 2.1, 2.2],\n",
      " |          ]\n",
      " |          output = [\n",
      " |              [2.0, 1.1, 0.0]\n",
      " |              [1.0, 0.0, 2.2]\n",
      " |              [0.0, 2.1, 1.2]\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      ::\n",
      " |      \n",
      " |          data = [[1.0, 2.0, 3.0, 4.0, 5.0]]\n",
      " |          indices = [[1, 3]]\n",
      " |          updates = [[1.1, 2.1]]\n",
      " |          axis = 1\n",
      " |          output = [[1.0, 1.1, 3.0, 2.1, 5.0]]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of int32/int64 indices, of r >= 1 (same\n",
      " |              rank as input). All index values are expected to be within bounds [-s,\n",
      " |              s-1] along axis of size s. It is an error if any of the index values are\n",
      " |              out of bounds.\n",
      " |      \n",
      " |          updates: (differentiable) Tensor of rank r >=1 (same rank and shape as\n",
      " |              indices)\n",
      " |      \n",
      " |          axis: Which axis to scatter on. Negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-r, r-1] where r = rank(data).\n",
      " |      \n",
      " |          reduction: Type of reduction to apply: none (default), add, mul, max, min.\n",
      " |              'none': no reduction applied. 'add':  reduction using the addition\n",
      " |              operation. 'mul': reduction using the multiplication operation.'max':\n",
      " |              reduction using the maximum operation.'min': reduction using the minimum\n",
      " |              operation.\n",
      " |  \n",
      " |  ScatterND(self, data: 'T_ScatterND', indices: 'INT64', updates: 'T_ScatterND', *, reduction: 'str' = 'none') -> 'T_ScatterND'\n",
      " |      [üåê ScatterND(18)](https://onnx.ai/onnx/operators/onnx__ScatterND.html#scatternd-18 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      ScatterND takes three inputs `data` tensor of rank r >= 1, `indices` tensor of rank q >= 1,\n",
      " |      and `updates` tensor of rank q + r - indices.shape[-1] - 1. The output of the operation\n",
      " |      is produced by creating a copy of the input `data`, and then updating its value to values\n",
      " |      specified by `updates` at specific index positions specified by `indices`. Its output shape\n",
      " |      is the same as the shape of `data`.\n",
      " |      \n",
      " |      `indices` is an integer tensor. Let k denote indices.shape[-1], the last dimension in the shape of `indices`.\n",
      " |      `indices` is treated as a (q-1)-dimensional tensor of k-tuples, where each k-tuple is a partial-index into `data`.\n",
      " |      Hence, k can be a value at most the rank of `data`. When k equals rank(data), each update entry specifies an\n",
      " |      update to a single element of the tensor. When k is less than rank(data) each update entry specifies an\n",
      " |      update to a slice of the tensor. Index values are allowed to be negative, as per the usual\n",
      " |      convention for counting backwards from the end, but are expected in the valid range.\n",
      " |      \n",
      " |      `updates` is treated as a (q-1)-dimensional tensor of replacement-slice-values. Thus, the\n",
      " |      first (q-1) dimensions of updates.shape must match the first (q-1) dimensions of indices.shape.\n",
      " |      The remaining dimensions of `updates` correspond to the dimensions of the\n",
      " |      replacement-slice-values. Each replacement-slice-value is a (r-k) dimensional tensor,\n",
      " |      corresponding to the trailing (r-k) dimensions of `data`.  Thus, the shape of `updates`\n",
      " |      must equal indices.shape[0:q-1] ++ data.shape[k:r-1], where ++ denotes the concatenation\n",
      " |      of shapes.\n",
      " |      \n",
      " |      The `output` is calculated via the following equation:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          output = np.copy(data)\n",
      " |          update_indices = indices.shape[:-1]\n",
      " |          for idx in np.ndindex(update_indices):\n",
      " |              output[indices[idx]] = updates[idx]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      The order of iteration in the above loop is not specified.\n",
      " |      In particular, indices should not have duplicate entries: that is, if idx1 != idx2, then indices[idx1] != indices[idx2].\n",
      " |      This ensures that the output value does not depend on the iteration order.\n",
      " |      \n",
      " |      `reduction` allows specification of an optional reduction operation, which is applied to all values in `updates`\n",
      " |      tensor into `output` at the specified `indices`.\n",
      " |      In cases where `reduction` is set to \"none\", indices should not have duplicate entries: that is, if idx1 != idx2,\n",
      " |      then indices[idx1] != indices[idx2]. This ensures that the output value does not depend on the iteration order.\n",
      " |      When `reduction` is set to some reduction function `f`, `output` is calculated as follows:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          output = np.copy(data)\n",
      " |          update_indices = indices.shape[:-1]\n",
      " |          for idx in np.ndindex(update_indices):\n",
      " |              output[indices[idx]] = f(output[indices[idx]], updates[idx])\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      where the `f` is `+`, `*`, `max` or `min` as specified.\n",
      " |      \n",
      " |      This operator is the inverse of GatherND.\n",
      " |      \n",
      " |      (Opset 18 change): Adds max/min to the set of allowed reduction ops.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      ::\n",
      " |      \n",
      " |          data    = [1, 2, 3, 4, 5, 6, 7, 8]\n",
      " |          indices = [[4], [3], [1], [7]]\n",
      " |          updates = [9, 10, 11, 12]\n",
      " |          output  = [1, 11, 3, 10, 9, 6, 7, 12]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      ::\n",
      " |      \n",
      " |          data    = [[[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],\n",
      " |                      [[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],\n",
      " |                      [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]],\n",
      " |                      [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]]]\n",
      " |          indices = [[0], [2]]\n",
      " |          updates = [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      " |                      [[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4]]]\n",
      " |          output  = [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      " |                      [[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],\n",
      " |                      [[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4]],\n",
      " |                      [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]]]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of rank q >= 1.\n",
      " |      \n",
      " |          updates: (differentiable) Tensor of rank q + r - indices_shape[-1] - 1.\n",
      " |      \n",
      " |          reduction: Type of reduction to apply: none (default), add, mul, max, min.\n",
      " |              'none': no reduction applied. 'add':  reduction using the addition\n",
      " |              operation. 'mul':  reduction using the addition operation. 'max':\n",
      " |              reduction using the maximum operation.'min': reduction using the minimum\n",
      " |              operation.\n",
      " |  \n",
      " |  Split(self, input: 'T_Split', split: 'Optional[INT64]' = None, *, axis: 'int' = 0, num_outputs: 'Optional[int]' = None) -> 'T_Split'\n",
      " |      [üåê Split(18)](https://onnx.ai/onnx/operators/onnx__Split.html#split-18 \"Online Documentation\")\n",
      " |      \n",
      " |      Split a tensor into a list of tensors, along the specified 'axis'.\n",
      " |      Either input 'split' or the attribute 'num_outputs' should be specified, but not both.\n",
      " |      If the attribute 'num_outputs' is specified, then the tensor is split into equal sized parts.\n",
      " |      If the tensor is not evenly splittable into `num_outputs`, the last chunk will be smaller.\n",
      " |      If the input 'split' is specified, it indicates the sizes of each output in the split.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The tensor to split\n",
      " |      \n",
      " |          split: (optional, non-differentiable) Optional length of each output. Values\n",
      " |              should be >= 0.Sum of the values must be equal to the dim value at\n",
      " |              'axis' specified.\n",
      " |      \n",
      " |          axis: Which axis to split on. A negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-rank, rank-1] where r = rank(input).\n",
      " |      \n",
      " |          num_outputs: Number of outputs to split parts of the tensor into. If the\n",
      " |              tensor is not evenly splittable the last chunk will be smaller.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  B_OptionalHasElement = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  O_OptionalGetElement = ~O_OptionalGetElement\n",
      " |  \n",
      " |  O_OptionalHasElement = ~O_OptionalHasElement\n",
      " |  \n",
      " |  T1_Resize = ~T1_Resize\n",
      " |  \n",
      " |  T2_Resize = ~T2_Resize\n",
      " |  \n",
      " |  T_BitwiseAnd = ~T_BitwiseAnd\n",
      " |  \n",
      " |  T_BitwiseNot = ~T_BitwiseNot\n",
      " |  \n",
      " |  T_BitwiseOr = ~T_BitwiseOr\n",
      " |  \n",
      " |  T_BitwiseXor = ~T_BitwiseXor\n",
      " |  \n",
      " |  T_CenterCropPad = ~T_CenterCropPad\n",
      " |  \n",
      " |  T_Col2Im = ~T_Col2Im\n",
      " |  \n",
      " |  T_GroupNormalization = ~T_GroupNormalization\n",
      " |  \n",
      " |  T_LpPool = ~T_LpPool\n",
      " |  \n",
      " |  T_Mish = ~T_Mish\n",
      " |  \n",
      " |  T_Pad = ~T_Pad\n",
      " |  \n",
      " |  T_ReduceL1 = ~T_ReduceL1\n",
      " |  \n",
      " |  T_ReduceL2 = ~T_ReduceL2\n",
      " |  \n",
      " |  T_ReduceLogSum = ~T_ReduceLogSum\n",
      " |  \n",
      " |  T_ReduceLogSumExp = ~T_ReduceLogSumExp\n",
      " |  \n",
      " |  T_ReduceMax = ~T_ReduceMax\n",
      " |  \n",
      " |  T_ReduceMean = ~T_ReduceMean\n",
      " |  \n",
      " |  T_ReduceMin = ~T_ReduceMin\n",
      " |  \n",
      " |  T_ReduceProd = ~T_ReduceProd\n",
      " |  \n",
      " |  T_ReduceSumSquare = ~T_ReduceSumSquare\n",
      " |  \n",
      " |  T_ScatterElements = ~T_ScatterElements\n",
      " |  \n",
      " |  T_ScatterND = ~T_ScatterND\n",
      " |  \n",
      " |  T_Split = ~T_Split\n",
      " |  \n",
      " |  Tind_CenterCropPad = ~Tind_CenterCropPad\n",
      " |  \n",
      " |  Tind_Pad = ~Tind_Pad\n",
      " |  \n",
      " |  Tind_ScatterElements = ~Tind_ScatterElements\n",
      " |  \n",
      " |  V_OptionalGetElement = typing.Union[typing.Sequence[onnxscript.onnx_ty...\n",
      " |  \n",
      " |  __annotations__ = {'B_OptionalHasElement': 'TypeAlias', 'V_OptionalGet...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset17.Opset17:\n",
      " |  \n",
      " |  BlackmanWindow(self, size: 'T1_BlackmanWindow', *, output_datatype: 'int' = 1, periodic: 'int' = 1) -> 'T2_BlackmanWindow'\n",
      " |      [üåê BlackmanWindow(17)](https://onnx.ai/onnx/operators/onnx__BlackmanWindow.html#blackmanwindow-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generates a Blackman window as described in the paper https://ieeexplore.ieee.org/document/1455106.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          size: (non-differentiable) A scalar value indicating the length of the\n",
      " |              window.\n",
      " |      \n",
      " |          output_datatype: The data type of the output tensor. Strictly must be one of\n",
      " |              the values from DataType enum in TensorProto whose values correspond to\n",
      " |              T2. The default value is 1 = FLOAT.\n",
      " |      \n",
      " |          periodic: If 1, returns a window to be used as periodic function. If 0,\n",
      " |              return a symmetric window. When 'periodic' is specified, hann computes a\n",
      " |              window of length size + 1 and returns the first size points. The default\n",
      " |              value is 1.\n",
      " |  \n",
      " |  DFT(self, input: 'T1_DFT', dft_length: 'Optional[T2_DFT]' = None, *, axis: 'int' = 1, inverse: 'int' = 0, onesided: 'int' = 0) -> 'T1_DFT'\n",
      " |      [üåê DFT(17)](https://onnx.ai/onnx/operators/onnx__DFT.html#dft-17 \"Online Documentation\")\n",
      " |      \n",
      " |      Computes the discrete Fourier transform of input.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: (non-differentiable) For real input, the following shape is expected:\n",
      " |              [batch_idx][signal_dim1][signal_dim2]...[signal_dimN][1]. For complex\n",
      " |              input, the following shape is expected:\n",
      " |              [batch_idx][signal_dim1][signal_dim2]...[signal_dimN][2]. The first\n",
      " |              dimension is the batch dimension. The following N dimentions correspond\n",
      " |              to the signal's dimensions. The final dimension represents the real and\n",
      " |              imaginary parts of the value in that order.\n",
      " |      \n",
      " |          dft_length: (optional, non-differentiable) The length of the signal.If\n",
      " |              greater than the axis dimension, the signal will be zero-padded up to\n",
      " |              dft_length. If less than the axis dimension, only the first dft_length\n",
      " |              values will be used as the signal. It's an optional value.\n",
      " |      \n",
      " |          axis: The axis on which to perform the DFT. By default this value is set to\n",
      " |              1, which corresponds to the first dimension after the batch index.\n",
      " |      \n",
      " |          inverse: Whether to perform the inverse discrete fourier transform. By\n",
      " |              default this value is set to 0, which corresponds to false.\n",
      " |      \n",
      " |          onesided: If onesided is 1, only values for w in [0, 1, 2, ...,\n",
      " |              floor(n_fft/2) + 1] are returned because the real-to-complex Fourier\n",
      " |              transform satisfies the conjugate symmetry, i.e., X[m, w] =\n",
      " |              X[m,w]=X[m,n_fft-w]*. Note if the input or window tensors are complex,\n",
      " |              then onesided output is not possible. Enabling onesided with real inputs\n",
      " |              performs a Real-valued fast Fourier transform (RFFT). When invoked with\n",
      " |              real or complex valued input, the default value is 0. Values can be 0 or\n",
      " |              1.\n",
      " |  \n",
      " |  HammingWindow(self, size: 'T1_HammingWindow', *, output_datatype: 'int' = 1, periodic: 'int' = 1) -> 'T2_HammingWindow'\n",
      " |      [üåê HammingWindow(17)](https://onnx.ai/onnx/operators/onnx__HammingWindow.html#hammingwindow-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generates a Hamming window as described in the paper https://ieeexplore.ieee.org/document/1455106.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          size: (non-differentiable) A scalar value indicating the length of the\n",
      " |              window.\n",
      " |      \n",
      " |          output_datatype: The data type of the output tensor. Strictly must be one of\n",
      " |              the values from DataType enum in TensorProto whose values correspond to\n",
      " |              T2. The default value is 1 = FLOAT.\n",
      " |      \n",
      " |          periodic: If 1, returns a window to be used as periodic function. If 0,\n",
      " |              return a symmetric window. When 'periodic' is specified, hann computes a\n",
      " |              window of length size + 1 and returns the first size points. The default\n",
      " |              value is 1.\n",
      " |  \n",
      " |  HannWindow(self, size: 'T1_HannWindow', *, output_datatype: 'int' = 1, periodic: 'int' = 1) -> 'T2_HannWindow'\n",
      " |      [üåê HannWindow(17)](https://onnx.ai/onnx/operators/onnx__HannWindow.html#hannwindow-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generates a Hann window as described in the paper https://ieeexplore.ieee.org/document/1455106.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          size: (non-differentiable) A scalar value indicating the length of the\n",
      " |              window.\n",
      " |      \n",
      " |          output_datatype: The data type of the output tensor. Strictly must be one of\n",
      " |              the values from DataType enum in TensorProto whose values correspond to\n",
      " |              T2. The default value is 1 = FLOAT.\n",
      " |      \n",
      " |          periodic: If 1, returns a window to be used as periodic function. If 0,\n",
      " |              return a symmetric window. When 'periodic' is specified, hann computes a\n",
      " |              window of length size + 1 and returns the first size points. The default\n",
      " |              value is 1.\n",
      " |  \n",
      " |  LayerNormalization(self, X: 'T_LayerNormalization', Scale: 'T_LayerNormalization', B: 'Optional[T_LayerNormalization]' = None, *, axis: 'int' = -1, epsilon: 'float' = 9.999999747378752e-06, stash_type: 'int' = 1) -> 'Tuple[T_LayerNormalization, U_LayerNormalization, U_LayerNormalization]'\n",
      " |      [üåê LayerNormalization(17)](https://onnx.ai/onnx/operators/onnx__LayerNormalization.html#layernormalization-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |            This is layer normalization defined in ONNX as function.\n",
      " |            The overall computation can be split into two stages.\n",
      " |            The first stage is standardization, which makes the\n",
      " |            normalized elements have zero mean and unit variances.\n",
      " |            The computation required by standardization can be\n",
      " |            described by the following equations.\n",
      " |            ```\n",
      " |            Mean = ReduceMean<axes=normalized_axes>(X)\n",
      " |            D = Sub(X, Mean)\n",
      " |            DD = Mul(D, D)\n",
      " |            Var = ReduceMean<axes=normalized_axes>(DD)\n",
      " |            VarEps = Add(Var, epsilon)\n",
      " |            StdDev = Sqrt(VarEps)\n",
      " |            InvStdDev = Reciprocal(StdDev)\n",
      " |            Normalized = Mul(D, InvStdDev)\n",
      " |            ```\n",
      " |            where `normalized_axes` is `[axis, ..., rank of X - 1]`.\n",
      " |            The variables `Var` and `StdDev` stand for variance and\n",
      " |            standard deviation, respectively. The second output is\n",
      " |            `Mean` and the last one is `InvStdDev`.\n",
      " |            Depending on `stash_type` attribute, the actual computation\n",
      " |            must happen in different floating-point precision.\n",
      " |            For example, if `stash_type` is 1, this operator casts\n",
      " |            all input variables to 32-bit float, perform the computation, and\n",
      " |            finally cast `Normalized` back to the original type of `X`.\n",
      " |            The second stage then scales and shifts the outcome of the\n",
      " |            first stage using\n",
      " |            ```\n",
      " |            NormalizedScaled = Mul(Normalized, Scale)\n",
      " |            Y = Add(NormalizedScaled, B)\n",
      " |            ```\n",
      " |            The second stage doesn't depends on `stash_type`.\n",
      " |            All equations are in [this syntax](https://github.com/onnx/onnx/blob/main/docs/Syntax.md).\n",
      " |            The same variable (i.e., input, output, and attribute) uses\n",
      " |            the same name in the equations above and this operator's definition.\n",
      " |            Let `d[i]` indicate the i-th dimension of `X`.\n",
      " |            If `X`'s shape is `[d[0], ..., d[axis-1], d[axis], ..., d[rank-1]]`,\n",
      " |            the shape of `Mean` and `InvStdDev` is `[d[0], ..., d[axis-1], 1, ..., 1]`.\n",
      " |            `Y` and `X` have the same shape.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: Tensor to be normalized.\n",
      " |      \n",
      " |          Scale: Scale tensor.\n",
      " |      \n",
      " |          B: (optional) Bias tensor.\n",
      " |      \n",
      " |          axis: The first normalization dimension. If rank(X) is r, axis' allowed\n",
      " |              range is [-r, r]. Negative value means counting dimensions from the\n",
      " |              back.\n",
      " |      \n",
      " |          epsilon: The epsilon value to use to avoid division by zero.\n",
      " |      \n",
      " |          stash_type: Type of Mean and InvStdDev. This also specifies stage one's\n",
      " |              computation precision.\n",
      " |  \n",
      " |  MelWeightMatrix(self, num_mel_bins: 'T1_MelWeightMatrix', dft_length: 'T1_MelWeightMatrix', sample_rate: 'T1_MelWeightMatrix', lower_edge_hertz: 'T2_MelWeightMatrix', upper_edge_hertz: 'T2_MelWeightMatrix', *, output_datatype: 'int' = 1) -> 'T3_MelWeightMatrix'\n",
      " |      [üåê MelWeightMatrix(17)](https://onnx.ai/onnx/operators/onnx__MelWeightMatrix.html#melweightmatrix-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a MelWeightMatrix that can be used to re-weight a Tensor containing a linearly sampled frequency spectra (from DFT or STFT) into num_mel_bins frequency information based on the [lower_edge_hertz, upper_edge_hertz] range on the mel scale.\n",
      " |      This function defines the mel scale in terms of a frequency in hertz according to the following formula:\n",
      " |      \n",
      " |          mel(f) = 2595 * log10(1 + f/700)\n",
      " |      \n",
      " |      In the returned matrix, all the triangles (filterbanks) have a peak value of 1.0.\n",
      " |      \n",
      " |      The returned MelWeightMatrix can be used to right-multiply a spectrogram S of shape [frames, num_spectrogram_bins] of linear scale spectrum values (e.g. STFT magnitudes) to generate a \"mel spectrogram\" M of shape [frames, num_mel_bins].\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          num_mel_bins: (non-differentiable) The number of bands in the mel spectrum.\n",
      " |      \n",
      " |          dft_length: (non-differentiable) The size of the original DFT. The size of\n",
      " |              the original DFT is used to infer the size of the onesided DFT, which is\n",
      " |              understood to be floor(dft_length/2) + 1, i.e. the spectrogram only\n",
      " |              contains the nonredundant DFT bins.\n",
      " |      \n",
      " |          sample_rate: (non-differentiable) Samples per second of the input signal\n",
      " |              used to create the spectrogram. Used to figure out the frequencies\n",
      " |              corresponding to each spectrogram bin, which dictates how they are\n",
      " |              mapped into the mel scale.\n",
      " |      \n",
      " |          lower_edge_hertz: (non-differentiable) Lower bound on the frequencies to be\n",
      " |              included in the mel spectrum. This corresponds to the lower edge of the\n",
      " |              lowest triangular band.\n",
      " |      \n",
      " |          upper_edge_hertz: (non-differentiable) The desired top edge of the highest\n",
      " |              frequency band.\n",
      " |      \n",
      " |          output_datatype: The data type of the output tensor. Strictly must be one of\n",
      " |              the values from DataType enum in TensorProto whose values correspond to\n",
      " |              T3. The default value is 1 = FLOAT.\n",
      " |  \n",
      " |  STFT(self, signal: 'T1_STFT', frame_step: 'T2_STFT', window: 'Optional[T1_STFT]' = None, frame_length: 'Optional[T2_STFT]' = None, *, onesided: 'int' = 1) -> 'T1_STFT'\n",
      " |      [üåê STFT(17)](https://onnx.ai/onnx/operators/onnx__STFT.html#stft-17 \"Online Documentation\")\n",
      " |      \n",
      " |      Computes the Short-time Fourier Transform of the signal.\n",
      " |      \n",
      " |      Args:\n",
      " |          signal: (non-differentiable) Input tensor representing a real or complex\n",
      " |              valued signal. For real input, the following shape is expected:\n",
      " |              [batch_size][signal_length][1]. For complex input, the following shape\n",
      " |              is expected: [batch_size][signal_length][2], where\n",
      " |              [batch_size][signal_length][0] represents the real component and\n",
      " |              [batch_size][signal_length][1] represents the imaginary component of the\n",
      " |              signal.\n",
      " |      \n",
      " |          frame_step: (non-differentiable) The number of samples to step between\n",
      " |              successive DFTs.\n",
      " |      \n",
      " |          window: (optional, non-differentiable) A tensor representing the window that\n",
      " |              will be slid over the signal.The window must have rank 1 with shape:\n",
      " |              [window_shape]. It's an optional value.\n",
      " |      \n",
      " |          frame_length: (optional, non-differentiable) A scalar representing the size\n",
      " |              of the DFT. It's an optional value.\n",
      " |      \n",
      " |          onesided: If onesided is 1, only values for w in [0, 1, 2, ...,\n",
      " |              floor(n_fft/2) + 1] are returned because the real-to-complex Fourier\n",
      " |              transform satisfies the conjugate symmetry, i.e., X[m, w] =\n",
      " |              X[m,w]=X[m,n_fft-w]*. Note if the input or window tensors are complex,\n",
      " |              then onesided output is not possible. Enabling onesided with real inputs\n",
      " |              performs a Real-valued fast Fourier transform (RFFT).When invoked with\n",
      " |              real or complex valued input, the default value is 1. Values can be 0 or\n",
      " |              1.\n",
      " |  \n",
      " |  SequenceMap(self, input_sequence: 'S_SequenceMap', *additional_inputs: 'V_SequenceMap', body: 'GraphProto') -> 'S_SequenceMap'\n",
      " |      [üåê SequenceMap(17)](https://onnx.ai/onnx/operators/onnx__SequenceMap.html#sequencemap-17 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Applies a sub-graph to each sample in the input sequence(s).\n",
      " |      \n",
      " |      Inputs can be either tensors or sequences, with the exception of the first input which must\n",
      " |      be a sequence. The length of the first input sequence will determine the number of samples in the\n",
      " |      outputs. Any other sequence inputs should have the same number of samples. The number of inputs\n",
      " |      and outputs, should match the one of the subgraph.\n",
      " |      \n",
      " |      For each i-th element in the output, a sample will be extracted from the input sequence(s) at\n",
      " |      the i-th position and the sub-graph will be applied to it.\n",
      " |      The outputs will contain the outputs of the sub-graph for each sample, in the same order as in\n",
      " |      the input.\n",
      " |      \n",
      " |      This operator assumes that processing each sample is independent and could executed in parallel\n",
      " |      or in any order. Users cannot expect any specific ordering in which each subgraph is computed.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |      \n",
      " |          additional_inputs: (variadic, heterogeneous) Additional inputs to the graph\n",
      " |      \n",
      " |          body: The graph to be run for each sample in the sequence(s). It should have\n",
      " |              as many inputs and outputs as inputs and outputs to the SequenceMap\n",
      " |              function.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset17.Opset17:\n",
      " |  \n",
      " |  S_SequenceMap = ~S_SequenceMap\n",
      " |  \n",
      " |  T1_BlackmanWindow = ~T1_BlackmanWindow\n",
      " |  \n",
      " |  T1_DFT = ~T1_DFT\n",
      " |  \n",
      " |  T1_HammingWindow = ~T1_HammingWindow\n",
      " |  \n",
      " |  T1_HannWindow = ~T1_HannWindow\n",
      " |  \n",
      " |  T1_MelWeightMatrix = ~T1_MelWeightMatrix\n",
      " |  \n",
      " |  T1_STFT = ~T1_STFT\n",
      " |  \n",
      " |  T2_BlackmanWindow = typing.Union[onnxscript.onnx_types.BFLOAT16, onn.....\n",
      " |  \n",
      " |  T2_DFT = ~T2_DFT\n",
      " |  \n",
      " |  T2_HammingWindow = typing.Union[onnxscript.onnx_types.BFLOAT16, onn......\n",
      " |  \n",
      " |  T2_HannWindow = typing.Union[onnxscript.onnx_types.BFLOAT16, onn...t.o...\n",
      " |  \n",
      " |  T2_MelWeightMatrix = ~T2_MelWeightMatrix\n",
      " |  \n",
      " |  T2_STFT = ~T2_STFT\n",
      " |  \n",
      " |  T3_MelWeightMatrix = typing.Union[onnxscript.onnx_types.BFLOAT16, onn....\n",
      " |  \n",
      " |  T_LayerNormalization = ~T_LayerNormalization\n",
      " |  \n",
      " |  U_LayerNormalization = typing.Union[onnxscript.onnx_types.BFLOAT16, on...\n",
      " |  \n",
      " |  V_SequenceMap = ~V_SequenceMap\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset16.Opset16:\n",
      " |  \n",
      " |  GreaterOrEqual(self, A: 'T_GreaterOrEqual', B: 'T_GreaterOrEqual') -> 'T1_GreaterOrEqual'\n",
      " |      [üåê GreaterOrEqual(16)](https://onnx.ai/onnx/operators/onnx__GreaterOrEqual.html#greaterorequal-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `greater_equal` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  GridSample(self, X: 'T1_GridSample', grid: 'T2_GridSample', *, align_corners: 'int' = 0, mode: 'str' = 'bilinear', padding_mode: 'str' = 'zeros') -> 'T1_GridSample'\n",
      " |      [üåê GridSample(16)](https://onnx.ai/onnx/operators/onnx__GridSample.html#gridsample-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given an input `X` and a flow-field `grid`, computes the output `Y` using `X` values and pixel locations from `grid`.\n",
      " |      Currently, only spatial (4-D) inputs are supported. For input `X` with shape (N, C, H, W) and `grid` with shape (N, H_out, W_out, 2),\n",
      " |      the output `Y` will have shape (N, C, H_out, W_out).\n",
      " |      \n",
      " |      The tensor `X` contains values at centers of square pixels in a H by W 2-dimensional image.\n",
      " |      The tensor `grid` describes normalized positions where the output `Y` is to be computed\n",
      " |      using a specified interpolation method (the mode) and a padding mode (for grid positions falling outside the 2-dimensional image).\n",
      " |      \n",
      " |      Elements in `grid[N, H_out, W_out]` are size-2 vectors specifying positions in the 2-dimensional space of `X`.\n",
      " |      They are used to interpolate output values of `Y[N, C, H_out, W_out]`.\n",
      " |      \n",
      " |      The GridSample operator is often used in doing grid generator and sampler in the [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025).\n",
      " |      See also in [torch.nn.functional.grid_sample](https://pytorch.org/docs/master/generated/torch.nn.functional.grid_sample.html#torch-nn-functional-grid-sample).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) 4-D tensor of shape (N, C, H, W), where N is the batch\n",
      " |              size, C is the numbers of channels, H and W are the height and width of\n",
      " |              the input data.\n",
      " |      \n",
      " |          grid: (non-differentiable) Input offset, 4-D tensor of shape (N, H_out,\n",
      " |              W_out, 2), where H_out and W_out are the height and width of grid and\n",
      " |              output, Grid specifies the sampling pixel locations normalized by the\n",
      " |              input spatial dimensions. Therefore, it should have most values in the\n",
      " |              range of [-1, 1]. If grid has values outside the range of [-1, 1], the\n",
      " |              corresponding outputs will be handled as defined by padding_mode.\n",
      " |      \n",
      " |          align_corners: If align_corners=1, the extrema (-1 and 1) are considered as\n",
      " |              referring to the center points of the input's corner pixels. If\n",
      " |              align_corners=0, they are instead considered as referring to the corner\n",
      " |              points of the input's corner pixels, making the sampling more resolution\n",
      " |              agnostic.\n",
      " |      \n",
      " |          mode: Three interpolation modes: bilinear (default), nearest and bicubic.\n",
      " |      \n",
      " |          padding_mode: Support padding modes for outside grid values:\n",
      " |              `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound\n",
      " |              grid locations, border: use border values for out-of-bound grid\n",
      " |              locations, reflection: use values at locations reflected by the border\n",
      " |              for out-of-bound grid locations. If index 0 represents the margin pixel,\n",
      " |              the reflected value at index -1 will be the same as the value at index\n",
      " |              1. For location far away from the border, it will keep being reflected\n",
      " |              until becoming in bound. If pixel location x = -3.5 reflects by border\n",
      " |              -1 and becomes x' = 1.5, then reflects by border 1 and becomes x'' =\n",
      " |              0.5.\n",
      " |  \n",
      " |  Identity(self, input: 'V_Identity') -> 'V_Identity'\n",
      " |      [üåê Identity(16)](https://onnx.ai/onnx/operators/onnx__Identity.html#identity-16 \"Online Documentation\")\n",
      " |      \n",
      " |      Identity operator\n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  If(self, cond: 'B_If', *, else_branch: 'GraphProto', then_branch: 'GraphProto') -> 'V_If'\n",
      " |      [üåê If(16)](https://onnx.ai/onnx/operators/onnx__If.html#if-16 \"Online Documentation\")\n",
      " |      \n",
      " |      If conditional\n",
      " |      \n",
      " |      Args:\n",
      " |          cond: Condition for the if\n",
      " |      \n",
      " |          else_branch: Graph to run if condition is false. Has N outputs: values you\n",
      " |              wish to be live-out to the enclosing scope. The number of outputs must\n",
      " |              match the number of outputs in the then_branch.\n",
      " |      \n",
      " |          then_branch: Graph to run if condition is true. Has N outputs: values you\n",
      " |              wish to be live-out to the enclosing scope. The number of outputs must\n",
      " |              match the number of outputs in the else_branch.\n",
      " |  \n",
      " |  LeakyRelu(self, X: 'T_LeakyRelu', *, alpha: 'float' = 0.009999999776482582) -> 'T_LeakyRelu'\n",
      " |      [üåê LeakyRelu(16)](https://onnx.ai/onnx/operators/onnx__LeakyRelu.html#leakyrelu-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      LeakyRelu takes input data (Tensor<T>) and an argument alpha, and produces one\n",
      " |      output data (Tensor<T>) where the function `f(x) = alpha * x for x < 0`,\n",
      " |      `f(x) = x for x >= 0`, is applied to the data tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: Coefficient of leakage.\n",
      " |  \n",
      " |  LessOrEqual(self, A: 'T_LessOrEqual', B: 'T_LessOrEqual') -> 'T1_LessOrEqual'\n",
      " |      [üåê LessOrEqual(16)](https://onnx.ai/onnx/operators/onnx__LessOrEqual.html#lessorequal-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `less_equal` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Loop(self, M: 'Optional[I_Loop]', cond: 'Optional[B_Loop]', *v_initial: 'V_Loop', body: 'GraphProto') -> 'V_Loop'\n",
      " |      [üåê Loop(16)](https://onnx.ai/onnx/operators/onnx__Loop.html#loop-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generic Looping construct. This loop has multiple termination conditions:\n",
      " |      \n",
      " |      1) Trip count. Iteration count specified at runtime. Set by\n",
      " |         specifying the input M. Optional. Set to empty string to omit.\n",
      " |         Note that a static trip count (specified at graph construction time) can be\n",
      " |         specified by passing in a constant node for input M.\n",
      " |      2) Loop termination condition. This is an input to the op that determines\n",
      " |         whether to run the first iteration and also a loop-carried dependency for\n",
      " |         the body graph. The body graph must yield a value for the condition variable,\n",
      " |         whether this input is provided or not.\n",
      " |      \n",
      " |      This table summarizes the operating modes of this operator with equivalent\n",
      " |      C-style code:\n",
      " |      \n",
      " |      Operator inputs defined as (max_trip_count, condition_var).\n",
      " |      \n",
      " |      * input (\"\", \"\"):\n",
      " |              for (int i=0; ; ++i) {\n",
      " |                cond = ... // Note this value is ignored, but is required in the body\n",
      " |              }\n",
      " |      \n",
      " |      * input (\"\", cond) // Note this is analogous to a while loop\n",
      " |              bool cond = ...;\n",
      " |              for (int i=0; cond; ++i) {\n",
      " |                cond = ...;\n",
      " |              }\n",
      " |      \n",
      " |      * input (\"\", 1) // Note this is analogous to a do-while loop\n",
      " |              bool cond = true\n",
      " |              for (int i=0; cond; ++i) {\n",
      " |                cond = ...;\n",
      " |              }\n",
      " |      \n",
      " |      * input (trip_count, \"\") // Note this is analogous to a for loop\n",
      " |              int trip_count = ...\n",
      " |              for (int i=0; i < trip_count; ++i) {\n",
      " |                cond = ...; // ignored\n",
      " |              }\n",
      " |      \n",
      " |      * input (trip_count, cond)\n",
      " |              int trip_count = ...;\n",
      " |              bool cond = ...;\n",
      " |              for (int i=0; i < trip_count && cond; ++i) {\n",
      " |                cond = ...;\n",
      " |              }\n",
      " |      \n",
      " |      \n",
      " |      *Sample usage - cond as well as trip count*\n",
      " |      \n",
      " |          graph predict-net {\n",
      " |            %a = Constant[value = <Scalar Tensor [3]>]()\n",
      " |            %b = Constant[value = <Scalar Tensor [6]>]()\n",
      " |            %keepgoing = Constant[value = <Scalar Tensor [1]>]()\n",
      " |            %max_trip_count = Constant[value = <Scalar Tensor [10]>]()\n",
      " |            %keepgoing_out, %b_out, %user_defined_vals = Loop[body = <graph body-net>](%max_trip_count, %keepgoing, %b)\n",
      " |            return\n",
      " |          }\n",
      " |      \n",
      " |          graph body-net (\n",
      " |            %i[INT32, scalar]           // iteration number\n",
      " |            %keepgoing_in[BOOL, scalar] // incoming loop-termination-condition; not used\n",
      " |            %b_in[INT32, scalar]        // incoming value of loop-carried-dependency b\n",
      " |          ) {\n",
      " |            %my_local = Add(%a, %b_in)\n",
      " |            %b_out = Sub(%a, %b_in) // outgoing value of loop-carried-dependency b\n",
      " |            %keepgoing_out = Greater(%my_local, %b_out) // outgoing loop-termination-condition\n",
      " |            %user_defined_val = Add(%b_in, %b_in) // scan-output value to be accumulated\n",
      " |            return %keepgoing_out, %b_out, %user_defined_val\n",
      " |          }\n",
      " |      \n",
      " |      *Sample equivalent C code*\n",
      " |      \n",
      " |          {\n",
      " |            /* User-defined code (enclosing scope) */\n",
      " |            int a = 3, b = 6;\n",
      " |            bool keepgoing = true; // Analogous to input cond\n",
      " |            /* End user-defined code */\n",
      " |      \n",
      " |            /* Implicitly-defined code */\n",
      " |            const int max_trip_count = 10; // Analogous to input M\n",
      " |            int user_defined_vals[]; // Imagine this is resizable\n",
      " |            /* End implicitly-defined code */\n",
      " |            /* initialize loop-carried variables and scan-output variables */\n",
      " |            bool keepgoing_out = keepgoing\n",
      " |            int b_out = b\n",
      " |      \n",
      " |            for (int i=0; i < max_trip_count && keepgoing_out; ++i) {\n",
      " |              /* Implicitly-defined code: bind actual parameter values\n",
      " |                 to formal parameter variables of loop-body */\n",
      " |              bool keepgoing_in = keepgoing_out;\n",
      " |              bool b_in = b_out;\n",
      " |      \n",
      " |              /* User-defined code (loop body) */\n",
      " |              int my_local = a + b_in; // Reading value \"a\" from the enclosing scope is fine\n",
      " |              b_out = a - b_in;\n",
      " |              keepgoing_out = my_local > b_out;\n",
      " |              user_defined_val = b_in + b_in; // b_in and b_out are different variables\n",
      " |              /* End user-defined code */\n",
      " |      \n",
      " |              /* Implicitly defined-code */\n",
      " |              user_defined_vals[i] = user_defined_val // accumulate scan-output values\n",
      " |            }\n",
      " |            // int t = my_local; // Can't do this. my_local is not accessible here.\n",
      " |      \n",
      " |            // The values below are bound to the output variables of the loop and therefore accessible\n",
      " |            // b_out; user_defined_vals; keepgoing_out;\n",
      " |          }\n",
      " |      \n",
      " |      There are several things of note in this code snippet:\n",
      " |      \n",
      " |      1) Values from the enclosing scope (i.e. variable \"a\" here) are in scope and can\n",
      " |         be referenced in the inputs of the loop.\n",
      " |      2) Any values computed in the loop body that needs to be used in a subsequent\n",
      " |         iteration or after the loop are modelled using a pair of variables in the loop-body,\n",
      " |         consisting of an input variable (eg., b_in) and an output variable (eg., b_out).\n",
      " |         These are referred to as loop-carried dependences. The loop operation node\n",
      " |         supplies the input value of the input variable for the first iteration, and\n",
      " |         returns the output value of the output variable produced by the final\n",
      " |         iteration.\n",
      " |      3) Scan_output variables are used to implicitly concatenate values computed across\n",
      " |         all the iterations. In the above example, the value of user_defined_val computed\n",
      " |         over all iterations are concatenated and returned as the value of user_defined_vals\n",
      " |         after the loop.\n",
      " |      4) Values created in the body cannot be accessed in the enclosing scope,\n",
      " |         except using the mechanism described above.\n",
      " |      \n",
      " |      Note that the semantics of this op support \"diagonal\" or \"wavefront\" execution.\n",
      " |      (See Step 3 here for an example:\n",
      " |      https://devblogs.nvidia.com/optimizing-recurrent-neural-networks-cudnn-5/).\n",
      " |      Frontends should emit multi-layer RNNs as a series of While operators (with\n",
      " |      time being the inner looping dimension), with each successive layer consuming\n",
      " |      the scan_outputs from the previous layer, possibly going through several\n",
      " |      point-wise operators (e.g. dropout, residual connections, linear layer).\n",
      " |      \n",
      " |      The input/output of subgraph (produced by loop node) matching is based on order instead of name. The implementation will figure out the names based on this order.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          M: (optional) A maximum trip-count for the loop specified at runtime.\n",
      " |              Optional. Pass empty string to skip.\n",
      " |      \n",
      " |          cond: (optional) A boolean termination condition. Optional. Pass empty\n",
      " |              string to skip.\n",
      " |      \n",
      " |          v_initial: (variadic, heterogeneous) The initial values of any loop-carried\n",
      " |              dependencies (values that change across loop iterations)\n",
      " |      \n",
      " |          body: The graph run each iteration. It has 2+N inputs: (iteration_num,\n",
      " |              condition, loop carried dependencies...). It has 1+N+K outputs:\n",
      " |              (condition, loop carried dependencies..., scan_outputs...). Each\n",
      " |              scan_output is created by concatenating the value of the specified\n",
      " |              output value at the end of each iteration of the loop. It is an error if\n",
      " |              the dimensions or data type of these scan_outputs change across loop\n",
      " |              iterations.\n",
      " |  \n",
      " |  PRelu(self, X: 'T_PRelu', slope: 'T_PRelu') -> 'T_PRelu'\n",
      " |      [üåê PRelu(16)](https://onnx.ai/onnx/operators/onnx__PRelu.html#prelu-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      PRelu takes input data (Tensor<T>) and slope tensor as input, and produces one\n",
      " |      output data (Tensor<T>) where the function `f(x) = slope * x for x < 0`,\n",
      " |      `f(x) = x for x >= 0`., is applied to the data tensor elementwise.\n",
      " |      This operator supports **unidirectional broadcasting** (tensor slope should be unidirectional broadcastable to input tensor X); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          slope: (differentiable) Slope tensor. The shape of slope can be smaller then\n",
      " |              first input X; if so, its shape must be unidirectional broadcastable to\n",
      " |              X\n",
      " |  \n",
      " |  RoiAlign(self, X: 'T1_RoiAlign', rois: 'T1_RoiAlign', batch_indices: 'T2_RoiAlign', *, coordinate_transformation_mode: 'str' = 'half_pixel', mode: 'str' = 'avg', output_height: 'int' = 1, output_width: 'int' = 1, sampling_ratio: 'int' = 0, spatial_scale: 'float' = 1.0) -> 'T1_RoiAlign'\n",
      " |      [üåê RoiAlign(16)](https://onnx.ai/onnx/operators/onnx__RoiAlign.html#roialign-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Region of Interest (RoI) align operation described in the\n",
      " |      [Mask R-CNN paper](https://arxiv.org/abs/1703.06870).\n",
      " |      RoiAlign consumes an input tensor X and region of interests (rois)\n",
      " |      to apply pooling across each RoI; it produces a 4-D tensor of shape\n",
      " |      (num_rois, C, output_height, output_width).\n",
      " |      \n",
      " |      RoiAlign is proposed to avoid the misalignment by removing\n",
      " |      quantizations while converting from original image into feature\n",
      " |      map and from feature map into RoI feature; in each ROI bin,\n",
      " |      the value of the sampled locations are computed directly\n",
      " |      through bilinear interpolation.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: Input data tensor from the previous operator; 4-D feature map of shape\n",
      " |              (N, C, H, W), where N is the batch size, C is the number of channels,\n",
      " |              and H and W are the height and the width of the data.\n",
      " |      \n",
      " |          rois: RoIs (Regions of Interest) to pool over; rois is 2-D input of shape\n",
      " |              (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates\n",
      " |              are in the coordinate system of the input image. Each coordinate set has\n",
      " |              a 1:1 correspondence with the 'batch_indices' input.\n",
      " |      \n",
      " |          batch_indices: 1-D tensor of shape (num_rois,) with each element denoting\n",
      " |              the index of the corresponding image in the batch.\n",
      " |      \n",
      " |          coordinate_transformation_mode: Allowed values are 'half_pixel' and\n",
      " |              'output_half_pixel'. Use the value 'half_pixel' to pixel shift the input\n",
      " |              coordinates by -0.5 (the recommended behavior). Use the value\n",
      " |              'output_half_pixel' to omit the pixel shift for the input (use this for\n",
      " |              a backward-compatible behavior).\n",
      " |      \n",
      " |          mode: The pooling method. Two modes are supported: 'avg' and 'max'. Default\n",
      " |              is 'avg'.\n",
      " |      \n",
      " |          output_height: default 1; Pooled output Y's height.\n",
      " |      \n",
      " |          output_width: default 1; Pooled output Y's width.\n",
      " |      \n",
      " |          sampling_ratio: Number of sampling points in the interpolation grid used to\n",
      " |              compute the output value of each pooled output bin. If > 0, then exactly\n",
      " |              sampling_ratio x sampling_ratio grid points are used. If == 0, then an\n",
      " |              adaptive number of grid points are used (computed as ceil(roi_width /\n",
      " |              output_width), and likewise for height). Default is 0.\n",
      " |      \n",
      " |          spatial_scale: Multiplicative spatial scale factor to translate ROI\n",
      " |              coordinates from their input spatial scale to the scale used when\n",
      " |              pooling, i.e., spatial scale of the input feature map X relative to the\n",
      " |              input image. E.g.; default is 1.0f.\n",
      " |  \n",
      " |  Scan(self, *initial_state_and_scan_inputs: 'V_Scan', body: 'GraphProto', num_scan_inputs: 'int', scan_input_axes: 'Optional[Sequence[int]]' = None, scan_input_directions: 'Optional[Sequence[int]]' = None, scan_output_axes: 'Optional[Sequence[int]]' = None, scan_output_directions: 'Optional[Sequence[int]]' = None) -> 'V_Scan'\n",
      " |      [üåê Scan(16)](https://onnx.ai/onnx/operators/onnx__Scan.html#scan-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Scan can be used to iterate over one or more scan_input tensors,\n",
      " |      constructing zero or more scan_output tensors. It combines ideas from general recurrences,\n",
      " |      functional programming constructs such as scan, fold, map, and zip, and is intended to enable\n",
      " |      generalizations of RNN-like constructs for sequence-to-sequence processing.\n",
      " |      Other tensors (referred to as state_variables here) can be used to carry a state\n",
      " |      when iterating from one element to another (similar to hidden-state in RNNs, also referred\n",
      " |      to as loop-carried dependences in the context of loops).\n",
      " |      Many common usages involve a single scan_input tensor (where functionality\n",
      " |      similar to scan, fold and map can be obtained). When more than one scan_input is used,\n",
      " |      a behavior similar to zip is obtained.\n",
      " |      \n",
      " |      The attribute body must be a graph, specifying the computation to be performed in\n",
      " |      every iteration. It takes as input the current values of the state_variables and\n",
      " |      the current iterated element of the scan_inputs. It must return the (updated) values\n",
      " |      of the state_variables and zero or more scan_output_element tensors. The values of the\n",
      " |      scan_output_element tensors are concatenated over all the iterations to produce the\n",
      " |      scan_output values of the scan construct (similar to the concatenated intermediate\n",
      " |      hidden-state values of RNN-like constructs). All the output tensors (state_variables as\n",
      " |      well as scan_output_element tensors) are required to have the same shape in each iteration\n",
      " |      of the loop (a restriction imposed to enable efficient memory allocation).\n",
      " |      \n",
      " |      Note that the iterated element passed to the body subgraph does not have a sequence\n",
      " |      axis. It will have a rank one less than the rank of the corresponding scan_input.\n",
      " |      \n",
      " |      The scan operation returns the final values of the state_variables as well as the\n",
      " |      scan_outputs.\n",
      " |      \n",
      " |      The optional attribute scan_input_directions specifies the direction (forward or backward)\n",
      " |      for each scan input. If this attribute is omitted, all sequences are scanned in the forward\n",
      " |      direction. A bidirectional scan may be performed by specifying the same tensor input twice\n",
      " |      in the scan_inputs, once with a forward direction, and once with a backward direction.\n",
      " |      \n",
      " |      The scan_output of the operation is produced by concatenating the scan_output_element\n",
      " |      values produced by the body in each iteration.  The optional attribute scan_output_directions\n",
      " |      specifies the direction in which scan_output is constructed (by appending or prepending the\n",
      " |      scan_output_element to scan_output in each iteration) for each scan_output. If this attribute\n",
      " |      is omitted, the scan_output_element is appended to the scan_output in each iteration.\n",
      " |      \n",
      " |      The optional attribute scan_input_axes specifies the axis to be scanned for each scan_input.\n",
      " |      If omitted, every scan_input will be scanned in axis 0. For example, if axis 0 is the\n",
      " |      batch axis and axis 1 is the time axis (to be scanned), specify an axis value of 1.\n",
      " |      Note that scanning a non-zero axis may be less efficient than scanning axis zero.\n",
      " |      \n",
      " |      The optional attribute scan_output_axes specifies the axis along which the scan_outputs\n",
      " |      are accumulated for each scan_output. For example, if axis 1 is the time axis (to be\n",
      " |      scanned) for both inputs and outputs, specify a scan_input axis and scan_output axis\n",
      " |      value of 1.\n",
      " |      \n",
      " |      Note that because of the ONNX restriction that only the last parameter of an operator can\n",
      " |      be variadic, the initial-states and scan-inputs are listed together as one input parameter.\n",
      " |      Similarly, the final-states and scan-outputs are listed together as one output parameter.\n",
      " |      The attribute num_scan_inputs indicates the number M of scan-inputs.\n",
      " |      \n",
      " |      The behavior of\n",
      " |      \n",
      " |          Scan <\n",
      " |              num_scan_inputs = m,\n",
      " |              body = loop-body,\n",
      " |              scan_input_axes = [axis_1, ..., axis_m]\n",
      " |          > (init_1, ..., init_n, scan_1, ..., scan_m)\n",
      " |      \n",
      " |      is equivalent to the following pseudo-code:\n",
      " |      \n",
      " |          // scan_i.shape[axis_i] denotes the (max) sequence-length of scan_i\n",
      " |          // scan_i.shape[axis_i] is required to be equal to scan_j.shape[axis_j] for all i,j.\n",
      " |          sequence_length = scan_1.shape[axis_1];\n",
      " |      \n",
      " |          // initialize state-variables\n",
      " |          st_1 = init_1; ... st_n = init_n;\n",
      " |          // initialize scan-output variables: [] denotes an empty tensor\n",
      " |          scan_out_1 = []; ...; scan_out_k = [];\n",
      " |          // identify number of iterations:\n",
      " |      \n",
      " |          // execute loop\n",
      " |          for (int t = 0; t < sequence_length; ++t) {\n",
      " |              // generate the scan-input elements: the notation T<axis=k>[t] indicates the sub-tensor\n",
      " |              // of rank one less than T obtained by indexing T at position t along axis k.\n",
      " |              si_1 = scan_1<axis=axis_1>[t];\n",
      " |              ... ;\n",
      " |              si_m = scan_m<axis=axis_m>[t];\n",
      " |              // execute loop-body\n",
      " |              st_1, ..., st_n, so_1, ..., so_k = loop-body(st_1, ..., st_n, si_1, ..., si_m)\n",
      " |              // accumulate the scan-output elements\n",
      " |              scan_out_1 = Concat<axis=0>(scan_out_1, so_1); ... ; scan_out_k = Concat<axis=0>(scan_out_k, so_k);\n",
      " |          }\n",
      " |      \n",
      " |          return st_1, ..., st_n, scan_out_1, ..., scan_out_k;\n",
      " |      \n",
      " |      *Sample usage: Encoding RNN using a Scan*\n",
      " |      \n",
      " |      The following example shows how a simple RNN over an input tensor %X, with weight tensor %Wi,\n",
      " |      recurrence weight tensor %Ri, bias tensors %Wbi and %Rbi, and initial hidden-state %H_0 can\n",
      " |      be encoded as a ScanLoop. Note that the loop-body is a nested graph, and it directly computes\n",
      " |      %Wi, %Ri, %Wbi, and %Rbi (typically constants or initializers in the body graph). If these\n",
      " |      values are computed in the outer graph, they need to be passed in as extra state_variables.\n",
      " |      \n",
      " |          graph rnn-encoding {\n",
      " |            %H_0 = ...\n",
      " |            %X = ...\n",
      " |            %Y_h, %Y = Scan[body = <graph rnn-cell-1>, num_scan_inputs=1](%H_0, %X)\n",
      " |            return %Y, %Y_h\n",
      " |          }\n",
      " |      \n",
      " |          graph rnn-cell-1 (\n",
      " |            %H_tminus1[FLOAT, tensor]\n",
      " |            %X_t[FLOAT, tensor]\n",
      " |          ) {\n",
      " |            %Wi = ...\n",
      " |            %Ri = ...\n",
      " |            %Wbi = ...\n",
      " |            %Rbi = ...\n",
      " |            %t1 = X_t * (Wi^T)\n",
      " |            %t2 = H_tminus1*(Ri^T)\n",
      " |            %t3 = Add(%t1, %t2)\n",
      " |            %t4 = Add(%t3, %Wbi)\n",
      " |            %t5 = Add(%t4, %Rbi)\n",
      " |            %Ht = Tanh(%t5)\n",
      " |            %Accumulate = Identity(%Ht)\n",
      " |            return %Ht, %Accumulate\n",
      " |          }\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          initial_state_and_scan_inputs: (variadic, heterogeneous) Initial values of\n",
      " |              the loop's N state variables followed by M scan_inputs\n",
      " |      \n",
      " |          body: The graph run each iteration. It has N+M inputs: (loop state\n",
      " |              variables..., scan_input_elts...). It has N+K outputs: (loop state\n",
      " |              variables..., scan_output_elts...). Each scan_output is created by\n",
      " |              concatenating the value of the specified scan_output_elt value at the\n",
      " |              end of each iteration of the loop. It is an error if the dimensions of\n",
      " |              these values change across loop iterations.\n",
      " |      \n",
      " |          num_scan_inputs: An attribute specifying the number of scan_inputs M.\n",
      " |      \n",
      " |          scan_input_axes: An optional list of M flags. The i-th element of the list\n",
      " |              specifies the axis to be scanned (the sequence axis) for the i-th\n",
      " |              scan_input. If omitted, 0 will be used as the scan axis for every\n",
      " |              scan_input. Negative value for an axis means counting dimensions from\n",
      " |              the back. Accepted range is [-r, r-1] where r = rank(input).\n",
      " |      \n",
      " |          scan_input_directions: An optional list of M flags. The i-th element of the\n",
      " |              list specifies the direction to be scanned for the i-th scan_input\n",
      " |              tensor: 0 indicates forward direction and 1 indicates reverse direction.\n",
      " |              If omitted, all scan_input tensors will be scanned in the forward\n",
      " |              direction.\n",
      " |      \n",
      " |          scan_output_axes: An optional list of K flags. The i-th element of the list\n",
      " |              specifies the axis for the i-th scan_output. The scan outputs are\n",
      " |              accumulated along the specified axis. If omitted, 0 will be used as the\n",
      " |              scan axis for every scan_output. Negative value for an axis means\n",
      " |              counting dimensions from the back. Accepted range is [-r, r-1].\n",
      " |      \n",
      " |          scan_output_directions: An optional list of K flags, one for each\n",
      " |              scan_output. The i-th element of the list specifies whether the i-th\n",
      " |              scan_output should be constructed by appending or prepending a new value\n",
      " |              in each iteration: 0 indicates appending and 1 indicates prepending. If\n",
      " |              omitted, all scan_output tensors will be produced by appending a value\n",
      " |              in each iteration.\n",
      " |  \n",
      " |  Where(self, condition: 'B_Where', X: 'T_Where', Y: 'T_Where') -> 'T_Where'\n",
      " |      [üåê Where(16)](https://onnx.ai/onnx/operators/onnx__Where.html#where-16 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Return elements, either from X or Y, depending on condition.\n",
      " |      Where behaves like\n",
      " |      [numpy.where](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html)\n",
      " |      with three parameters.\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          condition: (non-differentiable) When True (nonzero), yield X, otherwise\n",
      " |              yield Y\n",
      " |      \n",
      " |          X: (differentiable) values selected at indices where condition is True\n",
      " |      \n",
      " |          Y: (differentiable) values selected at indices where condition is False\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset16.Opset16:\n",
      " |  \n",
      " |  B_If = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  B_Loop = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  B_Where = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  I_Loop = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T1_GreaterOrEqual = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_GridSample = ~T1_GridSample\n",
      " |  \n",
      " |  T1_LessOrEqual = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_RoiAlign = ~T1_RoiAlign\n",
      " |  \n",
      " |  T2_GridSample = ~T2_GridSample\n",
      " |  \n",
      " |  T2_RoiAlign = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T_GreaterOrEqual = ~T_GreaterOrEqual\n",
      " |  \n",
      " |  T_LeakyRelu = ~T_LeakyRelu\n",
      " |  \n",
      " |  T_LessOrEqual = ~T_LessOrEqual\n",
      " |  \n",
      " |  T_PRelu = ~T_PRelu\n",
      " |  \n",
      " |  T_Where = ~T_Where\n",
      " |  \n",
      " |  V_Identity = ~V_Identity\n",
      " |  \n",
      " |  V_If = typing.Union[typing.Sequence[onnxscript.onnx_typ...t.onnx_types...\n",
      " |  \n",
      " |  V_Loop = ~V_Loop\n",
      " |  \n",
      " |  V_Scan = ~V_Scan\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset15.Opset15:\n",
      " |  \n",
      " |  BatchNormalization(self, X: 'T_BatchNormalization', scale: 'T1_BatchNormalization', B: 'T1_BatchNormalization', input_mean: 'T2_BatchNormalization', input_var: 'T2_BatchNormalization', *, epsilon: 'float' = 9.999999747378752e-06, momentum: 'float' = 0.8999999761581421, training_mode: 'int' = 0) -> 'Tuple[T_BatchNormalization, T2_BatchNormalization, T2_BatchNormalization]'\n",
      " |      [üåê BatchNormalization(15)](https://onnx.ai/onnx/operators/onnx__BatchNormalization.html#batchnormalization-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Carries out batch normalization as described in the paper\n",
      " |      https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\n",
      " |      There are five required inputs 'X', 'scale', 'B', 'input_mean' and\n",
      " |      'input_var'.\n",
      " |      Note that 'input_mean' and 'input_var' are expected to be the estimated\n",
      " |      statistics in inference mode (training_mode=False, default),\n",
      " |      and the running statistics in training mode (training_mode=True).\n",
      " |      There are multiple cases for the number of outputs, which we list below:\n",
      " |      \n",
      " |      * Output case #1: Y, running_mean, running_var (training_mode=True)\n",
      " |      * Output case #2: Y (training_mode=False)\n",
      " |      \n",
      " |      When training_mode=False, extra outputs are invalid.\n",
      " |      The outputs are updated as follows when training_mode=True:\n",
      " |      ::\n",
      " |      \n",
      " |          running_mean = input_mean * momentum + current_mean * (1 - momentum)\n",
      " |          running_var = input_var * momentum + current_var * (1 - momentum)\n",
      " |      \n",
      " |          Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B\n",
      " |      \n",
      " |      \n",
      " |      where:\n",
      " |      ::\n",
      " |      \n",
      " |          current_mean = ReduceMean(X, axis=all_except_channel_index)\n",
      " |          current_var =  ReduceVar(X, axis=all_except_channel_index)\n",
      " |      \n",
      " |      \n",
      " |      Notice that `ReduceVar` refers to the population variance, and it equals to\n",
      " |      `sum(sqrd(x_i - x_avg)) / N`\n",
      " |      where `N` is the population size (this formula does not use sample size `N - 1`).\n",
      " |      \n",
      " |      The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.\n",
      " |      \n",
      " |      When training_mode=False:\n",
      " |      ::\n",
      " |      \n",
      " |          Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      For previous (depreciated) non-spatial cases, implementors are suggested\n",
      " |      to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size,\n",
      " |              C is the number of channels. Statistics are computed for every channel\n",
      " |              of C over N and D1 to Dn dimensions. For image data, input dimensions\n",
      " |              become (N x C x H x W). The op also accepts single dimension input of\n",
      " |              size N in which case C is assumed to be 1\n",
      " |      \n",
      " |          scale: (differentiable) Scale tensor of shape (C).\n",
      " |      \n",
      " |          B: (differentiable) Bias tensor of shape (C).\n",
      " |      \n",
      " |          input_mean: (differentiable) running (training) or estimated (testing) mean\n",
      " |              tensor of shape (C).\n",
      " |      \n",
      " |          input_var: (differentiable) running (training) or estimated (testing)\n",
      " |              variance tensor of shape (C).\n",
      " |      \n",
      " |          epsilon: The epsilon value to use to avoid division by zero.\n",
      " |      \n",
      " |          momentum: Factor used in computing the running mean and variance.e.g.,\n",
      " |              running_mean = running_mean * momentum + mean * (1 - momentum).\n",
      " |      \n",
      " |          training_mode: If set to true, it indicates BatchNormalization is being used\n",
      " |              for training, and outputs 1, 2, 3, and 4 would be populated.\n",
      " |  \n",
      " |  Bernoulli(self, input: 'T1_Bernoulli', *, dtype: '_Optional[int]' = None, seed: '_Optional[float]' = None) -> 'T2_Bernoulli'\n",
      " |      [üåê Bernoulli(15)](https://onnx.ai/onnx/operators/onnx__Bernoulli.html#bernoulli-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Draws binary random numbers (0 or 1) from a Bernoulli distribution. The input tensor should be a tensor\n",
      " |      containing probabilities p (a value in the range [0,1]) to be used for drawing the binary random number,\n",
      " |      where an output of 1 is produced with probability p and an output of 0 is produced with probability (1-p).\n",
      " |      \n",
      " |      This operator is non-deterministic and may not produce the same values in different\n",
      " |      implementations (even if a seed is specified).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: All values in input have to be in the range:[0, 1].\n",
      " |      \n",
      " |          dtype: The data type for the elements of the output tensor. if not\n",
      " |              specified, we will use the data type of the input tensor.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  CastLike(self, input: 'T1_CastLike', target_type: 'T2_CastLike') -> 'T2_CastLike'\n",
      " |      [üåê CastLike(15)](https://onnx.ai/onnx/operators/onnx__CastLike.html#castlike-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator casts the elements of a given input tensor (the first input) to\n",
      " |      the same data type as the elements of the second input tensor.\n",
      " |      See documentation of the Cast operator for further details.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor to be cast.\n",
      " |      \n",
      " |          target_type: (non-differentiable) The (first) input tensor will be cast to\n",
      " |              produce a tensor of the same type as this (second input) tensor.\n",
      " |  \n",
      " |  Optional(self, input: '_Optional[V_Optional]' = None, *, type: '_Optional[TypeProto]' = None) -> 'O_Optional'\n",
      " |      [üåê Optional(15)](https://onnx.ai/onnx/operators/onnx__Optional.html#optional-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Constructs an optional-type value containing either an empty optional of a certain type specified by the attribute,\n",
      " |      or a non-empty value containing the input element.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (optional) The input element.\n",
      " |      \n",
      " |          type: Type of the element in the optional output\n",
      " |  \n",
      " |  Pow(self, X: 'T_Pow', Y: 'T1_Pow') -> 'T_Pow'\n",
      " |      [üåê Pow(15)](https://onnx.ai/onnx/operators/onnx__Pow.html#pow-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Pow takes input data (Tensor<T>) and exponent Tensor, and\n",
      " |      produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,\n",
      " |      is applied to the data tensor elementwise.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) First operand, base of the exponent.\n",
      " |      \n",
      " |          Y: (differentiable) Second operand, power of the exponent.\n",
      " |  \n",
      " |  Shape(self, data: 'T_Shape', *, end: '_Optional[int]' = None, start: 'int' = 0) -> 'T1_Shape'\n",
      " |      [üåê Shape(15)](https://onnx.ai/onnx/operators/onnx__Shape.html#shape-15 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Takes a tensor as input and outputs an 1D int64 tensor containing the shape of the input tensor.\n",
      " |      Optional attributes start and end can be used to compute a slice of the input tensor's shape.\n",
      " |      If start axis is omitted, the slice starts from axis 0.\n",
      " |      The end axis, if specified, is exclusive (and the returned value will not include the size of that axis).\n",
      " |      If the end axis is omitted, the axes upto the last one will be included.\n",
      " |      Negative axes indicate counting back from the last axis.\n",
      " |      Note that axes will be clamped to the range [0, r-1], where r is the\n",
      " |      rank of the input tensor if they are out-of-range (after adding r in the case of\n",
      " |      negative axis). Thus, specifying any end value > r is equivalent to specifying an end\n",
      " |      value of r, and specifying any start value < -r is equivalent to specifying a start\n",
      " |      value of 0.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Input tensor with shape: [2, 3, 4]\n",
      " |          No attributes specified.\n",
      " |          Output: [2, 3, 4]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Input tensor with shape: [2, 3, 4]\n",
      " |          start: -1\n",
      " |          Output: [4]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Input tensor with shape: [2, 3, 4]\n",
      " |          end: -1\n",
      " |          Output: [2, 3]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Input tensor with shape: [2, 3, 4]\n",
      " |          start: 1\n",
      " |          end: 2\n",
      " |          Output: [3]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (non-differentiable) An input tensor.\n",
      " |      \n",
      " |          end: (Optional) Ending axis for slicing the shape. Negative value means\n",
      " |              counting dimensions from the back. If omitted, sizes of all axes upto\n",
      " |              (including) the last one will be included.\n",
      " |      \n",
      " |          start: (Optional) Starting axis for slicing the shape. Default value is\n",
      " |              0.Negative value means counting dimensions from the back.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset15.Opset15:\n",
      " |  \n",
      " |  O_Optional = typing.Union[typing.Sequence[onnxscript.onnx_typ...t.onnx...\n",
      " |  \n",
      " |  T1_BatchNormalization = ~T1_BatchNormalization\n",
      " |  \n",
      " |  T1_Bernoulli = ~T1_Bernoulli\n",
      " |  \n",
      " |  T1_CastLike = ~T1_CastLike\n",
      " |  \n",
      " |  T1_Pow = ~T1_Pow\n",
      " |  \n",
      " |  T1_Shape = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T2_BatchNormalization = ~T2_BatchNormalization\n",
      " |  \n",
      " |  T2_Bernoulli = typing.Union[onnxscript.onnx_types.BFLOAT16, onn...t.on...\n",
      " |  \n",
      " |  T2_CastLike = ~T2_CastLike\n",
      " |  \n",
      " |  T_BatchNormalization = ~T_BatchNormalization\n",
      " |  \n",
      " |  T_Pow = ~T_Pow\n",
      " |  \n",
      " |  T_Shape = ~T_Shape\n",
      " |  \n",
      " |  V_Optional = ~V_Optional\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset14.Opset14:\n",
      " |  \n",
      " |  Add(self, A: 'T_Add', B: 'T_Add') -> 'T_Add'\n",
      " |      [üåê Add(14)](https://onnx.ai/onnx/operators/onnx__Add.html#add-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs element-wise binary addition (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      (Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) First operand.\n",
      " |      \n",
      " |          B: (differentiable) Second operand.\n",
      " |  \n",
      " |  CumSum(self, x: 'T_CumSum', axis: 'T2_CumSum', *, exclusive: 'int' = 0, reverse: 'int' = 0) -> 'T_CumSum'\n",
      " |      [üåê CumSum(14)](https://onnx.ai/onnx/operators/onnx__CumSum.html#cumsum-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs cumulative sum of the input elements along the given axis.\n",
      " |      By default, it will do the sum inclusively meaning the first element is copied as is.\n",
      " |      Through an `exclusive` attribute, this behavior can change to exclude the first element.\n",
      " |      It can also perform summation in the opposite direction of the axis. For that, set `reverse` attribute to 1.\n",
      " |      \n",
      " |      Example:\n",
      " |      ::\n",
      " |      \n",
      " |          input_x = [1, 2, 3]\n",
      " |          axis=0\n",
      " |          output = [1, 3, 6]\n",
      " |          exclusive=1\n",
      " |          output = [0, 1, 3]\n",
      " |          exclusive=0\n",
      " |          reverse=1\n",
      " |          output = [6, 5, 3]\n",
      " |          exclusive=1\n",
      " |          reverse=1\n",
      " |          output = [5, 3, 0]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: (differentiable) An input tensor that is to be processed.\n",
      " |      \n",
      " |          axis: (non-differentiable) A 0-D tensor. Must be in the range [-rank(x),\n",
      " |              rank(x)-1]. Negative value means counting dimensions from the back.\n",
      " |      \n",
      " |          exclusive: If set to 1 will return exclusive sum in which the top element is\n",
      " |              not included. In other terms, if set to 1, the j-th output element would\n",
      " |              be the sum of the first (j-1) elements. Otherwise, it would be the sum\n",
      " |              of the first j elements.\n",
      " |      \n",
      " |          reverse: If set to 1 will perform the sums in reverse direction.\n",
      " |  \n",
      " |  Div(self, A: 'T_Div', B: 'T_Div') -> 'T_Div'\n",
      " |      [üåê Div(14)](https://onnx.ai/onnx/operators/onnx__Div.html#div-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs element-wise binary division (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      (Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) First operand.\n",
      " |      \n",
      " |          B: (differentiable) Second operand.\n",
      " |  \n",
      " |  GRU(self, X: 'T_GRU', W: 'T_GRU', R: 'T_GRU', B: 'Optional[T_GRU]' = None, sequence_lens: 'Optional[T1_GRU]' = None, initial_h: 'Optional[T_GRU]' = None, *, activation_alpha: 'Optional[Sequence[float]]' = None, activation_beta: 'Optional[Sequence[float]]' = None, activations: 'Optional[Sequence[str]]' = None, clip: 'Optional[float]' = None, direction: 'str' = 'forward', hidden_size: 'Optional[int]' = None, layout: 'int' = 0, linear_before_reset: 'int' = 0) -> 'Tuple[T_GRU, T_GRU]'\n",
      " |      [üåê GRU(14)](https://onnx.ai/onnx/operators/onnx__GRU.html#gru-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes an one-layer GRU. This operator is usually supported via some custom\n",
      " |      implementation such as CuDNN.\n",
      " |      \n",
      " |      Notations:\n",
      " |      \n",
      " |      * `X` - input tensor\n",
      " |      * `z` - update gate\n",
      " |      * `r` - reset gate\n",
      " |      * `h` - hidden gate\n",
      " |      * `t` - time step (t-1 means previous time step)\n",
      " |      * `W[zrh]` - W parameter weight matrix for update, reset, and hidden gates\n",
      " |      * `R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates\n",
      " |      * `Wb[zrh]` - W bias vectors for update, reset, and hidden gates\n",
      " |      * `Rb[zrh]` - R bias vectors for update, reset, and hidden gates\n",
      " |      * `WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates\n",
      " |      * `RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates\n",
      " |      * `WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates\n",
      " |      * `RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates\n",
      " |      * `H` - Hidden state\n",
      " |      * `num_directions` - 2 if direction == bidirectional else 1\n",
      " |      \n",
      " |      Activation functions:\n",
      " |      \n",
      " |      * Relu(x)                - max(0, x)\n",
      " |      * Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})\n",
      " |      * Sigmoid(x)             - 1/(1 + e^{-x})\n",
      " |      \n",
      " |      NOTE:\n",
      " |        Below are optional\n",
      " |      \n",
      " |      * Affine(x)              - alpha * x + beta\n",
      " |      * LeakyRelu(x)           - x if x >= 0 else alpha * x\n",
      " |      * ThresholdedRelu(x)     - x if x >= alpha else 0\n",
      " |      * ScaledTanh(x)          - alpha * Tanh(beta * x)\n",
      " |      * HardSigmoid(x)         - min(max(alpha * x + beta, 0), 1)\n",
      " |      * Elu(x)                 - x if x >= 0 else alpha * (e^x - 1)\n",
      " |      * Softsign(x)            - x/(1 + |x|)\n",
      " |      * Softplus(x)            - log(1 + e^x)\n",
      " |      \n",
      " |      Equations (Default: f=Sigmoid, g=Tanh):\n",
      " |      \n",
      " |      * zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)\n",
      " |      * rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)\n",
      " |      * ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0\n",
      " |      * ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0\n",
      " |      * Ht = (1 - zt) (.) ht + zt (.) Ht-1\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) The input sequences packed (and potentially padded) into\n",
      " |              one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor for the gates. Concatenation of\n",
      " |              `W[zrh]` and `WB[zrh]` (if bidirectional) along dimension 0. This tensor\n",
      " |              has shape `[num_directions, 3*hidden_size, input_size]`.\n",
      " |      \n",
      " |          R: (differentiable) The recurrence weight tensor. Concatenation of `R[zrh]`\n",
      " |              and `RB[zrh]` (if bidirectional) along dimension 0. This tensor has\n",
      " |              shape `[num_directions, 3*hidden_size, hidden_size]`.\n",
      " |      \n",
      " |          B: (optional, differentiable) The bias tensor for the gates. Concatenation\n",
      " |              of `[Wb[zrh], Rb[zrh]]` and `[WBb[zrh], RBb[zrh]]` (if bidirectional)\n",
      " |              along dimension 0. This tensor has shape `[num_directions,\n",
      " |              6*hidden_size]`. Optional: If not specified - assumed to be 0\n",
      " |      \n",
      " |          sequence_lens: (optional, non-differentiable) Optional tensor specifying\n",
      " |              lengths of the sequences in a batch. If not specified - assumed all\n",
      " |              sequences in the batch to have length `seq_length`. It has shape\n",
      " |              `[batch_size]`.\n",
      " |      \n",
      " |          initial_h: (optional, non-differentiable) Optional initial value of the\n",
      " |              hidden. If not specified - assumed to be 0. It has shape\n",
      " |              `[num_directions, batch_size, hidden_size]`.\n",
      " |      \n",
      " |          activation_alpha: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.For example with LeakyRelu, the default\n",
      " |              alpha is 0.01.\n",
      " |      \n",
      " |          activation_beta: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.\n",
      " |      \n",
      " |          activations: A list of 2 (or 4 if bidirectional) activation functions for\n",
      " |              update, reset, and hidden gates. The activation functions must be one of\n",
      " |              the activation functions specified above. Optional: See the equations\n",
      " |              for default if not specified.\n",
      " |      \n",
      " |          clip: Cell clip threshold. Clipping bounds the elements of a tensor in the\n",
      " |              range of [-threshold, +threshold] and is applied to the input of\n",
      " |              activations. No clip if not specified.\n",
      " |      \n",
      " |          direction: Specify if the RNN is forward, reverse, or bidirectional. Must be\n",
      " |              one of forward (default), reverse, or bidirectional.\n",
      " |      \n",
      " |          hidden_size: Number of neurons in the hidden layer\n",
      " |      \n",
      " |          layout: The shape format of inputs X, initial_h and outputs Y, Y_h. If 0,\n",
      " |              the following shapes are expected: X.shape = [seq_length, batch_size,\n",
      " |              input_size], Y.shape = [seq_length, num_directions, batch_size,\n",
      " |              hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size,\n",
      " |              hidden_size]. If 1, the following shapes are expected: X.shape =\n",
      " |              [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length,\n",
      " |              num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size,\n",
      " |              num_directions, hidden_size].\n",
      " |      \n",
      " |          linear_before_reset: When computing the output of the hidden gate, apply the\n",
      " |              linear transformation before multiplying by the output of the reset\n",
      " |              gate.\n",
      " |  \n",
      " |  HardSwish(self, X: 'T_HardSwish') -> 'T_HardSwish'\n",
      " |      [üåê HardSwish(14)](https://onnx.ai/onnx/operators/onnx__HardSwish.html#hardswish-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      HardSwish takes one input data (Tensor<T>) and produces one output data (Tensor<T>) where\n",
      " |      the HardSwish function, y = x * max(0, min(1, alpha * x + beta)) = x * HardSigmoid<alpha, beta>(x),\n",
      " |      where alpha = 1/6 and beta = 0.5, is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  LSTM(self, X: 'T_LSTM', W: 'T_LSTM', R: 'T_LSTM', B: 'Optional[T_LSTM]' = None, sequence_lens: 'Optional[T1_LSTM]' = None, initial_h: 'Optional[T_LSTM]' = None, initial_c: 'Optional[T_LSTM]' = None, P: 'Optional[T_LSTM]' = None, *, activation_alpha: 'Optional[Sequence[float]]' = None, activation_beta: 'Optional[Sequence[float]]' = None, activations: 'Optional[Sequence[str]]' = None, clip: 'Optional[float]' = None, direction: 'str' = 'forward', hidden_size: 'Optional[int]' = None, input_forget: 'int' = 0, layout: 'int' = 0) -> 'Tuple[T_LSTM, T_LSTM, T_LSTM]'\n",
      " |      [üåê LSTM(14)](https://onnx.ai/onnx/operators/onnx__LSTM.html#lstm-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes an one-layer LSTM. This operator is usually supported via some\n",
      " |      custom implementation such as CuDNN.\n",
      " |      \n",
      " |      Notations:\n",
      " |      \n",
      " |      * `X` - input tensor\n",
      " |      * `i` - input gate\n",
      " |      * `o` - output gate\n",
      " |      * `f` - forget gate\n",
      " |      * `c` - cell gate\n",
      " |      * `t` - time step (t-1 means previous time step)\n",
      " |      * `W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates\n",
      " |      * `R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates\n",
      " |      * `Wb[iofc]` - W bias vectors for input, output, forget, and cell gates\n",
      " |      * `Rb[iofc]` - R bias vectors for input, output, forget, and cell gates\n",
      " |      * `P[iof]`  - P peephole weight vector for input, output, and forget gates\n",
      " |      * `WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates\n",
      " |      * `RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates\n",
      " |      * `WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates\n",
      " |      * `RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates\n",
      " |      * `PB[iof]`  - P peephole weight vector for backward input, output, and forget gates\n",
      " |      * `H` - Hidden state\n",
      " |      * `num_directions` - 2 if direction == bidirectional else 1\n",
      " |      \n",
      " |      Activation functions:\n",
      " |      \n",
      " |      * Relu(x)                - max(0, x)\n",
      " |      * Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})\n",
      " |      * Sigmoid(x)             - 1/(1 + e^{-x})\n",
      " |      \n",
      " |      NOTE: Below are optional\n",
      " |      \n",
      " |      * Affine(x)              - alpha*x + beta\n",
      " |      * LeakyRelu(x)           - x if x >= 0 else alpha * x\n",
      " |      * ThresholdedRelu(x)     - x if x >= alpha else 0\n",
      " |      * ScaledTanh(x)          - alpha*Tanh(beta*x)\n",
      " |      * HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)\n",
      " |      * Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)\n",
      " |      * Softsign(x)            - x/(1 + |x|)\n",
      " |      * Softplus(x)            - log(1 + e^x)\n",
      " |      \n",
      " |      Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):\n",
      " |      \n",
      " |      * it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)\n",
      " |      * ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)\n",
      " |      * ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)\n",
      " |      * Ct = ft (.) Ct-1 + it (.) ct\n",
      " |      * ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)\n",
      " |      * Ht = ot (.) h(Ct)\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) The input sequences packed (and potentially padded) into\n",
      " |              one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor for the gates. Concatenation of\n",
      " |              `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The\n",
      " |              tensor has shape `[num_directions, 4*hidden_size, input_size]`.\n",
      " |      \n",
      " |          R: (differentiable) The recurrence weight tensor. Concatenation of `R[iofc]`\n",
      " |              and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has\n",
      " |              shape `[num_directions, 4*hidden_size, hidden_size]`.\n",
      " |      \n",
      " |          B: (optional, differentiable) The bias tensor for input gate. Concatenation\n",
      " |              of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if\n",
      " |              bidirectional) along dimension 0. This tensor has shape\n",
      " |              `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed\n",
      " |              to be 0.\n",
      " |      \n",
      " |          sequence_lens: (optional, non-differentiable) Optional tensor specifying\n",
      " |              lengths of the sequences in a batch. If not specified - assumed all\n",
      " |              sequences in the batch to have length `seq_length`. It has shape\n",
      " |              `[batch_size]`.\n",
      " |      \n",
      " |          initial_h: (optional, non-differentiable) Optional initial value of the\n",
      " |              hidden. If not specified - assumed to be 0. It has shape\n",
      " |              `[num_directions, batch_size, hidden_size]`.\n",
      " |      \n",
      " |          initial_c: (optional, non-differentiable) Optional initial value of the\n",
      " |              cell. If not specified - assumed to be 0. It has shape `[num_directions,\n",
      " |              batch_size, hidden_size]`.\n",
      " |      \n",
      " |          P: (optional, differentiable) The weight tensor for peepholes. Concatenation\n",
      " |              of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has\n",
      " |              shape `[num_directions, 3*hidde_size]`. Optional: If not specified -\n",
      " |              assumed to be 0.\n",
      " |      \n",
      " |          activation_alpha: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.For example with LeakyRelu, the default\n",
      " |              alpha is 0.01.\n",
      " |      \n",
      " |          activation_beta: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.\n",
      " |      \n",
      " |          activations: A list of 3 (or 6 if bidirectional) activation functions for\n",
      " |              input, output, forget, cell, and hidden. The activation functions must\n",
      " |              be one of the activation functions specified above. Optional: See the\n",
      " |              equations for default if not specified.\n",
      " |      \n",
      " |          clip: Cell clip threshold. Clipping bounds the elements of a tensor in the\n",
      " |              range of [-threshold, +threshold] and is applied to the input of\n",
      " |              activations. No clip if not specified.\n",
      " |      \n",
      " |          direction: Specify if the RNN is forward, reverse, or bidirectional. Must be\n",
      " |              one of forward (default), reverse, or bidirectional.\n",
      " |      \n",
      " |          hidden_size: Number of neurons in the hidden layer\n",
      " |      \n",
      " |          input_forget: Couple the input and forget gates if 1.\n",
      " |      \n",
      " |          layout: The shape format of inputs X, initial_h, initial_c and outputs Y,\n",
      " |              Y_h, Y_c. If 0, the following shapes are expected: X.shape =\n",
      " |              [seq_length, batch_size, input_size], Y.shape = [seq_length,\n",
      " |              num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape =\n",
      " |              initial_c.shape = Y_c.shape = [num_directions, batch_size, hidden_size].\n",
      " |              If 1, the following shapes are expected: X.shape = [batch_size,\n",
      " |              seq_length, input_size], Y.shape = [batch_size, seq_length,\n",
      " |              num_directions, hidden_size], initial_h.shape = Y_h.shape =\n",
      " |              initial_c.shape = Y_c.shape = [batch_size, num_directions, hidden_size].\n",
      " |  \n",
      " |  Mul(self, A: 'T_Mul', B: 'T_Mul') -> 'T_Mul'\n",
      " |      [üåê Mul(14)](https://onnx.ai/onnx/operators/onnx__Mul.html#mul-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      (Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) First operand.\n",
      " |      \n",
      " |          B: (differentiable) Second operand.\n",
      " |  \n",
      " |  RNN(self, X: 'T_RNN', W: 'T_RNN', R: 'T_RNN', B: 'Optional[T_RNN]' = None, sequence_lens: 'Optional[T1_RNN]' = None, initial_h: 'Optional[T_RNN]' = None, *, activation_alpha: 'Optional[Sequence[float]]' = None, activation_beta: 'Optional[Sequence[float]]' = None, activations: 'Sequence[str]' = ('Tanh', 'Tanh'), clip: 'Optional[float]' = None, direction: 'str' = 'forward', hidden_size: 'Optional[int]' = None, layout: 'int' = 0) -> 'Tuple[T_RNN, T_RNN]'\n",
      " |      [üåê RNN(14)](https://onnx.ai/onnx/operators/onnx__RNN.html#rnn-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes an one-layer simple RNN. This operator is usually supported\n",
      " |      via some custom implementation such as CuDNN.\n",
      " |      \n",
      " |      Notations:\n",
      " |      \n",
      " |      * `X` - input tensor\n",
      " |      * `i` - input gate\n",
      " |      * `t` - time step (t-1 means previous time step)\n",
      " |      * `Wi` - W parameter weight matrix for input gate\n",
      " |      * `Ri` - R recurrence weight matrix for input gate\n",
      " |      * `Wbi` - W parameter bias vector for input gate\n",
      " |      * `Rbi` - R parameter bias vector for input gate\n",
      " |      * `WBi` - W parameter weight matrix for backward input gate\n",
      " |      * `RBi` - R recurrence weight matrix for backward input gate\n",
      " |      * `WBbi` - WR bias vectors for backward input gate\n",
      " |      * `RBbi` - RR bias vectors for backward input gate\n",
      " |      * `H` - Hidden state\n",
      " |      * `num_directions` - 2 if direction == bidirectional else 1\n",
      " |      \n",
      " |      Activation functions:\n",
      " |      \n",
      " |      * Relu(x)                - max(0, x)\n",
      " |      * Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})\n",
      " |      * Sigmoid(x)             - 1/(1 + e^{-x})\n",
      " |      \n",
      " |      NOTE: Below are optional\n",
      " |      \n",
      " |      * Affine(x)              - alpha*x + beta\n",
      " |      * LeakyRelu(x)           - x if x >= 0 else alpha * x\n",
      " |      * ThresholdedRelu(x)     - x if x >= alpha else 0\n",
      " |      * ScaledTanh(x)          - alpha*Tanh(beta*x)\n",
      " |      * HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)\n",
      " |      * Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)\n",
      " |      * Softsign(x)            - x/(1 + |x|)\n",
      " |      * Softplus(x)            - log(1 + e^x)\n",
      " |      \n",
      " |      Equations (Default: f=Tanh):\n",
      " |      \n",
      " |      * Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) The input sequences packed (and potentially padded) into\n",
      " |              one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor for input gate. Concatenation of `Wi`\n",
      " |              and `WBi` (if bidirectional). The tensor has shape `[num_directions,\n",
      " |              hidden_size, input_size]`.\n",
      " |      \n",
      " |          R: (differentiable) The recurrence weight tensor. Concatenation of `Ri` and\n",
      " |              `RBi` (if bidirectional). The tensor has shape `[num_directions,\n",
      " |              hidden_size, hidden_size]`.\n",
      " |      \n",
      " |          B: (optional, differentiable) The bias tensor for input gate. Concatenation\n",
      " |              of `[Wbi, Rbi]` and `[WBbi, RBbi]` (if bidirectional). The tensor has\n",
      " |              shape `[num_directions, 2*hidden_size]`. Optional: If not specified -\n",
      " |              assumed to be 0.\n",
      " |      \n",
      " |          sequence_lens: (optional, non-differentiable) Optional tensor specifying\n",
      " |              lengths of the sequences in a batch. If not specified - assumed all\n",
      " |              sequences in the batch to have length `seq_length`. It has shape\n",
      " |              `[batch_size]`.\n",
      " |      \n",
      " |          initial_h: (optional, non-differentiable) Optional initial value of the\n",
      " |              hidden. If not specified - assumed to be 0. It has shape\n",
      " |              `[num_directions, batch_size, hidden_size]`.\n",
      " |      \n",
      " |          activation_alpha: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.For example with LeakyRelu, the default\n",
      " |              alpha is 0.01.\n",
      " |      \n",
      " |          activation_beta: Optional scaling values used by some activation functions.\n",
      " |              The values are consumed in the order of activation functions, for\n",
      " |              example (f, g, h) in LSTM. Default values are the same as of\n",
      " |              corresponding ONNX operators.\n",
      " |      \n",
      " |          activations: One (or two if bidirectional) activation function for input\n",
      " |              gate. The activation function must be one of the activation functions\n",
      " |              specified above. Optional: Default `Tanh` if not specified.\n",
      " |      \n",
      " |          clip: Cell clip threshold. Clipping bounds the elements of a tensor in the\n",
      " |              range of [-threshold, +threshold] and is applied to the input of\n",
      " |              activations. No clip if not specified.\n",
      " |      \n",
      " |          direction: Specify if the RNN is forward, reverse, or bidirectional. Must be\n",
      " |              one of forward (default), reverse, or bidirectional.\n",
      " |      \n",
      " |          hidden_size: Number of neurons in the hidden layer\n",
      " |      \n",
      " |          layout: The shape format of inputs X, initial_h and outputs Y, Y_h. If 0,\n",
      " |              the following shapes are expected: X.shape = [seq_length, batch_size,\n",
      " |              input_size], Y.shape = [seq_length, num_directions, batch_size,\n",
      " |              hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size,\n",
      " |              hidden_size]. If 1, the following shapes are expected: X.shape =\n",
      " |              [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length,\n",
      " |              num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size,\n",
      " |              num_directions, hidden_size].\n",
      " |  \n",
      " |  Relu(self, X: 'T_Relu') -> 'T_Relu'\n",
      " |      [üåê Relu(14)](https://onnx.ai/onnx/operators/onnx__Relu.html#relu-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Relu takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  Reshape(self, data: 'T_Reshape', shape: 'INT64', *, allowzero: 'int' = 0) -> 'T_Reshape'\n",
      " |      [üåê Reshape(14)](https://onnx.ai/onnx/operators/onnx__Reshape.html#reshape-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Reshape the input tensor similar to numpy.reshape.\n",
      " |      First input is the data tensor, second input is a shape tensor which specifies the output shape. It outputs the reshaped tensor.\n",
      " |      At most one dimension of the new shape can be -1. In this case, the value is\n",
      " |      inferred from the size of the tensor and the remaining dimensions. A dimension\n",
      " |      could also be 0, in which case the actual dimension value is unchanged (i.e. taken\n",
      " |      from the input tensor). If 'allowzero' is set, and the new shape includes 0, the\n",
      " |      dimension will be set explicitly to zero (i.e. not taken from input tensor).\n",
      " |      Shape (second input) could be an empty shape, which means converting to a scalar.\n",
      " |      The input tensor's shape and the output tensor's shape are required to have the same number of elements.\n",
      " |      \n",
      " |      If the attribute 'allowzero' is set, it is invalid for the specified shape to\n",
      " |      contain both a zero value and -1, as the value of the dimension corresponding\n",
      " |      to -1 cannot be determined uniquely.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          shape: (non-differentiable) Specified shape for output.\n",
      " |      \n",
      " |          allowzero: (Optional) By default, when any value in the 'shape' input is\n",
      " |              equal to zero the corresponding dimension value is copied from the input\n",
      " |              tensor dynamically. allowzero=1 indicates that if any value in the\n",
      " |              'shape' input is set to zero, the zero value is honored, similar to\n",
      " |              NumPy.\n",
      " |  \n",
      " |  Sub(self, A: 'T_Sub', B: 'T_Sub') -> 'T_Sub'\n",
      " |      [üåê Sub(14)](https://onnx.ai/onnx/operators/onnx__Sub.html#sub-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Performs element-wise binary subtraction (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      (Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) First operand.\n",
      " |      \n",
      " |          B: (differentiable) Second operand.\n",
      " |  \n",
      " |  Trilu(self, input: 'T_Trilu', k: 'Optional[INT64]' = None, *, upper: 'int' = 1) -> 'T_Trilu'\n",
      " |      [üåê Trilu(14)](https://onnx.ai/onnx/operators/onnx__Trilu.html#trilu-14 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given a 2-D matrix or batches of 2-D matrices, returns the upper or lower triangular part of the tensor(s).\n",
      " |      The attribute \"upper\" determines whether the upper or lower part is retained. If set to true,\n",
      " |      the upper triangular matrix is retained. Lower triangular matrix is retained otherwise.\n",
      " |      Default value for the \"upper\" attribute is true.\n",
      " |      Trilu takes one input tensor of shape [*, N, M], where * is zero or more batch dimensions. The upper triangular part consists\n",
      " |      of the elements on and above the given diagonal (k). The lower triangular part consists of elements on and below the diagonal.\n",
      " |      All other elements in the matrix are set to zero.\n",
      " |      If k = 0, the triangular part on and above/below the main diagonal is retained.\n",
      " |      If upper is set to true, a positive k retains the upper triangular matrix excluding the main diagonal and (k-1) diagonals above it.\n",
      " |      A negative k value retains the main diagonal and |k| diagonals below it.\n",
      " |      If upper is set to false, a positive k retains the lower triangular matrix including the main diagonal and k diagonals above it.\n",
      " |      A negative k value excludes the main diagonal and (|k|-1) diagonals below it.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of rank 2 or higher.\n",
      " |      \n",
      " |          k: (optional, non-differentiable) A 0-D tensor containing a single value\n",
      " |              corresponding to the number diagonals above or below the main diagonal\n",
      " |              to exclude or include. Default value is 0 if it's not specified.\n",
      " |      \n",
      " |          upper: Boolean. Indicates whether upper or lower part of matrix is retained.\n",
      " |              Default is true.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset14.Opset14:\n",
      " |  \n",
      " |  T1_GRU = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T1_LSTM = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T1_RNN = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T2_CumSum = ~T2_CumSum\n",
      " |  \n",
      " |  T_Add = ~T_Add\n",
      " |  \n",
      " |  T_CumSum = ~T_CumSum\n",
      " |  \n",
      " |  T_Div = ~T_Div\n",
      " |  \n",
      " |  T_GRU = ~T_GRU\n",
      " |  \n",
      " |  T_HardSwish = ~T_HardSwish\n",
      " |  \n",
      " |  T_LSTM = ~T_LSTM\n",
      " |  \n",
      " |  T_Mul = ~T_Mul\n",
      " |  \n",
      " |  T_RNN = ~T_RNN\n",
      " |  \n",
      " |  T_Relu = ~T_Relu\n",
      " |  \n",
      " |  T_Reshape = ~T_Reshape\n",
      " |  \n",
      " |  T_Sub = ~T_Sub\n",
      " |  \n",
      " |  T_Trilu = ~T_Trilu\n",
      " |  \n",
      " |  U_BatchNormalization = ~U_BatchNormalization\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset13.Opset13:\n",
      " |  \n",
      " |  Abs(self, X: 'T_Abs') -> 'T_Abs'\n",
      " |      [üåê Abs(13)](https://onnx.ai/onnx/operators/onnx__Abs.html#abs-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Absolute takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where absolute value, y = abs(x), is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  ArgMax(self, data: 'T_ArgMax', *, axis: 'int' = 0, keepdims: 'int' = 1, select_last_index: 'int' = 0) -> 'INT64'\n",
      " |      [üåê ArgMax(13)](https://onnx.ai/onnx/operators/onnx__ArgMax.html#argmax-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the indices of the max elements of the input tensor's element along the\n",
      " |      provided axis. The resulting tensor has the same rank as the input if keepdims equals 1.\n",
      " |      If keepdims equals 0, then the resulting tensor has the reduced dimension pruned.\n",
      " |      If select_last_index is True (default False), the index of the last occurrence of the max\n",
      " |      is selected if the max appears more than once in the input. Otherwise the index of the\n",
      " |      first occurrence is selected.\n",
      " |      The type of the output tensor is integer.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (non-differentiable) An input tensor.\n",
      " |      \n",
      " |          axis: The axis in which to compute the arg indices. Accepted range is [-r,\n",
      " |              r-1] where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          select_last_index: Whether to select the last index or the first index if\n",
      " |              the {name} appears in multiple indices, default is False (first index).\n",
      " |  \n",
      " |  ArgMin(self, data: 'T_ArgMin', *, axis: 'int' = 0, keepdims: 'int' = 1, select_last_index: 'int' = 0) -> 'INT64'\n",
      " |      [üåê ArgMin(13)](https://onnx.ai/onnx/operators/onnx__ArgMin.html#argmin-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the indices of the min elements of the input tensor's element along the\n",
      " |      provided axis. The resulting tensor has the same rank as the input if keepdims equals 1.\n",
      " |      If keepdims equals 0, then the resulting tensor has the reduced dimension pruned.\n",
      " |      If select_last_index is True (default False), the index of the last occurrence of the min\n",
      " |      is selected if the min appears more than once in the input. Otherwise the index of the\n",
      " |      first occurrence is selected.\n",
      " |      The type of the output tensor is integer.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (non-differentiable) An input tensor.\n",
      " |      \n",
      " |          axis: The axis in which to compute the arg indices. Accepted range is [-r,\n",
      " |              r-1] where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          select_last_index: Whether to select the last index or the first index if\n",
      " |              the {name} appears in multiple indices, default is False (first index).\n",
      " |  \n",
      " |  Cast(self, input: 'T1_Cast', *, to: 'int') -> 'T2_Cast'\n",
      " |      [üåê Cast(13)](https://onnx.ai/onnx/operators/onnx__Cast.html#cast-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator casts the elements of a given input tensor to a data type\n",
      " |      specified by the 'to' argument and returns an output tensor of the same size in\n",
      " |      the converted type. The 'to' argument must be one of the data types specified\n",
      " |      in the 'DataType' enum field in the TensorProto message.\n",
      " |      \n",
      " |      Casting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n",
      " |      (e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\n",
      " |      yield result 100. There are some string literals reserved for special floating-point values;\n",
      " |      \"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\n",
      " |      Any string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\n",
      " |      this case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\n",
      " |      to string tensors, plain floating-point representation (such as \"314.15926\") would be used.\n",
      " |      Converting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\n",
      " |      of converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n",
      " |      \n",
      " |      Conversion from a numerical type to any numerical type is always allowed.\n",
      " |      User must be aware of precision loss and value change caused by range difference between two types.\n",
      " |      For example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\n",
      " |      an integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
      " |      \n",
      " |      In more detail, the conversion among numerical types should follow these rules:\n",
      " |      \n",
      " |      * Casting from floating point to:\n",
      " |        * floating point: +/- infinity if OOR (out of range).\n",
      " |        * fixed point: undefined if OOR.\n",
      " |        * bool: +/- 0.0 to False; all else to True.\n",
      " |      * Casting from fixed point to:\n",
      " |        * floating point: +/- infinity if OOR. (+ infinity in the case of uint)\n",
      " |        * fixed point: when OOR, discard higher bits and reinterpret (with respect to two's complement representation for\n",
      " |          signed types). For example, 200 (int16) -> -56 (int8).\n",
      " |        * bool: zero to False; nonzero to True.\n",
      " |      * Casting from bool to:\n",
      " |        * floating point: `{1.0, 0.0}`.\n",
      " |        * fixed point: `{1, 0}`.\n",
      " |        * bool: no change.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor to be cast.\n",
      " |      \n",
      " |          to: The data type to which the elements of the input tensor are cast.\n",
      " |              Strictly must be one of the types from DataType enum in TensorProto\n",
      " |  \n",
      " |  Ceil(self, X: 'T_Ceil') -> 'T_Ceil'\n",
      " |      [üåê Ceil(13)](https://onnx.ai/onnx/operators/onnx__Ceil.html#ceil-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Ceil takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the ceil is, y = ceil(x), is applied to\n",
      " |      the tensor elementwise. If x is integral, +0, -0, NaN,  or infinite, x itself is returned.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  Clip(self, input: 'T_Clip', min: 'Optional[T_Clip]' = None, max: 'Optional[T_Clip]' = None) -> 'T_Clip'\n",
      " |      [üåê Clip(13)](https://onnx.ai/onnx/operators/onnx__Clip.html#clip-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Clip operator limits the given input within an interval. The interval is\n",
      " |      specified by the inputs 'min' and 'max'. They default to\n",
      " |      numeric_limits::lowest() and numeric_limits::max(), respectively.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor whose elements to be clipped\n",
      " |      \n",
      " |          min: (optional, non-differentiable) Minimum value, under which element is\n",
      " |              replaced by min. It must be a scalar(tensor of empty shape).\n",
      " |      \n",
      " |          max: (optional, non-differentiable) Maximum value, above which element is\n",
      " |              replaced by max. It must be a scalar(tensor of empty shape).\n",
      " |  \n",
      " |  Concat(self, *inputs: 'T_Concat', axis: 'int') -> 'T_Concat'\n",
      " |      [üåê Concat(13)](https://onnx.ai/onnx/operators/onnx__Concat.html#concat-13 \"Online Documentation\")\n",
      " |      \n",
      " |      Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: (variadic, differentiable) List of tensors for concatenation\n",
      " |      \n",
      " |          axis: Which axis to concat on. A negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-r, r-1] where r = rank(inputs)..\n",
      " |  \n",
      " |  Constant(self, *, sparse_value: 'Optional[SparseTensorProto]' = None, value: 'Optional[TensorProto]' = None, value_float: 'Optional[float]' = None, value_floats: 'Optional[Sequence[float]]' = None, value_int: 'Optional[int]' = None, value_ints: 'Optional[Sequence[int]]' = None, value_string: 'Optional[str]' = None, value_strings: 'Optional[Sequence[str]]' = None) -> 'T_Constant'\n",
      " |      [üåê Constant(13)](https://onnx.ai/onnx/operators/onnx__Constant.html#constant-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      This operator produces a constant tensor. Exactly one of the provided attributes, either value, sparse_value,\n",
      " |      or value_* must be specified.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          sparse_value: The value for the elements of the output tensor in sparse\n",
      " |              format.\n",
      " |      \n",
      " |          value: The value for the elements of the output tensor.\n",
      " |      \n",
      " |          value_float: The value for the sole element for the scalar, float32, output\n",
      " |              tensor.\n",
      " |      \n",
      " |          value_floats: The values for the elements for the 1D, float32, output\n",
      " |              tensor.\n",
      " |      \n",
      " |          value_int: The value for the sole element for the scalar, int64, output\n",
      " |              tensor.\n",
      " |      \n",
      " |          value_ints: The values for the elements for the 1D, int64, output tensor.\n",
      " |      \n",
      " |          value_string: The value for the sole element for the scalar, UTF-8 string,\n",
      " |              output tensor.\n",
      " |      \n",
      " |          value_strings: The values for the elements for the 1D, UTF-8 string, output\n",
      " |              tensor.\n",
      " |  \n",
      " |  DepthToSpace(self, input: 'T_DepthToSpace', *, blocksize: 'int', mode: 'str' = 'DCR') -> 'T_DepthToSpace'\n",
      " |      [üåê DepthToSpace(13)](https://onnx.ai/onnx/operators/onnx__DepthToSpace.html#depthtospace-13 \"Online Documentation\")\n",
      " |      \n",
      " |      DepthToSpace rearranges (permutes) data from depth into blocks of spatial data.\n",
      " |      This is the reverse transformation of SpaceToDepth. More specifically, this op outputs a copy of\n",
      " |      the input tensor where values from the depth dimension are moved in spatial blocks to the height\n",
      " |      and width dimensions. By default, `mode` = `DCR`.\n",
      " |      In the DCR mode, elements along the depth dimension from the input tensor are rearranged in the\n",
      " |      following order: depth, column, and then row. The output y is computed from the input x as below:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          b, c, h, w = x.shape\n",
      " |          tmp = np.reshape(x, [b, blocksize, blocksize, c // (blocksize**2), h, w])\n",
      " |          tmp = np.transpose(tmp, [0, 3, 4, 1, 5, 2])\n",
      " |          y = np.reshape(tmp, [b, c // (blocksize**2), h * blocksize, w * blocksize])\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      In the CRD mode, elements along the depth dimension from the input tensor are rearranged in the\n",
      " |      following order: column, row, and the depth. The output y is computed from the input x as below:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          b, c, h, w = x.shape\n",
      " |          tmp = np.reshape(x, [b, c // (blocksize ** 2), blocksize, blocksize, h, w])\n",
      " |          tmp = np.transpose(tmp, [0, 1, 4, 2, 5, 3])\n",
      " |          y = np.reshape(tmp, [b, c // (blocksize ** 2), h * blocksize, w * blocksize])\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of [N,C,H,W], where N is the batch\n",
      " |              axis, C is the channel or depth, H is the height and W is the width.\n",
      " |      \n",
      " |          blocksize: Blocks of [blocksize, blocksize] are moved.\n",
      " |      \n",
      " |          mode: DCR (default) for depth-column-row order re-arrangement. Use CRD for\n",
      " |              column-row-depth order.\n",
      " |  \n",
      " |  DequantizeLinear(self, x: 'T_DequantizeLinear', x_scale: 'FLOAT', x_zero_point: 'Optional[T_DequantizeLinear]' = None, *, axis: 'int' = 1) -> 'FLOAT'\n",
      " |      [üåê DequantizeLinear(13)](https://onnx.ai/onnx/operators/onnx__DequantizeLinear.html#dequantizelinear-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The linear dequantization operator. It consumes a quantized tensor, a scale, and a zero point to compute the full precision tensor.\n",
      " |      The dequantization formula is `y = (x - x_zero_point) * x_scale`. `x_scale` and `x_zero_point` must have same shape, and can be either a scalar\n",
      " |      for per-tensor / per layer quantization, or a 1-D tensor for per-axis quantization.\n",
      " |      `x_zero_point` and `x` must have same type. `x` and `y` must have same shape. In the case of dequantizing int32,\n",
      " |      there's no zero point (zero point is supposed to be 0).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: N-D quantized input tensor to be de-quantized.\n",
      " |      \n",
      " |          x_scale: Scale for input 'x'. It can be a scalar, which means a\n",
      " |              per-tensor/layer dequantization, or a 1-D tensor for per-axis\n",
      " |              dequantization.\n",
      " |      \n",
      " |          x_zero_point: (optional) Zero point for input 'x'. Shape must match x_scale.\n",
      " |              It's optional. Zero point is 0 when it's not specified.\n",
      " |      \n",
      " |          axis: (Optional) The axis of the dequantizing dimension of the input tensor.\n",
      " |              Ignored for per-tensor quantization. Negative value means counting\n",
      " |              dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |  \n",
      " |  Dropout(self, data: 'T_Dropout', ratio: 'Optional[T1_Dropout]' = None, training_mode: 'Optional[T2_Dropout]' = None, *, seed: 'Optional[int]' = None) -> 'Tuple[T_Dropout, T2_Dropout]'\n",
      " |      [üåê Dropout(13)](https://onnx.ai/onnx/operators/onnx__Dropout.html#dropout-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Dropout takes an input floating-point tensor, an optional input ratio (floating-point scalar) and an optional input training_mode (boolean scalar). It produces two tensor outputs,\n",
      " |      output (floating-point tensor) and mask (optional `Tensor<bool>`). If `training_mode` is true then the output Y will be a random dropout;\n",
      " |      Note that this Dropout scales the masked input data by the following equation, so to convert the trained model into inference mode,\n",
      " |      the user can simply not pass `training_mode` input or set it to false.\n",
      " |      ::\n",
      " |      \n",
      " |          output = scale * data * mask,\n",
      " |      \n",
      " |      \n",
      " |      where\n",
      " |      ::\n",
      " |      \n",
      " |          scale = 1. / (1. - ratio).\n",
      " |      \n",
      " |      \n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) The input data as Tensor.\n",
      " |      \n",
      " |          ratio: (optional, non-differentiable) The ratio of random dropout, with\n",
      " |              value in [0, 1). If this input was not set, or if it was set to 0, the\n",
      " |              output would be a simple copy of the input. If it's non-zero, output\n",
      " |              will be a random dropout of the scaled input, which is typically the\n",
      " |              case during training. It is an optional value, if not specified it will\n",
      " |              default to 0.5.\n",
      " |      \n",
      " |          training_mode: (optional, non-differentiable) If set to true then it\n",
      " |              indicates dropout is being used for training. It is an optional value\n",
      " |              hence unless specified explicitly, it is false. If it is false, ratio is\n",
      " |              ignored and the operation mimics inference mode where nothing will be\n",
      " |              dropped from the input data and if mask is requested as output it will\n",
      " |              contain all ones.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  Equal(self, A: 'T_Equal', B: 'T_Equal') -> 'T1_Equal'\n",
      " |      [üåê Equal(13)](https://onnx.ai/onnx/operators/onnx__Equal.html#equal-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `equal` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Erf(self, input: 'T_Erf') -> 'T_Erf'\n",
      " |      [üåê Erf(13)](https://onnx.ai/onnx/operators/onnx__Erf.html#erf-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the error function of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Exp(self, input: 'T_Exp') -> 'T_Exp'\n",
      " |      [üåê Exp(13)](https://onnx.ai/onnx/operators/onnx__Exp.html#exp-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the exponential of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Expand(self, input: 'T_Expand', shape: 'INT64') -> 'T_Expand'\n",
      " |      [üåê Expand(13)](https://onnx.ai/onnx/operators/onnx__Expand.html#expand-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Broadcast the input tensor following the given shape and the broadcast rule.\n",
      " |      The broadcast rule is similar to numpy.array(input) * numpy.ones(shape):\n",
      " |      Dimensions are right alignment;\n",
      " |      Two corresponding dimensions must have the same value, or one of them is equal to 1.\n",
      " |      Also, this operator is similar to numpy.broadcast_to(input, shape),\n",
      " |      but the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().\n",
      " |      It is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,\n",
      " |      or the shape.ndim < input.shape.ndim.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |      \n",
      " |          shape: (non-differentiable) A 1-D tensor indicates the shape you want to\n",
      " |              expand to, following the broadcast rule\n",
      " |  \n",
      " |  Flatten(self, input: 'T_Flatten', *, axis: 'int' = 1) -> 'T_Flatten'\n",
      " |      [üåê Flatten(13)](https://onnx.ai/onnx/operators/onnx__Flatten.html#flatten-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Flattens the input tensor into a 2D matrix. If input tensor has shape\n",
      " |      (d_0, d_1, ... d_n) then the output will have shape\n",
      " |      (d_0 X d_1 ... d_(axis-1), d_axis X d_(axis+1) ... X dn).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) A tensor of rank >= axis.\n",
      " |      \n",
      " |          axis: Indicate up to which input dimensions (exclusive) should be flattened\n",
      " |              to the outer dimension of the output. The value for axis must be in the\n",
      " |              range [-r, r], where r is the rank of the input tensor. Negative value\n",
      " |              means counting dimensions from the back. When axis = 0, the shape of the\n",
      " |              output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input\n",
      " |              tensor is (d_0, d_1, ... d_n).\n",
      " |  \n",
      " |  Floor(self, X: 'T_Floor') -> 'T_Floor'\n",
      " |      [üåê Floor(13)](https://onnx.ai/onnx/operators/onnx__Floor.html#floor-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Floor takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the floor is, y = floor(x), is applied to\n",
      " |      the tensor elementwise. If x is integral, +0, -0, NaN,  or infinite, x itself is returned.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  Gather(self, data: 'T_Gather', indices: 'Tind_Gather', *, axis: 'int' = 0) -> 'T_Gather'\n",
      " |      [üåê Gather(13)](https://onnx.ai/onnx/operators/onnx__Gather.html#gather-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given `data` tensor of rank r >= 1, and `indices` tensor of rank q, gather\n",
      " |      entries of the axis dimension of `data` (by default outer-most one as axis=0) indexed by `indices`, and concatenates\n",
      " |      them in an output tensor of rank q + (r - 1).\n",
      " |      \n",
      " |      If `axis = 0`, let `k = indices[i_{0}, ..., i_{q-1}]`\n",
      " |      then `output[i_{0}, ..., i_{q-1}, j_{0}, ..., j_{r-2}] = input[k , j_{0}, ..., j_{r-2}]`:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2],\n",
      " |              [2.3, 3.4],\n",
      " |              [4.5, 5.7],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [0, 1],\n",
      " |              [1, 2],\n",
      " |          ]\n",
      " |          output = [\n",
      " |              [\n",
      " |                  [1.0, 1.2],\n",
      " |                  [2.3, 3.4],\n",
      " |              ],\n",
      " |              [\n",
      " |                  [2.3, 3.4],\n",
      " |                  [4.5, 5.7],\n",
      " |              ],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      If `axis = 1`, let `k = indices[i_{0}, ..., i_{q-1}]`\n",
      " |      then `output[j_{0}, i_{0}, ..., i_{q-1}, j_{1}, ..., j_{r-2}] = input[j_{0}, k, j_{1}, ..., j_{r-2}]`:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1.0, 1.2, 1.9],\n",
      " |              [2.3, 3.4, 3.9],\n",
      " |              [4.5, 5.7, 5.9],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [0, 2],\n",
      " |          ]\n",
      " |          axis = 1,\n",
      " |          output = [\n",
      " |                  [[1.0, 1.9]],\n",
      " |                  [[2.3, 3.9]],\n",
      " |                  [[4.5, 5.9]],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of int32/int64 indices, of any rank q.\n",
      " |              All index values are expected to be within bounds [-s, s-1] along axis\n",
      " |              of size s. It is an error if any of the index values are out of bounds.\n",
      " |      \n",
      " |          axis: Which axis to gather on. Negative value means counting dimensions from\n",
      " |              the back. Accepted range is [-r, r-1] where r = rank(data).\n",
      " |  \n",
      " |  GatherElements(self, data: 'T_GatherElements', indices: 'Tind_GatherElements', *, axis: 'int' = 0) -> 'T_GatherElements'\n",
      " |      [üåê GatherElements(13)](https://onnx.ai/onnx/operators/onnx__GatherElements.html#gatherelements-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      GatherElements takes two inputs `data` and `indices` of the same rank r >= 1\n",
      " |      and an optional attribute `axis` that identifies an axis of `data`\n",
      " |      (by default, the outer-most axis, that is axis 0). It is an indexing operation\n",
      " |      that produces its output by indexing into the input data tensor at index\n",
      " |      positions determined by elements of the `indices` tensor.\n",
      " |      Its output shape is the same as the shape of `indices` and consists of one value\n",
      " |      (gathered from the `data`) for each element in `indices`.\n",
      " |      \n",
      " |      For instance, in the 3-D case (r = 3), the output produced is determined\n",
      " |      by the following equations:\n",
      " |      ::\n",
      " |      \n",
      " |          out[i][j][k] = input[index[i][j][k]][j][k] if axis = 0,\n",
      " |          out[i][j][k] = input[i][index[i][j][k]][k] if axis = 1,\n",
      " |          out[i][j][k] = input[i][j][index[i][j][k]] if axis = 2,\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      This operator is also the inverse of ScatterElements. It is similar to Torch's gather operation.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1, 2],\n",
      " |              [3, 4],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [0, 0],\n",
      " |              [1, 0],\n",
      " |          ]\n",
      " |          axis = 1\n",
      " |          output = [\n",
      " |              [1, 1],\n",
      " |              [4, 3],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1, 2, 3],\n",
      " |              [4, 5, 6],\n",
      " |              [7, 8, 9],\n",
      " |          ]\n",
      " |          indices = [\n",
      " |              [1, 2, 0],\n",
      " |              [2, 0, 0],\n",
      " |          ]\n",
      " |          axis = 0\n",
      " |          output = [\n",
      " |              [4, 8, 3],\n",
      " |              [7, 2, 3],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of int32/int64 indices, with the same\n",
      " |              rank r as the input. All index values are expected to be within bounds\n",
      " |              [-s, s-1] along axis of size s. It is an error if any of the index\n",
      " |              values are out of bounds.\n",
      " |      \n",
      " |          axis: Which axis to gather on. Negative value means counting dimensions from\n",
      " |              the back. Accepted range is [-r, r-1] where r = rank(data).\n",
      " |  \n",
      " |  GatherND(self, data: 'T_GatherND', indices: 'INT64', *, batch_dims: 'int' = 0) -> 'T_GatherND'\n",
      " |      [üåê GatherND(13)](https://onnx.ai/onnx/operators/onnx__GatherND.html#gathernd-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given `data` tensor of rank `r` >= 1, `indices` tensor of rank `q` >= 1, and `batch_dims` integer `b`, this operator gathers\n",
      " |      slices of `data` into an output tensor of rank `q + r - indices_shape[-1] - 1 - b`.\n",
      " |      \n",
      " |      `indices` is an q-dimensional integer tensor, best thought of as a `(q-1)`-dimensional tensor of index-tuples into `data`,\n",
      " |      where each element defines a slice of `data`\n",
      " |      \n",
      " |      `batch_dims` (denoted as `b`) is an integer indicating the number of batch dimensions, i.e the leading `b` number of dimensions of\n",
      " |      `data` tensor and `indices` are representing the batches, and the gather starts from the `b+1` dimension.\n",
      " |      \n",
      " |      Some salient points about the inputs' rank and shape:\n",
      " |      \n",
      " |      1) r >= 1 and q >= 1 are to be honored. There is no dependency condition to be met between ranks `r` and `q`\n",
      " |      \n",
      " |      2) The first `b` dimensions of the shape of `indices` tensor and `data` tensor must be equal.\n",
      " |      \n",
      " |      3) b < min(q, r) is to be honored.\n",
      " |      \n",
      " |      4) The `indices_shape[-1]` should have a value between 1 (inclusive) and rank `r-b` (inclusive)\n",
      " |      \n",
      " |      5) All values in `indices` are expected to be within bounds [-s, s-1] along axis of size `s` (i.e.) `-data_shape[i] <= indices[...,i] <= data_shape[i] - 1`.\n",
      " |         It is an error if any of the index values are out of bounds.\n",
      " |      \n",
      " |      The output is computed as follows:\n",
      " |      \n",
      " |      The output tensor is obtained by mapping each index-tuple in the `indices` tensor to the corresponding slice of the input `data`.\n",
      " |      \n",
      " |      1) If `indices_shape[-1] > r-b` => error condition\n",
      " |      \n",
      " |      2) If `indices_shape[-1] == r-b`, since the rank of `indices` is `q`, `indices` can be thought of as `N` `(q-b-1)`-dimensional tensors\n",
      " |         containing 1-D tensors of dimension `r-b`, where `N` is an integer equals to the product of 1 and all the elements in the batch dimensions\n",
      " |         of the indices_shape. Let us think of each such `r-b` ranked tensor as `indices_slice`. Each *scalar value* corresponding to `data[0:b-1,indices_slice]`\n",
      " |         is filled into the corresponding location of the `(q-b-1)`-dimensional tensor to form the `output` tensor (Example 1 below)\n",
      " |      \n",
      " |      3) If `indices_shape[-1] < r-b`, since the rank of `indices` is `q`, `indices` can be thought of as `N` `(q-b-1)`-dimensional tensor\n",
      " |         containing 1-D tensors of dimension `< r-b`. Let us think of each such tensors as `indices_slice`. Each *tensor slice* corresponding\n",
      " |         to `data[0:b-1, indices_slice , :]` is filled into the corresponding location of the `(q-b-1)`-dimensional tensor\n",
      " |         to form the `output` tensor (Examples 2, 3, 4 and 5 below)\n",
      " |      \n",
      " |      This operator is the inverse of `ScatterND`.\n",
      " |      \n",
      " |      `Example 1`\n",
      " |      \n",
      " |        batch_dims = 0\n",
      " |      \n",
      " |        data    = [[0,1],[2,3]]   # data_shape = [2, 2]\n",
      " |      \n",
      " |        indices = [[0,0],[1,1]]   # indices_shape = [2, 2]\n",
      " |      \n",
      " |        output  = [0,3]           # output_shape = [2]\n",
      " |      \n",
      " |      `Example 2`\n",
      " |      \n",
      " |        batch_dims = 0\n",
      " |      \n",
      " |        data    = [[0,1],[2,3]]  # data_shape = [2, 2]\n",
      " |      \n",
      " |        indices = [[1],[0]]      # indices_shape = [2, 1]\n",
      " |      \n",
      " |        output  = [[2,3],[0,1]]  # output_shape = [2, 2]\n",
      " |      \n",
      " |      `Example 3`\n",
      " |      \n",
      " |        batch_dims = 0\n",
      " |      \n",
      " |        data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]\n",
      " |      \n",
      " |        indices = [[0,1],[1,0]]                 # indices_shape = [2, 2]\n",
      " |      \n",
      " |        output  = [[2,3],[4,5]]                 # output_shape = [2, 2]\n",
      " |      \n",
      " |      `Example 4`\n",
      " |      \n",
      " |        batch_dims = 0\n",
      " |      \n",
      " |        data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]\n",
      " |      \n",
      " |        indices = [[[0,1]],[[1,0]]]             # indices_shape = [2, 1, 2]\n",
      " |      \n",
      " |        output  = [[[2,3]],[[4,5]]]             # output_shape = [2, 1, 2]\n",
      " |      \n",
      " |      `Example 5`\n",
      " |      \n",
      " |        batch_dims = 1\n",
      " |      \n",
      " |        data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]\n",
      " |      \n",
      " |        indices = [[1],[0]]             # indices_shape = [2, 1]\n",
      " |      \n",
      " |        output  = [[2,3],[4,5]]             # output_shape = [2, 2]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: (non-differentiable) Tensor of rank q >= 1. All index values are\n",
      " |              expected to be within bounds [-s, s-1] along axis of size s. It is an\n",
      " |              error if any of the index values are out of bounds.\n",
      " |      \n",
      " |          batch_dims: The number of batch dimensions. The gather of indexing starts\n",
      " |              from dimension of data[batch_dims:]\n",
      " |  \n",
      " |  Gemm(self, A: 'T_Gemm', B: 'T_Gemm', C: 'Optional[T_Gemm]' = None, *, alpha: 'float' = 1.0, beta: 'float' = 1.0, transA: 'int' = 0, transB: 'int' = 0) -> 'T_Gemm'\n",
      " |      [üåê Gemm(13)](https://onnx.ai/onnx/operators/onnx__Gemm.html#gemm-13 \"Online Documentation\")\n",
      " |      \n",
      " |      General Matrix multiplication:\n",
      " |      https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3\n",
      " |      \n",
      " |      * A' = transpose(A) if transA else A\n",
      " |      * B' = transpose(B) if transB else B\n",
      " |      \n",
      " |      Compute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),\n",
      " |      input tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),\n",
      " |      and output tensor Y has shape (M, N). A will be transposed before doing the\n",
      " |      computation if attribute transA is non-zero, same for B and transB.\n",
      " |      This operator supports **unidirectional broadcasting** (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      This operator has **optional** inputs/outputs. See `ONNX <https://github.com/onnx/onnx/blob/master/docs/IR.md>`_ for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) Input tensor A. The shape of A should be (M, K) if\n",
      " |              transA is 0, or (K, M) if transA is non-zero.\n",
      " |      \n",
      " |          B: (differentiable) Input tensor B. The shape of B should be (K, N) if\n",
      " |              transB is 0, or (N, K) if transB is non-zero.\n",
      " |      \n",
      " |          C: (optional, differentiable) Optional input tensor C. If not specified, the\n",
      " |              computation is done as if C is a scalar 0. The shape of C should be\n",
      " |              unidirectional broadcastable to (M, N).\n",
      " |      \n",
      " |          alpha: Scalar multiplier for the product of input tensors A * B.\n",
      " |      \n",
      " |          beta: Scalar multiplier for input tensor C.\n",
      " |      \n",
      " |          transA: Whether A should be transposed\n",
      " |      \n",
      " |          transB: Whether B should be transposed\n",
      " |  \n",
      " |  Greater(self, A: 'T_Greater', B: 'T_Greater') -> 'T1_Greater'\n",
      " |      [üåê Greater(13)](https://onnx.ai/onnx/operators/onnx__Greater.html#greater-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `greater` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Hardmax(self, input: 'T_Hardmax', *, axis: 'int' = -1) -> 'T_Hardmax'\n",
      " |      [üåê Hardmax(13)](https://onnx.ai/onnx/operators/onnx__Hardmax.html#hardmax-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator computes the hardmax values for the given input:\n",
      " |      \n",
      " |       Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise\n",
      " |      \n",
      " |      The \"axis\" attribute indicates the dimension along which Hardmax\n",
      " |      will be performed. The output tensor has the same shape\n",
      " |      and contains the Hardmax values of the corresponding input.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The input tensor of rank >= axis.\n",
      " |      \n",
      " |          axis:\n",
      " |      Describes the dimension Hardmax will be performed on.\n",
      " |      Negative value\n",
      " |              means counting dimensions\n",
      " |      from the back. Accepted range is [-r, r-1]\n",
      " |              where r = rank(input).\n",
      " |  \n",
      " |  IsNaN(self, X: 'T1_IsNaN') -> 'T2_IsNaN'\n",
      " |      [üåê IsNaN(13)](https://onnx.ai/onnx/operators/onnx__IsNaN.html#isnan-13 \"Online Documentation\")\n",
      " |      \n",
      " |      Returns which elements of the input are NaN.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) input\n",
      " |  \n",
      " |  LRN(self, X: 'T_LRN', *, alpha: 'float' = 9.999999747378752e-05, beta: 'float' = 0.75, bias: 'float' = 1.0, size: 'int') -> 'T_LRN'\n",
      " |      [üåê LRN(13)](https://onnx.ai/onnx/operators/onnx__LRN.html#lrn-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Local Response Normalization proposed in the [AlexNet paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
      " |      It normalizes over local input regions.\n",
      " |      The local region is defined across the channels. For an element `X[n, c, d1, ..., dk]` in a tensor\n",
      " |      of shape `(N x C x D1 x D2, ..., Dk)`, its region is\n",
      " |      `{X[n, i, d1, ..., dk] | max(0, c - floor((size - 1) / 2)) <= i <= min(C - 1, c + ceil((size - 1) / 2))}`.\n",
      " |      \n",
      " |      `square_sum[n, c, d1, ..., dk] = sum(X[n, i, d1, ..., dk] ^ 2)`,\n",
      " |      where `max(0, c - floor((size - 1) / 2)) <= i <= min(C - 1, c + ceil((size - 1) / 2))`.\n",
      " |      \n",
      " |      `Y[n, c, d1, ..., dk] = X[n, c, d1, ..., dk] / (bias + alpha / size * square_sum[n, c, d1, ..., dk] ) ^ beta`\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size. Optionally, if dimension\n",
      " |              denotation is in effect, the operation expects the input data tensor to\n",
      " |              arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL,\n",
      " |              DATA_FEATURE, DATA_FEATURE ...].\n",
      " |      \n",
      " |          alpha: Scaling parameter.\n",
      " |      \n",
      " |          beta: The exponent.\n",
      " |      \n",
      " |          size: The number of channels to sum over\n",
      " |  \n",
      " |  Less(self, A: 'T_Less', B: 'T_Less') -> 'T1_Less'\n",
      " |      [üåê Less(13)](https://onnx.ai/onnx/operators/onnx__Less.html#less-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `less` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Log(self, input: 'T_Log') -> 'T_Log'\n",
      " |      [üåê Log(13)](https://onnx.ai/onnx/operators/onnx__Log.html#log-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the natural log of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  LogSoftmax(self, input: 'T_LogSoftmax', *, axis: 'int' = -1) -> 'T_LogSoftmax'\n",
      " |      [üåê LogSoftmax(13)](https://onnx.ai/onnx/operators/onnx__LogSoftmax.html#logsoftmax-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator computes the log of softmax values for the given input:\n",
      " |      \n",
      " |       LogSoftmax(input, axis) = Log(Softmax(input, axis=axis))\n",
      " |      \n",
      " |      The \"axis\" attribute indicates the dimension along which LogSoftmax\n",
      " |      will be performed. The output tensor has the same shape\n",
      " |      and contains the LogSoftmax values of the corresponding input.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The input tensor of rank >= axis.\n",
      " |      \n",
      " |          axis:\n",
      " |      Describes the dimension LogSoftmax will be performed on.\n",
      " |      Negative\n",
      " |              value means counting dimensions\n",
      " |      from the back. Accepted range is [-r,\n",
      " |              r-1] where r = rank(input).\n",
      " |  \n",
      " |  MatMul(self, A: 'T_MatMul', B: 'T_MatMul') -> 'T_MatMul'\n",
      " |      [üåê MatMul(13)](https://onnx.ai/onnx/operators/onnx__MatMul.html#matmul-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) N-dimensional matrix A\n",
      " |      \n",
      " |          B: (differentiable) N-dimensional matrix B\n",
      " |  \n",
      " |  Max(self, *data_0: 'T_Max') -> 'T_Max'\n",
      " |      [üåê Max(13)](https://onnx.ai/onnx/operators/onnx__Max.html#max-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Element-wise max of each of the input tensors (with Numpy-style broadcasting support).\n",
      " |      All inputs and outputs must have the same data type.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data_0: (variadic, differentiable) List of tensors for max.\n",
      " |  \n",
      " |  Mean(self, *data_0: 'T_Mean') -> 'T_Mean'\n",
      " |      [üåê Mean(13)](https://onnx.ai/onnx/operators/onnx__Mean.html#mean-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Element-wise mean of each of the input tensors (with Numpy-style broadcasting support).\n",
      " |      All inputs and outputs must have the same data type.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data_0: (variadic, differentiable) List of tensors for mean.\n",
      " |  \n",
      " |  MeanVarianceNormalization(self, X: 'T_MeanVarianceNormalization', *, axes: 'Sequence[int]' = (0, 2, 3)) -> 'T_MeanVarianceNormalization'\n",
      " |      [üåê MeanVarianceNormalization(13)](https://onnx.ai/onnx/operators/onnx__MeanVarianceNormalization.html#meanvariancenormalization-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |            A MeanVarianceNormalization Function: Perform mean variance normalization\n",
      " |            on the input tensor X using formula: `(X-EX)/sqrt(E(X-EX)^2)`\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          axes: A list of integers, along which to reduce. The default is to caculate\n",
      " |              along axes [0,2,3] for calculating mean and variance along each channel.\n",
      " |              Two variables with the same C-coordinate are associated with the same\n",
      " |              mean and variance.\n",
      " |  \n",
      " |  Min(self, *data_0: 'T_Min') -> 'T_Min'\n",
      " |      [üåê Min(13)](https://onnx.ai/onnx/operators/onnx__Min.html#min-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Element-wise min of each of the input tensors (with Numpy-style broadcasting support).\n",
      " |      All inputs and outputs must have the same data type.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data_0: (variadic, differentiable) List of tensors for min.\n",
      " |  \n",
      " |  Mod(self, A: 'T_Mod', B: 'T_Mod', *, fmod: 'int' = 0) -> 'T_Mod'\n",
      " |      [üåê Mod(13)](https://onnx.ai/onnx/operators/onnx__Mod.html#mod-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |        Performs element-wise binary modulus (with Numpy-style broadcasting support).\n",
      " |        The sign of the remainder is the same as that of the Divisor.\n",
      " |      \n",
      " |        Mod operator can also behave like C fmod() or numpy.fmod. In this case, the sign of the remainder however, will be the same as the Dividend\n",
      " |        (in contrast to integer mod). To force a behavior like numpy.fmod() an 'fmod' Attribute is provided.\n",
      " |        This attribute is set to 0 by default causing the behavior to be like integer mod.\n",
      " |        Setting this attribute to 1 causes the remainder to be calculated similar to that of numpy.fmod().\n",
      " |      \n",
      " |        If the input type is floating point, then `fmod` attribute must be set to 1.\n",
      " |      \n",
      " |        In case of dividend being zero, the results will be platform dependent.\n",
      " |      \n",
      " |        This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (differentiable) Dividend tensor\n",
      " |      \n",
      " |          B: (non-differentiable) Divisor tensor\n",
      " |      \n",
      " |          fmod: Whether the operator should behave like fmod (default=0 meaning it\n",
      " |              will do integer mods); Set this to 1 to force fmod treatment\n",
      " |  \n",
      " |  Neg(self, X: 'T_Neg') -> 'T_Neg'\n",
      " |      [üåê Neg(13)](https://onnx.ai/onnx/operators/onnx__Neg.html#neg-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Neg takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where each element flipped sign, y = -x, is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  NegativeLogLikelihoodLoss(self, input: 'T_NegativeLogLikelihoodLoss', target: 'Tind_NegativeLogLikelihoodLoss', weight: 'Optional[T_NegativeLogLikelihoodLoss]' = None, *, ignore_index: 'Optional[int]' = None, reduction: 'str' = 'mean') -> 'T_NegativeLogLikelihoodLoss'\n",
      " |      [üåê NegativeLogLikelihoodLoss(13)](https://onnx.ai/onnx/operators/onnx__NegativeLogLikelihoodLoss.html#negativeloglikelihoodloss-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      A NegativeLogLikelihoodLoss operator computes (weighted) negative log likelihood loss.\n",
      " |      Its \"input\" tensor has the shape of (N, C, d1, d2, ..., dk) where k >= 0.\n",
      " |      The \"input\" tensor contains log-probabilities for input[n, :, d_1, d_2,..., d_k] being in a class of [0, C).\n",
      " |      The operator's \"target\" input tensor has the shape of (N, d1, d2, ..., dk). It encodes class labels (one of C classes)\n",
      " |      or it may contain a special value (indicated by an attribute ignore_index) for N x d1 x d2 x ... x dk samples.\n",
      " |      The loss value for input[n, :, d_1, d_2,...d_k] being classified as class c = target[n][d_1][d_2]...[d_k] is computed as:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          loss[n][d_1][d_2]...[d_k] = -input[n][c][d_1][d_2]...[d_k].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      When an optional \"weight\" is provided, the sample loss is calculated as:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          loss[n][d_1][d_2]...[d_k] = -input[n][c][d_1][d_2]...[d_k] * weight[c].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      loss is zero for the case when target-value equals ignore_index.\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          loss[n][d_1][d_2]...[d_k] = 0, when target[n][d_1][d_2]...[d_k] = ignore_index\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      If \"reduction\" attribute is set to \"none\", the operator's output will be the above loss with shape (N, d1, d2, ..., dk).\n",
      " |      If \"reduction\" attribute is set to \"mean\" (the default attribute value), the output loss is (weight) averaged:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          mean(loss), if \"weight\" is not provided,\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      or if weight is provided,\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          sum(loss) / sum(weight[target[n][d_1][d_2]...[d_k]]]), for all samples.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      If \"reduction\" attribute is set to \"sum\", the output is a scalar: `sum(loss)`.\n",
      " |      \n",
      " |      See also https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          // negative log likelihood loss, \"none\" reduction\n",
      " |          N, C, d1 = 2, 3, 2\n",
      " |          input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],\n",
      " |                    [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]\n",
      " |          target = [[2, 1], [0, 2]]\n",
      " |      \n",
      " |          loss = np.zeros((N, d1))\n",
      " |          for n in range(N):\n",
      " |              for d_1 in range(d1):\n",
      " |                  c = target[n][d_1]\n",
      " |                  loss[n][d_1] = -input[n][c][d_1]\n",
      " |      \n",
      " |          // print(loss)\n",
      " |          // [[-3. -2.]\n",
      " |          //  [-0. -2.]]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          // weighted negative log likelihood loss, sum reduction\n",
      " |          N, C, d1 = 2, 3, 2\n",
      " |          input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],\n",
      " |                  [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]\n",
      " |          target = [[2, 1], [0, 2]]\n",
      " |          weight = [0.2, 0.3, 0.1]\n",
      " |          loss = np.zeros((N, d1))\n",
      " |          for n in range(N):\n",
      " |              for d_1 in range(d1):\n",
      " |                  c = target[n][d_1]\n",
      " |                  loss[n][d_1] = -input[n][c][d_1] * weight[c]\n",
      " |      \n",
      " |          loss = np.sum(loss)\n",
      " |          // print(loss)\n",
      " |          // -1.1\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 3:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          // weighted negative log likelihood loss, mean reduction\n",
      " |          N, C, d1 = 2, 3, 2\n",
      " |          input = [[[1.0, 2.0], [2.0, 2.0], [3.0, 2.0]],\n",
      " |                  [[0.0, 1.0], [2.0, 2.0], [1.0, 2]]]\n",
      " |          target = [[2, 1], [0, 2]]\n",
      " |          weight = [0.2, 0.3, 0.1]\n",
      " |          loss = np.zeros((N, d1))\n",
      " |          weight_total = 0\n",
      " |          for n in range(N):\n",
      " |              for d_1 in range(d1):\n",
      " |                  c = target[n][d_1]\n",
      " |                  loss[n][d_1] = -input[n][c][d_1] * weight[c]\n",
      " |                  weight_total = weight_total + weight[c]\n",
      " |      \n",
      " |          loss = np.sum(loss) / weight_total\n",
      " |          // print(loss)\n",
      " |          // -1.57\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of shape (N, C) or (N, C, d1, d2, ...,\n",
      " |              dk).\n",
      " |      \n",
      " |          target: (non-differentiable) Target tensor of shape (N) or (N, d1, d2, ...,\n",
      " |              dk). Target element value shall be in range of [0, C). If ignore_index\n",
      " |              is specified, it may have a value outside [0, C) and the target values\n",
      " |              should either be in the range [0, C) or have the value ignore_index.\n",
      " |      \n",
      " |          weight: (optional, non-differentiable) Optional rescaling weight tensor. If\n",
      " |              given, it has to be a tensor of size C. Otherwise, it is treated as if\n",
      " |              having all ones.\n",
      " |      \n",
      " |          ignore_index: Specifies a target value that is ignored and does not\n",
      " |              contribute to the input gradient. It's an optional value.\n",
      " |      \n",
      " |          reduction: Type of reduction to apply to loss: none, sum, mean (default).\n",
      " |              'none': the output is the loss for each sample. 'sum': the output will\n",
      " |              be summed. 'mean': the sum of the output will be divided by the sum of\n",
      " |              applied weights.\n",
      " |  \n",
      " |  NonZero(self, X: 'T_NonZero') -> 'INT64'\n",
      " |      [üåê NonZero(13)](https://onnx.ai/onnx/operators/onnx__NonZero.html#nonzero-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |          Returns the indices of the elements that are non-zero\n",
      " |          (in row-major order - by dimension).\n",
      " |          NonZero behaves similar to numpy.nonzero:\n",
      " |          https://docs.scipy.org/doc/numpy/reference/generated/numpy.nonzero.html,\n",
      " |          but for scalar input, NonZero produces output shape (0, N) instead of (1, N), which is different from Numpy's behavior.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) input\n",
      " |  \n",
      " |  QuantizeLinear(self, x: 'T1_QuantizeLinear', y_scale: 'FLOAT', y_zero_point: 'Optional[T2_QuantizeLinear]' = None, *, axis: 'int' = 1) -> 'T2_QuantizeLinear'\n",
      " |      [üåê QuantizeLinear(13)](https://onnx.ai/onnx/operators/onnx__QuantizeLinear.html#quantizelinear-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The linear quantization operator. It consumes a high precision tensor, a scale, and a zero point to compute the low precision / quantized tensor.\n",
      " |      The scale factor and zero point must have same shape, and can be either a scalar for per-tensor / per layer quantization, or a 1-D tensor for per-axis quantization.\n",
      " |      The quantization formula is y = saturate ((x / y_scale) + y_zero_point).\n",
      " |      For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\n",
      " |      For (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: N-D full precision Input tensor to be quantized.\n",
      " |      \n",
      " |          y_scale: Scale for doing quantization to get 'y'. It can be a scalar, which\n",
      " |              means per-tensor/layer quantization, or a 1-D Tensor for per-axis\n",
      " |              quantization.\n",
      " |      \n",
      " |          y_zero_point: (optional) Zero point for doing quantization to get 'y'. Shape\n",
      " |              must match y_scale. Default is uint8 with zero point of 0 if it's not\n",
      " |              specified.\n",
      " |      \n",
      " |          axis: (Optional) The axis of the quantization dimension of the input tensor.\n",
      " |              Ignored for per-tensor quantization. Negative value means counting\n",
      " |              dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |  \n",
      " |  Reciprocal(self, X: 'T_Reciprocal') -> 'T_Reciprocal'\n",
      " |      [üåê Reciprocal(13)](https://onnx.ai/onnx/operators/onnx__Reciprocal.html#reciprocal-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Reciprocal takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the reciprocal is, y = 1/x, is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  ReduceSum(self, data: 'T_ReduceSum', axes: 'Optional[INT64]' = None, *, keepdims: 'int' = 1, noop_with_empty_axes: 'int' = 0) -> 'T_ReduceSum'\n",
      " |      [üåê ReduceSum(13)](https://onnx.ai/onnx/operators/onnx__ReduceSum.html#reducesum-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Computes the sum of the input tensor's elements along the provided axes. The resulting\n",
      " |      tensor has the same rank as the input if keepdims equals 1. If keepdims equals 0, then\n",
      " |      the resulting tensor has the reduced dimension pruned. Input tensors of rank zero are\n",
      " |      valid.\n",
      " |      \n",
      " |      The above behavior is similar to numpy, with the exception that numpy defaults keepdims to\n",
      " |      False instead of True.\n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) Optional input list of integers, along\n",
      " |              which to reduce. The default is to reduce over all the dimensions of the\n",
      " |              input tensor if 'noop_with_empty_axes' is false, else act as an Identity\n",
      " |              op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1]\n",
      " |              where r = rank(data).\n",
      " |      \n",
      " |          keepdims: Keep the reduced dimension or not, default 1 means keep reduced\n",
      " |              dimension.\n",
      " |      \n",
      " |          noop_with_empty_axes: Defines behavior if 'axes' is empty. Default behavior\n",
      " |              with 'false' is to reduce all axes. When axes is empty and this\n",
      " |              attribute is set to true, input tensor will not be reduced,and the\n",
      " |              output tensor would be equivalent to input tensor.\n",
      " |  \n",
      " |  Sigmoid(self, X: 'T_Sigmoid') -> 'T_Sigmoid'\n",
      " |      [üåê Sigmoid(13)](https://onnx.ai/onnx/operators/onnx__Sigmoid.html#sigmoid-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Sigmoid takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\n",
      " |      tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  Sign(self, input: 'T_Sign') -> 'T_Sign'\n",
      " |      [üåê Sign(13)](https://onnx.ai/onnx/operators/onnx__Sign.html#sign-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculate the sign of the given input tensor element-wise.\n",
      " |      If input > 0, output 1. if input < 0, output -1. if input == 0, output 0.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  Size(self, data: 'T_Size') -> 'T1_Size'\n",
      " |      [üåê Size(13)](https://onnx.ai/onnx/operators/onnx__Size.html#size-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Takes a tensor as input and outputs a int64 scalar that equals to the total number of elements of the input tensor.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (non-differentiable) An input tensor.\n",
      " |  \n",
      " |  Slice(self, data: 'T_Slice', starts: 'Tind_Slice', ends: 'Tind_Slice', axes: 'Optional[Tind_Slice]' = None, steps: 'Optional[Tind_Slice]' = None) -> 'T_Slice'\n",
      " |      [üåê Slice(13)](https://onnx.ai/onnx/operators/onnx__Slice.html#slice-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Produces a slice of the input tensor along multiple axes. Similar to numpy:\n",
      " |      https://numpy.org/doc/stable/user/basics.indexing.html?highlight=slice#slicing-and-striding\n",
      " |      \n",
      " |      Slice uses the `starts`, `ends`, `axes` and `steps` inputs to select a sub-tensor\n",
      " |      of its input `data` tensor.\n",
      " |      \n",
      " |      An effective `start[i]`, `end[i]`, and `step[i]` must be computed for each `i`\n",
      " |      in `[0, ... r-1]` where `r = rank(input)` as follows:\n",
      " |      \n",
      " |      If `axes` are omitted, they are set to `[0, ..., r-1]`.\n",
      " |      If `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\n",
      " |      \n",
      " |      The effective values are initialized as `start[i] = 0`, `end[i] = dims[i]` where\n",
      " |      `dims` are the dimensions of `input` and `step[i] = `1.\n",
      " |      \n",
      " |      All negative elements of `axes` are made non-negatve by adding `r` to them, where\n",
      " |      `r =rank(input)`.\n",
      " |      \n",
      " |      All negative values in `starts[i]` and `ends[i]` have `dims[axes[i]]` added to them,\n",
      " |      where `dims` are the dimensions of `input`. Then `start[axes[i]]` is the adjusted\n",
      " |      `starts[i]` is clamped into the range `[0, dims[axes[i]]]` for positive stepping\n",
      " |      and `[0, dims[axes[i]]-1]` for negative stepping.\n",
      " |      \n",
      " |      The clamping for the adjusted `ends[i]` depends on the sign of `steps[i]` and must\n",
      " |      accommodate copying 0 through `dims[axes[i]]` elements, so for positive stepping\n",
      " |      `end[axes[i]]` is clamped to `[0, dims[axes[i]]]`, while for negative stepping it\n",
      " |      is clamped to `[-1, dims[axes[i]]-1]`.\n",
      " |      \n",
      " |      Finally, `step[axes[i]] = steps[i]`.\n",
      " |      \n",
      " |      For slicing to the end of a dimension with unknown size, it is recommended to pass\n",
      " |      in `INT_MAX` when slicing forward and 'INT_MIN' when slicing backward.\n",
      " |      \n",
      " |      Example 1:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1, 2, 3, 4],\n",
      " |              [5, 6, 7, 8],\n",
      " |          ]\n",
      " |          axes = [0, 1]\n",
      " |          starts = [1, 0]\n",
      " |          ends = [2, 3]\n",
      " |          steps = [1, 2]\n",
      " |          result = [\n",
      " |              [5, 7],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          data = [\n",
      " |              [1, 2, 3, 4],\n",
      " |              [5, 6, 7, 8],\n",
      " |          ]\n",
      " |          starts = [0, 1]\n",
      " |          ends = [-1, 1000]\n",
      " |          result = [\n",
      " |              [2, 3, 4],\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensor of data to extract slices from.\n",
      " |      \n",
      " |          starts: (non-differentiable) 1-D tensor of starting indices of corresponding\n",
      " |              axis in `axes`\n",
      " |      \n",
      " |          ends: (non-differentiable) 1-D tensor of ending indices (exclusive) of\n",
      " |              corresponding axis in `axes`\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) 1-D tensor of axes that `starts` and\n",
      " |              `ends` apply to. Negative value means counting dimensions from the back.\n",
      " |              Accepted range is [-r, r-1] where r = rank(data). Behavior is undefined\n",
      " |              if an axis is repeated.\n",
      " |      \n",
      " |          steps: (optional, non-differentiable) 1-D tensor of slice step of\n",
      " |              corresponding axis in `axes`. Negative value means slicing backward.\n",
      " |              'steps' cannot be 0. Defaults to 1s.\n",
      " |  \n",
      " |  Softmax(self, input: 'T_Softmax', *, axis: 'int' = -1) -> 'T_Softmax'\n",
      " |      [üåê Softmax(13)](https://onnx.ai/onnx/operators/onnx__Softmax.html#softmax-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The operator computes the normalized exponential values for the given input:\n",
      " |      \n",
      " |       Softmax(input, axis) = Exp(input) / ReduceSum(Exp(input), axis=axis, keepdims=1)\n",
      " |      \n",
      " |      The \"axis\" attribute indicates the dimension along which Softmax\n",
      " |      will be performed. The output tensor has the same shape\n",
      " |      and contains the Softmax values of the corresponding input.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The input tensor of rank >= axis.\n",
      " |      \n",
      " |          axis:\n",
      " |      Describes the dimension Softmax will be performed on.\n",
      " |      Negative value\n",
      " |              means counting dimensions\n",
      " |      from the back. Accepted range is [-r, r-1]\n",
      " |              where r = rank(input).\n",
      " |  \n",
      " |  SoftmaxCrossEntropyLoss(self, scores: 'T_SoftmaxCrossEntropyLoss', labels: 'Tind_SoftmaxCrossEntropyLoss', weights: 'Optional[T_SoftmaxCrossEntropyLoss]' = None, *, ignore_index: 'Optional[int]' = None, reduction: 'str' = 'mean') -> 'Tuple[T_SoftmaxCrossEntropyLoss, T_SoftmaxCrossEntropyLoss]'\n",
      " |      [üåê SoftmaxCrossEntropyLoss(13)](https://onnx.ai/onnx/operators/onnx__SoftmaxCrossEntropyLoss.html#softmaxcrossentropyloss-13 \"Online Documentation\")\n",
      " |      \n",
      " |      Loss function that measures the softmax cross entropy\n",
      " |      between 'scores' and 'labels'.\n",
      " |      This operator first computes a loss tensor whose shape is identical to the labels input.\n",
      " |      If the input is 2-D with shape (N, C), the loss tensor may be a N-element vector L = (l_1, l_2, ..., l_N).\n",
      " |      If the input is N-D tensor with shape (N, C, D1, D2, ..., Dk),\n",
      " |      the loss tensor L may have (N, D1, D2, ..., Dk) as its shape and L[i,][j_1][j_2]...[j_k] denotes a scalar element in L.\n",
      " |      After L is available, this operator can optionally do a reduction operator.\n",
      " |      \n",
      " |      * shape(scores): (N, C) where C is the number of classes, or (N, C, D1, D2,..., Dk),\n",
      " |        with K >= 1 in case of K-dimensional loss.\n",
      " |      * shape(labels): (N) where each value is 0 <= labels[i] <= C-1, or (N, D1, D2,..., Dk),\n",
      " |        with K >= 1 in case of K-dimensional loss.\n",
      " |      \n",
      " |      The loss for one sample, l_i, can caculated as follows:\n",
      " |      ::\n",
      " |      \n",
      " |          l[i][d1][d2]...[dk] = -y[i][c][d1][d2]..[dk], where i is the index of classes.\n",
      " |      \n",
      " |      \n",
      " |      or\n",
      " |      ::\n",
      " |      \n",
      " |          l[i][d1][d2]...[dk] = -y[i][c][d1][d2]..[dk] * weights[c], if 'weights' is provided.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      loss is zero for the case when label-value equals ignore_index.\n",
      " |      ::\n",
      " |      \n",
      " |          l[i][d1][d2]...[dk]  = 0, when labels[n][d1][d2]...[dk] = ignore_index\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      where:\n",
      " |      ::\n",
      " |      \n",
      " |          p = Softmax(scores)\n",
      " |          y = Log(p)\n",
      " |          c = labels[i][d1][d2]...[dk]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Finally, L is optionally reduced:\n",
      " |      \n",
      " |      * If reduction = 'none', the output is L with shape (N, D1, D2, ..., Dk).\n",
      " |      * If reduction = 'sum', the output is scalar: Sum(L).\n",
      " |      * If reduction = 'mean', the output is scalar: ReduceMean(L), or if weight is provided: `ReduceSum(L) / ReduceSum(W)`,\n",
      " |        where tensor W is of shape `(N, D1, D2, ..., Dk)` and `W[n][d1][d2]...[dk] = weights[labels[i][d1][d2]...[dk]]`.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          scores: (differentiable) The predicted outputs with shape [batch_size,\n",
      " |              class_size], or [batch_size, class_size, D1, D2 , ..., Dk], where K is\n",
      " |              the number of dimensions.\n",
      " |      \n",
      " |          labels: (non-differentiable) The ground truth output tensor, with shape\n",
      " |              [batch_size], or [batch_size, D1, D2, ..., Dk], where K is the number of\n",
      " |              dimensions. Labels element value shall be in range of [0, C). If\n",
      " |              ignore_index is specified, it may have a value outside [0, C) and the\n",
      " |              label values should either be in the range [0, C) or have the value\n",
      " |              ignore_index.\n",
      " |      \n",
      " |          weights: (optional, non-differentiable) A manual rescaling weight given to\n",
      " |              each class. If given, it has to be a 1D Tensor assigning weight to each\n",
      " |              of the classes. Otherwise, it is treated as if having all ones.\n",
      " |      \n",
      " |          ignore_index: Specifies a target value that is ignored and does not\n",
      " |              contribute to the input gradient. It's an optional value.\n",
      " |      \n",
      " |          reduction: Type of reduction to apply to loss: none, sum, mean(default).\n",
      " |              'none': no reduction will be applied, 'sum': the output will be summed.\n",
      " |              'mean': the sum of the output will be divided by the number of elements\n",
      " |              in the output.\n",
      " |  \n",
      " |  SpaceToDepth(self, input: 'T_SpaceToDepth', *, blocksize: 'int') -> 'T_SpaceToDepth'\n",
      " |      [üåê SpaceToDepth(13)](https://onnx.ai/onnx/operators/onnx__SpaceToDepth.html#spacetodepth-13 \"Online Documentation\")\n",
      " |      \n",
      " |      SpaceToDepth rearranges blocks of spatial data into depth. More specifically,\n",
      " |      this op outputs a copy of the input tensor where values from the height and width dimensions\n",
      " |      are moved to the depth dimension.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of [N,C,H,W], where N is the batch\n",
      " |              axis, C is the channel or depth, H is the height and W is the width.\n",
      " |      \n",
      " |          blocksize: Blocks of [blocksize, blocksize] are moved.\n",
      " |  \n",
      " |  Sqrt(self, X: 'T_Sqrt') -> 'T_Sqrt'\n",
      " |      [üåê Sqrt(13)](https://onnx.ai/onnx/operators/onnx__Sqrt.html#sqrt-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Square root takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the square root is, y = x^0.5, is applied to\n",
      " |      the tensor elementwise. If x is negative, then it will return NaN.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  Squeeze(self, data: 'T_Squeeze', axes: 'Optional[INT64]' = None) -> 'T_Squeeze'\n",
      " |      [üåê Squeeze(13)](https://onnx.ai/onnx/operators/onnx__Squeeze.html#squeeze-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Remove single-dimensional entries from the shape of a tensor.\n",
      " |      Takes an input `axes` with a list of axes to squeeze.\n",
      " |      If `axes` is not provided, all the single dimensions will be removed from\n",
      " |      the shape. If an axis is selected with shape entry not equal to one, an error is raised.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Tensors with at least max(dims) dimensions.\n",
      " |      \n",
      " |          axes: (optional, non-differentiable) List of integers indicating the\n",
      " |              dimensions to squeeze. Negative value means counting dimensions from the\n",
      " |              back. Accepted range is [-r, r-1] where r = rank(data).\n",
      " |  \n",
      " |  Sum(self, *data_0: 'T_Sum') -> 'T_Sum'\n",
      " |      [üåê Sum(13)](https://onnx.ai/onnx/operators/onnx__Sum.html#sum-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Element-wise sum of each of the input tensors (with Numpy-style broadcasting support).\n",
      " |      All inputs and outputs must have the same data type.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data_0: (variadic, differentiable) List of tensors for sum.\n",
      " |  \n",
      " |  Tanh(self, input: 'T_Tanh') -> 'T_Tanh'\n",
      " |      [üåê Tanh(13)](https://onnx.ai/onnx/operators/onnx__Tanh.html#tanh-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic tangent of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Tile(self, input: 'T_Tile', repeats: 'T1_Tile') -> 'T_Tile'\n",
      " |      [üåê Tile(13)](https://onnx.ai/onnx/operators/onnx__Tile.html#tile-13 \"Online Documentation\")\n",
      " |      \n",
      " |      Constructs a tensor by tiling a given tensor.\n",
      " |      This is the same as function `tile` in Numpy, but no broadcast.\n",
      " |      For example A = [[1, 2], [3, 4]], B = [1, 2], tile(A, B) = [[1, 2, 1, 2], [3, 4, 3, 4]]\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor of any shape.\n",
      " |      \n",
      " |          repeats: (non-differentiable) 1D int64 tensor of the same length as input's\n",
      " |              dimension number, includes numbers of repeated copies along input's\n",
      " |              dimensions.\n",
      " |  \n",
      " |  Transpose(self, data: 'T_Transpose', *, perm: 'Optional[Sequence[int]]' = None) -> 'T_Transpose'\n",
      " |      [üåê Transpose(13)](https://onnx.ai/onnx/operators/onnx__Transpose.html#transpose-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Transpose the input tensor similar to numpy.transpose. For example, when\n",
      " |      perm=(1, 0, 2), given an input tensor of shape (1, 2, 3), the output shape\n",
      " |      will be (2, 1, 3).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) An input tensor.\n",
      " |      \n",
      " |          perm: A list of integers. By default, reverse the dimensions, otherwise\n",
      " |              permute the axes according to the values given.\n",
      " |  \n",
      " |  Unsqueeze(self, data: 'T_Unsqueeze', axes: 'INT64') -> 'T_Unsqueeze'\n",
      " |      [üåê Unsqueeze(13)](https://onnx.ai/onnx/operators/onnx__Unsqueeze.html#unsqueeze-13 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Insert single-dimensional entries to the shape of an input tensor (`data`).\n",
      " |      Takes one required input `axes` - which contains a list of dimension indices and this operator will insert a dimension of value `1` into the corresponding index of the output tensor (`expanded`).\n",
      " |      \n",
      " |      For example, given an input tensor (`data`) of shape [3, 4, 5], then\n",
      " |      Unsqueeze(data, axes=[0, 4]) outputs a tensor (`expanded`) containing same data as `data` but with shape [1, 3, 4, 5, 1].\n",
      " |      \n",
      " |      The input `axes` should not contain any duplicate entries. It is an error if it contains duplicates.\n",
      " |      The rank of the output tensor (`output_rank`) is the rank of the input tensor (`data`) plus the number of values in `axes`.\n",
      " |      Each value in `axes` should be within the (inclusive) range [-output_rank , output_rank - 1].\n",
      " |      The order of values in `axes` does not matter and can come in any order.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: (differentiable) Original tensor\n",
      " |      \n",
      " |          axes: (non-differentiable) List of integers indicating the dimensions to be\n",
      " |              inserted. Negative value means counting dimensions from the back.\n",
      " |              Accepted range is [-r, r-1] where r = rank(expanded).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset13.Opset13:\n",
      " |  \n",
      " |  T1_Cast = ~T1_Cast\n",
      " |  \n",
      " |  T1_Dropout = ~T1_Dropout\n",
      " |  \n",
      " |  T1_Equal = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_Greater = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_IsNaN = ~T1_IsNaN\n",
      " |  \n",
      " |  T1_Less = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_QuantizeLinear = ~T1_QuantizeLinear\n",
      " |  \n",
      " |  T1_Size = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T1_Tile = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T2_Cast = typing.Union[onnxscript.onnx_types.BFLOAT16, onn...t.onnx_ty...\n",
      " |  \n",
      " |  T2_Dropout = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T2_IsNaN = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T2_QuantizeLinear = ~T2_QuantizeLinear\n",
      " |  \n",
      " |  T_Abs = ~T_Abs\n",
      " |  \n",
      " |  T_ArgMax = ~T_ArgMax\n",
      " |  \n",
      " |  T_ArgMin = ~T_ArgMin\n",
      " |  \n",
      " |  T_Ceil = ~T_Ceil\n",
      " |  \n",
      " |  T_Clip = ~T_Clip\n",
      " |  \n",
      " |  T_Concat = ~T_Concat\n",
      " |  \n",
      " |  T_Constant = typing.Union[onnxscript.onnx_types.BFLOAT16, onn...t.onnx...\n",
      " |  \n",
      " |  T_DepthToSpace = ~T_DepthToSpace\n",
      " |  \n",
      " |  T_DequantizeLinear = ~T_DequantizeLinear\n",
      " |  \n",
      " |  T_Dropout = ~T_Dropout\n",
      " |  \n",
      " |  T_Equal = ~T_Equal\n",
      " |  \n",
      " |  T_Erf = ~T_Erf\n",
      " |  \n",
      " |  T_Exp = ~T_Exp\n",
      " |  \n",
      " |  T_Expand = ~T_Expand\n",
      " |  \n",
      " |  T_Flatten = ~T_Flatten\n",
      " |  \n",
      " |  T_Floor = ~T_Floor\n",
      " |  \n",
      " |  T_Gather = ~T_Gather\n",
      " |  \n",
      " |  T_GatherElements = ~T_GatherElements\n",
      " |  \n",
      " |  T_GatherND = ~T_GatherND\n",
      " |  \n",
      " |  T_Gemm = ~T_Gemm\n",
      " |  \n",
      " |  T_Greater = ~T_Greater\n",
      " |  \n",
      " |  T_Hardmax = ~T_Hardmax\n",
      " |  \n",
      " |  T_Identity = ~T_Identity\n",
      " |  \n",
      " |  T_LRN = ~T_LRN\n",
      " |  \n",
      " |  T_Less = ~T_Less\n",
      " |  \n",
      " |  T_Log = ~T_Log\n",
      " |  \n",
      " |  T_LogSoftmax = ~T_LogSoftmax\n",
      " |  \n",
      " |  T_MatMul = ~T_MatMul\n",
      " |  \n",
      " |  T_Max = ~T_Max\n",
      " |  \n",
      " |  T_Mean = ~T_Mean\n",
      " |  \n",
      " |  T_MeanVarianceNormalization = ~T_MeanVarianceNormalization\n",
      " |  \n",
      " |  T_Min = ~T_Min\n",
      " |  \n",
      " |  T_Mod = ~T_Mod\n",
      " |  \n",
      " |  T_Neg = ~T_Neg\n",
      " |  \n",
      " |  T_NegativeLogLikelihoodLoss = ~T_NegativeLogLikelihoodLoss\n",
      " |  \n",
      " |  T_NonZero = ~T_NonZero\n",
      " |  \n",
      " |  T_Reciprocal = ~T_Reciprocal\n",
      " |  \n",
      " |  T_ReduceSum = ~T_ReduceSum\n",
      " |  \n",
      " |  T_Sigmoid = ~T_Sigmoid\n",
      " |  \n",
      " |  T_Sign = ~T_Sign\n",
      " |  \n",
      " |  T_Size = ~T_Size\n",
      " |  \n",
      " |  T_Slice = ~T_Slice\n",
      " |  \n",
      " |  T_Softmax = ~T_Softmax\n",
      " |  \n",
      " |  T_SoftmaxCrossEntropyLoss = ~T_SoftmaxCrossEntropyLoss\n",
      " |  \n",
      " |  T_SpaceToDepth = ~T_SpaceToDepth\n",
      " |  \n",
      " |  T_Sqrt = ~T_Sqrt\n",
      " |  \n",
      " |  T_Squeeze = ~T_Squeeze\n",
      " |  \n",
      " |  T_Sum = ~T_Sum\n",
      " |  \n",
      " |  T_Tanh = ~T_Tanh\n",
      " |  \n",
      " |  T_Tile = ~T_Tile\n",
      " |  \n",
      " |  T_Transpose = ~T_Transpose\n",
      " |  \n",
      " |  T_Unsqueeze = ~T_Unsqueeze\n",
      " |  \n",
      " |  Tind_Gather = ~Tind_Gather\n",
      " |  \n",
      " |  Tind_GatherElements = ~Tind_GatherElements\n",
      " |  \n",
      " |  Tind_NegativeLogLikelihoodLoss = ~Tind_NegativeLogLikelihoodLoss\n",
      " |  \n",
      " |  Tind_Slice = ~Tind_Slice\n",
      " |  \n",
      " |  Tind_SoftmaxCrossEntropyLoss = ~Tind_SoftmaxCrossEntropyLoss\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset12.Opset12:\n",
      " |  \n",
      " |  Celu(self, X: 'T_Celu', *, alpha: 'float' = 1.0) -> 'T_Celu'\n",
      " |      [üåê Celu(12)](https://onnx.ai/onnx/operators/onnx__Celu.html#celu-12 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Continuously Differentiable Exponential Linear Units:\n",
      " |      Perform the linear unit element-wise on the input tensor X\n",
      " |      using formula:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          max(0,x) + min(0,alpha*(exp(x/alpha)-1))\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: The Alpha value in Celu formula which control the shape of the unit.\n",
      " |              The default value is 1.0.\n",
      " |  \n",
      " |  Einsum(self, *Inputs: 'T_Einsum', equation: 'str') -> 'T_Einsum'\n",
      " |      [üåê Einsum(12)](https://onnx.ai/onnx/operators/onnx__Einsum.html#einsum-12 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      An einsum of the form `term1, term2 -> output-term` produces an output tensor using the following equation\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          output[output-term] = reduce-sum( input1[term1] * input2[term] )\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      where the reduce-sum performs a summation over all the indices occurring in the input terms (term1, term2)\n",
      " |      that do not occur in the output-term.\n",
      " |      \n",
      " |      The Einsum operator evaluates algebraic tensor operations on a sequence of tensors, using the Einstein summation\n",
      " |      convention. The equation string contains a comma-separated sequence of lower case letters. Each term corresponds to\n",
      " |      an operand tensor, and the characters within the terms correspond to operands dimensions.\n",
      " |      \n",
      " |      This sequence may be followed by \"->\" to separate the left and right hand side of the equation.\n",
      " |      If the equation contains \"->\" followed by the right-hand side, the explicit (not classical) form of the Einstein\n",
      " |      summation is performed, and the right-hand side indices indicate output tensor dimensions. In other cases,\n",
      " |      output indices are (implicitly) set to the alphabetically sorted sequence of indices appearing exactly once in the\n",
      " |      equation.\n",
      " |      \n",
      " |      When a dimension character is repeated in the left-hand side, it represents summation along the dimension.\n",
      " |      \n",
      " |      The equation may contain ellipsis (\"...\") to enable broadcasting. Ellipsis must indicate a fixed number of dimensions.\n",
      " |      Specifically, every occurrence of ellipsis in the equation must represent the same number of dimensions.\n",
      " |      The right-hand side may contain exactly one ellipsis. In implicit mode, the ellipsis dimensions are set to the\n",
      " |      beginning of the output. The equation string may contain space (U+0020) character.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          Inputs: (variadic, differentiable) Operands\n",
      " |      \n",
      " |          equation: Einsum expression string.\n",
      " |  \n",
      " |  MaxPool(self, X: 'T_MaxPool', *, auto_pad: 'str' = 'NOTSET', ceil_mode: 'int' = 0, dilations: 'Optional[Sequence[int]]' = None, kernel_shape: 'Sequence[int]', pads: 'Optional[Sequence[int]]' = None, storage_order: 'int' = 0, strides: 'Optional[Sequence[int]]' = None) -> 'Tuple[T_MaxPool, I_MaxPool]'\n",
      " |      [üåê MaxPool(12)](https://onnx.ai/onnx/operators/onnx__MaxPool.html#maxpool-12 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       MaxPool consumes an input tensor X and applies max pooling across\n",
      " |       the tensor according to kernel sizes, stride sizes, and pad lengths.\n",
      " |       max pooling consisting of computing the max on all values of a\n",
      " |       subset of the input tensor according to the kernel size and downsampling the\n",
      " |       data into the output tensor Y for further processing. The output spatial shape will be following:\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       or\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       if ceil_mode is enabled `pad_shape[i]` is the sum of pads along axis `i`.\n",
      " |      \n",
      " |       `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n",
      " |       ```\n",
      " |       VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n",
      " |       SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n",
      " |       ```\n",
      " |       And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n",
      " |       ```\n",
      " |       pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n",
      " |       ```\n",
      " |       The output of each pooling window is maximum number of elements exclude pad.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size. Optionally, if dimension\n",
      " |              denotation is in effect, the operation expects the input data tensor to\n",
      " |              arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL,\n",
      " |              DATA_FEATURE, DATA_FEATURE ...].\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          ceil_mode: Whether to use ceil or floor (default) to compute the output\n",
      " |              shape.\n",
      " |      \n",
      " |          dilations: Dilation value along each spatial axis of filter. If not present,\n",
      " |              the dilation defaults to 1 along each spatial axis.\n",
      " |      \n",
      " |          kernel_shape: The size of the kernel along each axis.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          storage_order: The storage order of the tensor. 0 is row major, and 1 is\n",
      " |              column major. This attribute is used only to convert an n-tuple index\n",
      " |              value into a single integer value for producing the second output.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset12.Opset12:\n",
      " |  \n",
      " |  I_MaxPool = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T_Celu = <class 'onnxscript.onnx_types.FLOAT'>\n",
      " |  \n",
      " |  T_Einsum = ~T_Einsum\n",
      " |  \n",
      " |  T_MaxPool = ~T_MaxPool\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset11.Opset11:\n",
      " |  \n",
      " |  AveragePool(self, X: 'T_AveragePool', *, auto_pad: 'str' = 'NOTSET', ceil_mode: 'int' = 0, count_include_pad: 'int' = 0, kernel_shape: 'Sequence[int]', pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_AveragePool'\n",
      " |      [üåê AveragePool(11)](https://onnx.ai/onnx/operators/onnx__AveragePool.html#averagepool-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       AveragePool consumes an input tensor X and applies average pooling across\n",
      " |       the tensor according to kernel sizes, stride sizes, and pad lengths.\n",
      " |       average pooling consisting of computing the average on all values of a\n",
      " |       subset of the input tensor according to the kernel size and downsampling the\n",
      " |       data into the output tensor Y for further processing. The output spatial shape will be following:\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       or\n",
      " |       ```\n",
      " |       output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n",
      " |       ```\n",
      " |       if ceil_mode is enabled\n",
      " |      \n",
      " |       ```\n",
      " |       * pad_shape[i] is sum of pads along axis i\n",
      " |       ```\n",
      " |      \n",
      " |       `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n",
      " |       ```\n",
      " |       VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n",
      " |       SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n",
      " |       ```\n",
      " |       And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n",
      " |       ```\n",
      " |       pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n",
      " |       ```\n",
      " |       The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size. Optionally, if dimension\n",
      " |              denotation is in effect, the operation expects the input data tensor to\n",
      " |              arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL,\n",
      " |              DATA_FEATURE, DATA_FEATURE ...].\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          ceil_mode: Whether to use ceil or floor (default) to compute the output\n",
      " |              shape.\n",
      " |      \n",
      " |          count_include_pad: Whether include pad pixels when calculating values for\n",
      " |              the edges. Default is 0, doesn't count include pad.\n",
      " |      \n",
      " |          kernel_shape: The size of the kernel along each axis.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  BitShift(self, X: 'T_BitShift', Y: 'T_BitShift', *, direction: 'str') -> 'T_BitShift'\n",
      " |      [üåê BitShift(11)](https://onnx.ai/onnx/operators/onnx__BitShift.html#bitshift-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Bitwise shift operator performs element-wise operation. For each input element, if the\n",
      " |      attribute \"direction\" is \"RIGHT\", this operator moves its binary representation toward\n",
      " |      the right side so that the input value is effectively decreased. If the attribute \"direction\"\n",
      " |      is \"LEFT\", bits of binary representation moves toward the left side, which results the\n",
      " |      increase of its actual value. The input X is the tensor to be shifted and another input\n",
      " |      Y specifies the amounts of shifting. For example, if \"direction\" is \"Right\", X is [1, 4],\n",
      " |      and S is [1, 1], the corresponding output Z would be [0, 2]. If \"direction\" is \"LEFT\" with\n",
      " |      X=[1, 2] and S=[1, 2], the corresponding output Y would be [2, 8].\n",
      " |      \n",
      " |      Because this operator supports Numpy-style broadcasting, X's and Y's shapes are\n",
      " |      not necessarily identical.\n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) First operand, input to be shifted.\n",
      " |      \n",
      " |          Y: (non-differentiable) Second operand, amounts of shift.\n",
      " |      \n",
      " |          direction: Direction of moving bits. It can be either \"RIGHT\" (for right\n",
      " |              shift) or \"LEFT\" (for left shift).\n",
      " |  \n",
      " |  Compress(self, input: 'T_Compress', condition: 'T1_Compress', *, axis: 'Optional[int]' = None) -> 'T_Compress'\n",
      " |      [üåê Compress(11)](https://onnx.ai/onnx/operators/onnx__Compress.html#compress-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |          Selects slices from an input tensor along a given axis where condition evaluates to True for each axis index.\n",
      " |          In case axis is not provided, input is flattened before elements are selected.\n",
      " |          Compress behaves like numpy.compress: https://docs.scipy.org/doc/numpy/reference/generated/numpy.compress.html\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Tensor of rank r >= 1.\n",
      " |      \n",
      " |          condition: (non-differentiable) Rank 1 tensor of booleans to indicate which\n",
      " |              slices or data elements to be selected. Its length can be less than the\n",
      " |              input length along the axis or the flattened input size if axis is not\n",
      " |              specified. In such cases data slices or elements exceeding the condition\n",
      " |              length are discarded.\n",
      " |      \n",
      " |          axis: (Optional) Axis along which to take slices. If not specified, input is\n",
      " |              flattened before elements being selected. Negative value means counting\n",
      " |              dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |  \n",
      " |  ConcatFromSequence(self, input_sequence: 'S_ConcatFromSequence', *, axis: 'int', new_axis: 'int' = 0) -> 'T_ConcatFromSequence'\n",
      " |      [üåê ConcatFromSequence(11)](https://onnx.ai/onnx/operators/onnx__ConcatFromSequence.html#concatfromsequence-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Concatenate a sequence of tensors into a single tensor.\n",
      " |      All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.\n",
      " |      By default 'new_axis' is 0, the behavior is similar to numpy.concatenate.\n",
      " |      When 'new_axis' is 1, the behavior is similar to numpy.stack.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Sequence of tensors for concatenation\n",
      " |      \n",
      " |          axis: Which axis to concat on. Accepted range in `[-r, r - 1]`, where `r` is\n",
      " |              the rank of input tensors. When `new_axis` is 1, accepted range is `[-r\n",
      " |              - 1, r]`.\n",
      " |      \n",
      " |          new_axis: Insert and concatenate on a new axis or not, default 0 means do\n",
      " |              not insert new axis.\n",
      " |  \n",
      " |  Conv(self, X: 'T_Conv', W: 'T_Conv', B: 'Optional[T_Conv]' = None, *, auto_pad: 'str' = 'NOTSET', dilations: 'Optional[Sequence[int]]' = None, group: 'int' = 1, kernel_shape: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_Conv'\n",
      " |      [üåê Conv(11)](https://onnx.ai/onnx/operators/onnx__Conv.html#conv-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The convolution operator consumes an input tensor and a filter, and\n",
      " |      computes the output.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from previous layer; has size (N x C x\n",
      " |              H x W), where N is the batch size, C is the number of channels, and H\n",
      " |              and W are the height and width. Note that this is for the 2D image.\n",
      " |              Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if\n",
      " |              dimension denotation is in effect, the operation expects input data\n",
      " |              tensor to arrive with the dimension denotation of [DATA_BATCH,\n",
      " |              DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor that will be used in the convolutions;\n",
      " |              has size (M x C/group x kH x kW), where C is the number of channels, and\n",
      " |              kH and kW are the height and width of the kernel, and M is the number of\n",
      " |              feature maps. For more than 2 dimensions, the kernel shape will be (M x\n",
      " |              C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension\n",
      " |              of the kernel. Optionally, if dimension denotation is in effect, the\n",
      " |              operation expects the weight tensor to arrive with the dimension\n",
      " |              denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL,\n",
      " |              FILTER_SPATIAL ...]. Assuming zero based indices for the shape array,\n",
      " |              X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in\n",
      " |              other words FILTER_IN_CHANNEL multiplied by the number of groups should\n",
      " |              be equal to DATA_CHANNEL and the number of feature maps M should be a\n",
      " |              multiple of the number of groups G.\n",
      " |      \n",
      " |          B: (optional, differentiable) Optional 1D bias to be added to the\n",
      " |              convolution, has size of M.\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults is 1 along each spatial axis.\n",
      " |      \n",
      " |          group: number of groups input channels and output channels are divided into.\n",
      " |      \n",
      " |          kernel_shape: The shape of the convolution kernel. If not present, should be\n",
      " |              inferred from input W.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              is 1 along each spatial axis.\n",
      " |  \n",
      " |  ConvTranspose(self, X: 'T_ConvTranspose', W: 'T_ConvTranspose', B: 'Optional[T_ConvTranspose]' = None, *, auto_pad: 'str' = 'NOTSET', dilations: 'Optional[Sequence[int]]' = None, group: 'int' = 1, kernel_shape: 'Optional[Sequence[int]]' = None, output_padding: 'Optional[Sequence[int]]' = None, output_shape: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T_ConvTranspose'\n",
      " |      [üåê ConvTranspose(11)](https://onnx.ai/onnx/operators/onnx__ConvTranspose.html#convtranspose-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The convolution transpose operator consumes an input tensor and a filter,\n",
      " |      and computes the output.\n",
      " |      \n",
      " |      If the pads parameter is provided the shape of the output is calculated via the following equation:\n",
      " |      \n",
      " |        output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]\n",
      " |      \n",
      " |      output_shape can also be explicitly specified in which case pads values are auto generated using these equations:\n",
      " |      \n",
      " |        total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]\n",
      " |        If (auto_pads == SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)\n",
      " |        Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from previous layer; has size (N x C x\n",
      " |              H x W), where N is the batch size, C is the number of channels, and H\n",
      " |              and W are the height and width. Note that this is for the 2D image.\n",
      " |              Otherwise the size is (N x C x D1 x D2 ... x Dn)\n",
      " |      \n",
      " |          W: (differentiable) The weight tensor that will be used in the convolutions;\n",
      " |              has size (C x M/group x kH x kW), where C is the number of channels, and\n",
      " |              kH and kW are the height and width of the kernel, and M is the number of\n",
      " |              feature maps. For more than 2 dimensions, the weight shape will be (C x\n",
      " |              M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the\n",
      " |              dimension of the kernel. The number of channels in the output should be\n",
      " |              equal to W.shape[1] * group (assuming zero based indices of the shape\n",
      " |              array)\n",
      " |      \n",
      " |          B: (optional, differentiable) Optional 1D bias to be added to the\n",
      " |              convolution, has size of M.\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              input_shape[i] * strides[i]` for each axis `i`. The padding is split\n",
      " |              between the two sides equally or almost equally (depending on whether it\n",
      " |              is even or odd). In case the padding is an odd number, the extra padding\n",
      " |              is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults to 1 along each spatial axis.\n",
      " |      \n",
      " |          group: number of groups input channels and output channels are divided into.\n",
      " |      \n",
      " |          kernel_shape: The shape of the convolution kernel. If not present, should be\n",
      " |              inferred from input W.\n",
      " |      \n",
      " |          output_padding: Additional elements added to the side with higher coordinate\n",
      " |              indices in the output. Each padding value in \"output_padding\" must be\n",
      " |              less than the corresponding stride/dilation dimension. By default, this\n",
      " |              attribute is a zero vector. Note that this attribute doesn't directly\n",
      " |              affect the computed output values. It only controls the selection of the\n",
      " |              computed values, so changing this attribute only adds or removes output\n",
      " |              elements. If \"output_shape\" is explicitly provided, \"output_padding\"\n",
      " |              does not contribute additional size to \"output_shape\" but participates\n",
      " |              in the computation of the needed padding amount. This is also called\n",
      " |              adjs or adjustment in some frameworks.\n",
      " |      \n",
      " |          output_shape: The shape of the output can be explicitly set which will cause\n",
      " |              pads values to be auto generated. If output_shape is specified pads\n",
      " |              values are ignored. See doc for details for equations to generate pads\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  Det(self, X: 'T_Det') -> 'T_Det'\n",
      " |      [üåê Det(11)](https://onnx.ai/onnx/operators/onnx__Det.html#det-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Det calculates determinant of a square matrix or batches of square matrices.\n",
      " |      Det takes one input tensor of shape `[*, M, M]`, where `*` is zero or more batch dimensions,\n",
      " |      and the inner-most 2 dimensions form square matrices.\n",
      " |      The output is a tensor of shape `[*]`, containing the determinants of all input submatrices.\n",
      " |      e.g., When the input is 2-D, the output is a scalar(shape is empty: `[]`).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |  \n",
      " |  DynamicQuantizeLinear(self, x: 'T1_DynamicQuantizeLinear') -> 'Tuple[T2_DynamicQuantizeLinear, FLOAT, T2_DynamicQuantizeLinear]'\n",
      " |      [üåê DynamicQuantizeLinear(11)](https://onnx.ai/onnx/operators/onnx__DynamicQuantizeLinear.html#dynamicquantizelinear-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      A Function to fuse calculation for Scale, Zero Point and FP32->8Bit convertion of FP32 Input data.\n",
      " |      Outputs Scale, ZeroPoint and Quantized Input for a given FP32 Input.\n",
      " |      Scale is calculated as:\n",
      " |      ::\n",
      " |      \n",
      " |          y_scale = (max(x) - min(x))/(qmax - qmin)\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      * where qmax and qmin are max and min values for quantization range .i.e [0, 255] in case of uint8\n",
      " |      * data range is adjusted to include 0.\n",
      " |      \n",
      " |      Zero point is calculated as:\n",
      " |      ::\n",
      " |      \n",
      " |          intermediate_zero_point = qmin - min(x)/y_scale\n",
      " |          y_zero_point = cast(round(saturate(itermediate_zero_point)))\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      * where qmax and qmin are max and min values for quantization range .i.e [0, 255] in case of uint8\n",
      " |      * for saturation, it saturates to [0, 255] if it's uint8, or [-127, 127] if it's int8. Right now only uint8 is supported.\n",
      " |      * rounding to nearest ties to even.\n",
      " |      \n",
      " |      Data quantization formula is:\n",
      " |      ::\n",
      " |      \n",
      " |          y = saturate (round (x / y_scale) + y_zero_point)\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      * for saturation, it saturates to [0, 255] if it's uint8, or [-127, 127] if it's int8. Right now only uint8 is supported.\n",
      " |      * rounding to nearest ties to even.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input tensor\n",
      " |  \n",
      " |  MaxUnpool(self, X: 'T1_MaxUnpool', I: 'T2_MaxUnpool', output_shape: 'Optional[T2_MaxUnpool]' = None, *, kernel_shape: 'Sequence[int]', pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T1_MaxUnpool'\n",
      " |      [üåê MaxUnpool(11)](https://onnx.ai/onnx/operators/onnx__MaxUnpool.html#maxunpool-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      MaxUnpool essentially computes the partial inverse of the MaxPool op.\n",
      " |       The input information to this op is typically the output information from a MaxPool op. The first\n",
      " |       input tensor X is the tensor that needs to be unpooled, which is typically the pooled tensor (first output)\n",
      " |       from MaxPool. The second input tensor, I, contains the indices to the (locally maximal) elements corrsponding\n",
      " |       to the elements in the first input tensor X. Input tensor I is typically the second output of the MaxPool op.\n",
      " |       The third (optional) input is a tensor that specifies the output size of the unpooling operation.\n",
      " |      \n",
      " |      MaxUnpool is intended to do 'partial' inverse of the MaxPool op. 'Partial' because all the non-maximal\n",
      " |       values from the original input to MaxPool are set to zero in the output of the MaxUnpool op. Pooling\n",
      " |       the result of an unpooling operation should give back the original input to the unpooling op.\n",
      " |      \n",
      " |      MaxUnpool can produce the same output size for several input sizes, which makes unpooling op ambiguous.\n",
      " |       The third input argument, output_size, is meant to disambiguate the op and produce output tensor of\n",
      " |       known/predictable size.\n",
      " |      \n",
      " |      In addition to the inputs, MaxUnpool takes three attributes, namely kernel_shape, strides, and pads,\n",
      " |       which define the exact unpooling op. The attributes typically have the same values as the corrsponding\n",
      " |       pooling op that the unpooling op is trying to invert.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor that has to be unpooled. This tensor\n",
      " |              is typically the first output of the MaxPool op.Dimensions for image\n",
      " |              case are (N x C x H x W), where N is the batch size, C is the number of\n",
      " |              channels, and H and W are the height and the width of the data. For\n",
      " |              non-image case, the dimensions are in the form of (N x C x D1 x D2 ...\n",
      " |              Dn), where N is the batch size. Optionally, if dimension denotation is\n",
      " |              in effect, the operation expects the input data tensor to arrive with\n",
      " |              the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE,\n",
      " |              DATA_FEATURE ...].\n",
      " |      \n",
      " |          I: (non-differentiable) Input data tensor containing the indices\n",
      " |              corresponding to elements in the first input tensor X.This tensor is\n",
      " |              typically the second output of the MaxPool op.Dimensions must be the\n",
      " |              same as input tensor X. The indices are linear, i.e. computed\n",
      " |              considering the tensor as flattened 1-D tensor, assuming row-major\n",
      " |              storage. Also, the linear indices should not consider padding. So the\n",
      " |              values in indices are in the range [0, N x C x D1 x ... x Dn).\n",
      " |      \n",
      " |          output_shape: (optional, non-differentiable) The shape of the output can be\n",
      " |              explicitly set which will cause pads values to be auto generated. If\n",
      " |              'output_shape' is specified, 'pads' values are ignored.\n",
      " |      \n",
      " |          kernel_shape: The size of the kernel along each axis.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0. The value represent the\n",
      " |              number of pixels added to the beginning and end part of the\n",
      " |              corresponding axis. `pads` format should be as follow [x1_begin,\n",
      " |              x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels\n",
      " |              added at the beginning of axis `i` and xi_end, the number of pixels\n",
      " |              added at the end of axis `i`. This attribute cannot be used\n",
      " |              simultaneously with auto_pad attribute. If not present, the padding\n",
      " |              defaults to 0 along start and end of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  NonMaxSuppression(self, boxes: 'FLOAT', scores: 'FLOAT', max_output_boxes_per_class: 'Optional[INT64]' = None, iou_threshold: 'Optional[FLOAT]' = None, score_threshold: 'Optional[FLOAT]' = None, *, center_point_box: 'int' = 0) -> 'INT64'\n",
      " |      [üåê NonMaxSuppression(11)](https://onnx.ai/onnx/operators/onnx__NonMaxSuppression.html#nonmaxsuppression-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Filter out boxes that have high intersection-over-union (IOU) overlap with previously selected boxes.\n",
      " |      Bounding boxes with score less than score_threshold are removed. Bounding box format is indicated by attribute center_point_box.\n",
      " |      Note that this algorithm is agnostic to where the origin is in the coordinate system and more generally is invariant to\n",
      " |      orthogonal transformations and translations of the coordinate system; thus translating or reflections of the coordinate system\n",
      " |      result in the same boxes being selected by the algorithm.\n",
      " |      The selected_indices output is a set of integers indexing into the input collection of bounding boxes representing the selected boxes.\n",
      " |      The bounding box coordinates corresponding to the selected indices can then be obtained using the Gather or GatherND operation.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          boxes: An input tensor with shape [num_batches, spatial_dimension, 4]. The\n",
      " |              single box data format is indicated by center_point_box.\n",
      " |      \n",
      " |          scores: An input tensor with shape [num_batches, num_classes,\n",
      " |              spatial_dimension]\n",
      " |      \n",
      " |          max_output_boxes_per_class: (optional) Integer representing the maximum\n",
      " |              number of boxes to be selected per batch per class. It is a scalar.\n",
      " |              Default to 0, which means no output.\n",
      " |      \n",
      " |          iou_threshold: (optional) Float representing the threshold for deciding\n",
      " |              whether boxes overlap too much with respect to IOU. It is scalar. Value\n",
      " |              range [0, 1]. Default to 0.\n",
      " |      \n",
      " |          score_threshold: (optional) Float representing the threshold for deciding\n",
      " |              when to remove boxes based on score. It is a scalar.\n",
      " |      \n",
      " |          center_point_box: Integer indicate the format of the box data. The default\n",
      " |              is 0. 0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1)\n",
      " |              and (y2, x2) are the coordinates of any diagonal pair of box corners and\n",
      " |              the coordinates can be provided as normalized (i.e., lying in the\n",
      " |              interval [0, 1]) or absolute. Mostly used for TF models. 1 - the box\n",
      " |              data is supplied as [x_center, y_center, width, height]. Mostly used for\n",
      " |              Pytorch models.\n",
      " |  \n",
      " |  OneHot(self, indices: 'T1_OneHot', depth: 'T2_OneHot', values: 'T3_OneHot', *, axis: 'int' = -1) -> 'T3_OneHot'\n",
      " |      [üåê OneHot(11)](https://onnx.ai/onnx/operators/onnx__OneHot.html#onehot-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |          Produces a one-hot tensor based on inputs.\n",
      " |          The locations represented by the index values in the 'indices' input tensor will have 'on_value'\n",
      " |          and the other locations will have 'off_value' in the output tensor, where 'on_value' and 'off_value'\n",
      " |          are specified as part of required input argument 'values', which is a two-element tensor of format\n",
      " |          [off_value, on_value]. The rank of the output tensor will be one greater than the rank of the\n",
      " |          input tensor. The additional dimension is for one-hot representation. The additional dimension will\n",
      " |          be inserted at the position specified by 'axis'. If 'axis' is not specified then then additional\n",
      " |          dimension will be inserted as the innermost dimension, i.e. axis=-1. The size of the additional\n",
      " |          dimension is specified by required scalar input 'depth'. The type of the output tensor is the same\n",
      " |          as the type of the 'values' input. Any entries in the 'indices' input tensor with values outside\n",
      " |          the range [-depth, depth-1] will result in one-hot representation with all 'off_value' values in the\n",
      " |          output tensor.\n",
      " |      \n",
      " |          when axis = 0:\n",
      " |          output[input[i, j, k], i, j, k] = 1 for all i, j, k and 0 otherwise.\n",
      " |      \n",
      " |          when axis = -1:\n",
      " |          output[i, j, k, input[i, j, k]] = 1 for all i, j, k and 0 otherwise.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          indices: (non-differentiable) Input tensor containing indices. Any entries\n",
      " |              in the 'indices' input tensor with values outside the range [-depth,\n",
      " |              depth-1] will result in one-hot representation with all 'off_value'\n",
      " |              values in the output tensor.In case 'indices' is of non-integer type,\n",
      " |              the values will be casted to int64 before use.\n",
      " |      \n",
      " |          depth: (non-differentiable) Scalar or Rank 1 tensor containing exactly one\n",
      " |              element, specifying the number of classes in one-hot tensor. This is\n",
      " |              also the size of the one-hot dimension (specified by 'axis' attribute)\n",
      " |              added on in the output tensor. The values in the 'indices' input tensor\n",
      " |              are expected to be in the range [-depth, depth-1]. In case 'depth' is of\n",
      " |              non-integer type, it will be casted to int64 before use.\n",
      " |      \n",
      " |          values: (non-differentiable) Rank 1 tensor containing exactly two elements,\n",
      " |              in the format [off_value, on_value], where 'on_value' is the value used\n",
      " |              for filling locations specified in 'indices' input tensor, and\n",
      " |              'off_value' is the value used for filling locations other than those\n",
      " |              specified in 'indices' input tensor.\n",
      " |      \n",
      " |          axis: (Optional) Axis along which one-hot representation in added. Default:\n",
      " |              axis=-1. axis=-1 means that the additional dimension will be inserted as\n",
      " |              the innermost/last dimension in the output tensor. Negative value means\n",
      " |              counting dimensions from the back. Accepted range is [-r-1, r] where r =\n",
      " |              rank(indices).\n",
      " |  \n",
      " |  Range(self, start: 'T_Range', limit: 'T_Range', delta: 'T_Range') -> 'T_Range'\n",
      " |      [üåê Range(11)](https://onnx.ai/onnx/operators/onnx__Range.html#range-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor containing a sequence of numbers that begin at `start` and extends by increments of `delta`\n",
      " |      up to `limit` (exclusive).\n",
      " |      \n",
      " |      The number of elements in the output of range is computed as below:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          number_of_elements = max( ceil( (limit - start) / delta ) , 0 )\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      The pseudocode determining the contents of the output is shown below:\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          for(int i=0; i<number_of_elements; ++i) {\n",
      " |            output[i] =  start + (i * delta);\n",
      " |          }\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 1\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Inputs: start = 3, limit = 9, delta = 3\n",
      " |          Output: [3, 6]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          Inputs: start = 10, limit = 4, delta = -2\n",
      " |          Output: [10, 8, 6]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          start: Scalar. First entry for the range of output values.\n",
      " |      \n",
      " |          limit: Scalar. Exclusive upper limit for the range of output values.\n",
      " |      \n",
      " |          delta: Scalar. Value to step by.\n",
      " |  \n",
      " |  Round(self, X: 'T_Round') -> 'T_Round'\n",
      " |      [üåê Round(11)](https://onnx.ai/onnx/operators/onnx__Round.html#round-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Round takes one input Tensor and rounds the values, element-wise, meaning\n",
      " |      it finds the nearest integer for each value.\n",
      " |      In case of halfs, the rule is to round them to the nearest even integer.\n",
      " |      If input x is integral, +0, -0, NaN,  or infinite, x itself is returned.\n",
      " |      The output tensor has the same shape and type as the input.\n",
      " |      \n",
      " |      Examples:\n",
      " |      ::\n",
      " |      \n",
      " |          round([0.9]) = [1.0]\n",
      " |          round([2.5]) = [2.0]\n",
      " |          round([2.3]) = [2.0]\n",
      " |          round([1.5]) = [2.0]\n",
      " |          round([-4.5]) = [-4.0]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  SequenceAt(self, input_sequence: 'S_SequenceAt', position: 'I_SequenceAt') -> 'T_SequenceAt'\n",
      " |      [üåê SequenceAt(11)](https://onnx.ai/onnx/operators/onnx__SequenceAt.html#sequenceat-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Outputs a tensor copy from the tensor at 'position' in 'input_sequence'.\n",
      " |      Accepted range for 'position' is in `[-n, n - 1]`, where `n` is the number of tensors in 'input_sequence'.\n",
      " |      Negative value means counting positions from the back.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |      \n",
      " |          position: Position of the tensor in the sequence. Negative value means\n",
      " |              counting positions from the back. Accepted range in `[-n, n - 1]`, where\n",
      " |              `n` is the number of tensors in 'input_sequence'. It is an error if any\n",
      " |              of the index values are out of bounds. It must be a scalar(tensor of\n",
      " |              empty shape).\n",
      " |  \n",
      " |  SequenceConstruct(self, *inputs: 'T_SequenceConstruct') -> 'S_SequenceConstruct'\n",
      " |      [üåê SequenceConstruct(11)](https://onnx.ai/onnx/operators/onnx__SequenceConstruct.html#sequenceconstruct-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Construct a tensor sequence containing 'inputs' tensors.\n",
      " |      All tensors in 'inputs' must have the same data type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: (variadic) Tensors.\n",
      " |  \n",
      " |  SequenceEmpty(self, *, dtype: 'Optional[int]' = None) -> 'S_SequenceEmpty'\n",
      " |      [üåê SequenceEmpty(11)](https://onnx.ai/onnx/operators/onnx__SequenceEmpty.html#sequenceempty-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Construct an empty tensor sequence, with given data type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          dtype: (Optional) The data type of the tensors in the output sequence. The\n",
      " |              default type is 'float'.\n",
      " |  \n",
      " |  SequenceErase(self, input_sequence: 'S_SequenceErase', position: 'Optional[I_SequenceErase]' = None) -> 'S_SequenceErase'\n",
      " |      [üåê SequenceErase(11)](https://onnx.ai/onnx/operators/onnx__SequenceErase.html#sequenceerase-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Outputs a tensor sequence that removes the tensor at 'position' from 'input_sequence'.\n",
      " |      Accepted range for 'position' is in `[-n, n - 1]`, where `n` is the number of tensors in 'input_sequence'.\n",
      " |      Negative value means counting positions from the back.\n",
      " |      'position' is optional, by default it erases the last tensor from 'input_sequence'.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |      \n",
      " |          position: (optional) Position of the tensor in the sequence. Negative value\n",
      " |              means counting positions from the back. Accepted range in `[-n, n - 1]`,\n",
      " |              where `n` is the number of tensors in 'input_sequence'. It is an error\n",
      " |              if any of the index values are out of bounds. It must be a scalar(tensor\n",
      " |              of empty shape).\n",
      " |  \n",
      " |  SequenceInsert(self, input_sequence: 'S_SequenceInsert', tensor: 'T_SequenceInsert', position: 'Optional[I_SequenceInsert]' = None) -> 'S_SequenceInsert'\n",
      " |      [üåê SequenceInsert(11)](https://onnx.ai/onnx/operators/onnx__SequenceInsert.html#sequenceinsert-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Outputs a tensor sequence that inserts 'tensor' into 'input_sequence' at 'position'.\n",
      " |      'tensor' must have the same data type as 'input_sequence'.\n",
      " |      Accepted range for 'position' is in `[-n, n]`, where `n` is the number of tensors in 'input_sequence'.\n",
      " |      Negative value means counting positions from the back.\n",
      " |      'position' is optional, by default it inserts 'tensor' to the back of 'input_sequence'.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |      \n",
      " |          tensor: Input tensor to be inserted into the input sequence.\n",
      " |      \n",
      " |          position: (optional) Position in the sequence where the new tensor is\n",
      " |              inserted. It is optional and default is to insert to the back of the\n",
      " |              sequence. Negative value means counting positions from the back.\n",
      " |              Accepted range in `[-n, n]`, where `n` is the number of tensors in\n",
      " |              'input_sequence'. It is an error if any of the index values are out of\n",
      " |              bounds. It must be a scalar(tensor of empty shape).\n",
      " |  \n",
      " |  SequenceLength(self, input_sequence: 'S_SequenceLength') -> 'I_SequenceLength'\n",
      " |      [üåê SequenceLength(11)](https://onnx.ai/onnx/operators/onnx__SequenceLength.html#sequencelength-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Produces a scalar(tensor of empty shape) containing the number of tensors in 'input_sequence'.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input_sequence: Input sequence.\n",
      " |  \n",
      " |  SplitToSequence(self, input: 'T_SplitToSequence', split: 'Optional[I_SplitToSequence]' = None, *, axis: 'int' = 0, keepdims: 'int' = 1) -> 'S_SplitToSequence'\n",
      " |      [üåê SplitToSequence(11)](https://onnx.ai/onnx/operators/onnx__SplitToSequence.html#splittosequence-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Split a tensor into a sequence of tensors, along the specified 'axis'.\n",
      " |      Lengths of the parts can be specified using the optional argument 'split'.\n",
      " |      If the argument `split' is not specified, a default scalar value of 1\n",
      " |      is used as the value of `split'.\n",
      " |      'split' must contain only positive numbers.\n",
      " |      'split' is either a scalar (tensor of empty shape), or a 1-D tensor.\n",
      " |      If 'split' is a scalar, then 'input' will be split into chunks all of size 'split'\n",
      " |      if possible. The last chunk alone may be smaller than 'split' if the 'input' size\n",
      " |      along the given axis 'axis' is not divisible by 'split'.\n",
      " |      If 'split' is a 1-dimensional tensor, the input tensor is split into 'size(split)' chunks,\n",
      " |      with lengths of the parts on 'axis' specified in 'split'. In this scenario, the sum of entries\n",
      " |      in 'split' must be equal to the dimension size of input tensor on 'axis'.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: The tensor to split\n",
      " |      \n",
      " |          split: (optional) Length of each output. It can be either a scalar(tensor of\n",
      " |              empty shape), or a 1-D tensor. All values must be >= 0.\n",
      " |      \n",
      " |          axis: Which axis to split on. A negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-rank, rank-1].\n",
      " |      \n",
      " |          keepdims: Keep the split dimension or not. Default 1, which means we keep\n",
      " |              split dimension. If input 'split' is specified, this attribute is\n",
      " |              ignored.\n",
      " |  \n",
      " |  TopK(self, X: 'T_TopK', K: 'INT64', *, axis: 'int' = -1, largest: 'int' = 1, sorted: 'int' = 1) -> 'Tuple[T_TopK, I_TopK]'\n",
      " |      [üåê TopK(11)](https://onnx.ai/onnx/operators/onnx__TopK.html#topk-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Retrieve the top-K largest or smallest elements along a specified axis. Given an input tensor of\n",
      " |      shape [a_1, a_2, ..., a_n, r] and integer argument k, return two outputs:\n",
      " |      \n",
      " |      * Value tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n]\n",
      " |        which contains the values of the top k elements along the specified axis\n",
      " |      * Index tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] which\n",
      " |        contains the indices of the top k elements (original indices from the input\n",
      " |        tensor).\n",
      " |      \n",
      " |      * If \"largest\" is 1 (the default value) then the k largest elements are returned.\n",
      " |      * If \"sorted\" is 1 (the default value) then the resulting k elements will be sorted.\n",
      " |      * If \"sorted\" is 0, order of returned 'Values' and 'Indices' are undefined.\n",
      " |      \n",
      " |      Given two equivalent values, this operator uses the indices along the axis as\n",
      " |      a tiebreaker. That is, the element with the lower index will appear first.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Tensor of shape [a_1, a_2, ..., a_n, r]\n",
      " |      \n",
      " |          K: (non-differentiable) A 1-D tensor containing a single positive value\n",
      " |              corresponding to the number of top elements to retrieve\n",
      " |      \n",
      " |          axis: Dimension on which to do the sort. Negative value means counting\n",
      " |              dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |      \n",
      " |          largest: Whether to return the top-K largest or smallest elements.\n",
      " |      \n",
      " |          sorted: Whether to return the elements in sorted order.\n",
      " |  \n",
      " |  Unique(self, X: 'T_Unique', *, axis: 'Optional[int]' = None, sorted: 'int' = 1) -> 'Tuple[T_Unique, INT64, INT64, INT64]'\n",
      " |      [üåê Unique(11)](https://onnx.ai/onnx/operators/onnx__Unique.html#unique-11 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Find the unique elements of a tensor. When an optional attribute 'axis' is provided, unique subtensors sliced along the 'axis' are returned.\n",
      " |      Otherwise the input tensor is flattened and unique values of the flattened tensor are returned.\n",
      " |      \n",
      " |      This operator returns the unique values or sliced unique subtensors of the input tensor and three optional outputs.\n",
      " |      The first output tensor 'Y' contains all unique values or subtensors of the input.\n",
      " |      The second optional output tensor 'indices' contains indices of 'Y' elements' first occurance in 'X'..\n",
      " |      The third optional output tensor 'inverse_indices' contains, for elements of 'X', its corresponding indices in 'Y'. \".\n",
      " |      The fourth optional output tensor 'counts' contains the count of each element of 'Y' in the input.\n",
      " |      \n",
      " |      Outputs are either sorted in ascending order or optionally in the order of the first occurrence of the values in the input.\n",
      " |      \n",
      " |      https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html\n",
      " |      \n",
      " |      Example 1:\n",
      " |      ::\n",
      " |      \n",
      " |          input_X = [2, 1, 1, 3, 4, 3]\n",
      " |          attribute_sorted = 0\n",
      " |          attribute_axis = None\n",
      " |          output_Y = [2, 1, 3, 4]\n",
      " |          output_indices = [0, 1, 3, 4]\n",
      " |          output_inverse_indices = [0, 1, 1, 2, 3, 2]\n",
      " |          output_counts = [1, 2, 2, 1]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 2:\n",
      " |      ::\n",
      " |      \n",
      " |          input_X = [[1, 3], [2, 3]]\n",
      " |          attribute_sorted = 1\n",
      " |          attribute_axis = None\n",
      " |          output_Y = [1, 2, 3]\n",
      " |          output_indices = [0, 2, 1]\n",
      " |          output_inverse_indices = [0, 2, 1, 2]\n",
      " |          output_counts = [1, 1, 2]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 3:\n",
      " |      ::\n",
      " |      \n",
      " |          input_X = [[1, 0, 0], [1, 0, 0], [2, 3, 4]]\n",
      " |          attribute_sorted = 1\n",
      " |          attribute_axis = 0\n",
      " |          output_Y = [[1, 0, 0], [2, 3, 4]]\n",
      " |          output_indices = [0, 2]\n",
      " |          output_inverse_indices = [0, 0, 1]\n",
      " |          output_counts = [2, 1]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Example 4:\n",
      " |      ::\n",
      " |      \n",
      " |          input_x = [[[1., 1.], [0., 1.], [2., 1.], [0., 1.]],\n",
      " |                      [[1., 1.], [0., 1.], [2., 1.], [0., 1.]]]\n",
      " |          attribute_sorted = 1\n",
      " |          attribute_axis = 1\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      intermediate data are presented below for better understanding:\n",
      " |      there are 4 subtensors sliced along axis 1 of input_x (shape = (2, 4, 2)):\n",
      " |      ::\n",
      " |      \n",
      " |          A: [[1, 1], [1, 1]],\n",
      " |             [[0, 1], [0, 1]],\n",
      " |             [[2, 1], [2, 1]],\n",
      " |             [[0, 1], [0, 1]].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      there are 3 unique subtensors:\n",
      " |      ::\n",
      " |      \n",
      " |          [[1, 1], [1, 1]],\n",
      " |          [[0, 1], [0, 1]],\n",
      " |          [[2, 1], [2, 1]].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      sorted unique subtensors:\n",
      " |      ::\n",
      " |      \n",
      " |          B: [[0, 1], [0, 1]],\n",
      " |             [[1, 1], [1, 1]],\n",
      " |             [[2, 1], [2, 1]].\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      output_Y is constructed from B:\n",
      " |      ::\n",
      " |      \n",
      " |          [[[0. 1.], [1. 1.], [2. 1.]],\n",
      " |           [[0. 1.], [1. 1.], [2. 1.]]]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      output_indices is to map from B to A:\n",
      " |      ::\n",
      " |      \n",
      " |          [1, 0, 2]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      output_inverse_indices is to map from A to B:\n",
      " |      ::\n",
      " |      \n",
      " |          [1, 0, 2, 0]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      output_counts:\n",
      " |      ::\n",
      " |      \n",
      " |          [2, 1, 1]\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) A N-D input tensor that is to be processed.\n",
      " |      \n",
      " |          axis: (Optional) The dimension to apply unique. If not specified, the unique\n",
      " |              elements of the flattened input are returned. Negative value means\n",
      " |              counting dimensions from the back. Accepted range is [-r, r-1] where r =\n",
      " |              rank(input).\n",
      " |      \n",
      " |          sorted: (Optional) Whether to sort the unique elements in ascending order\n",
      " |              before returning as output. Must be one of 0, or 1 (default).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset11.Opset11:\n",
      " |  \n",
      " |  I_SequenceAt = ~I_SequenceAt\n",
      " |  \n",
      " |  I_SequenceErase = ~I_SequenceErase\n",
      " |  \n",
      " |  I_SequenceInsert = ~I_SequenceInsert\n",
      " |  \n",
      " |  I_SequenceLength = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  I_SplitToSequence = ~I_SplitToSequence\n",
      " |  \n",
      " |  I_TopK = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  S_ConcatFromSequence = ~S_ConcatFromSequence\n",
      " |  \n",
      " |  S_SequenceAt = ~S_SequenceAt\n",
      " |  \n",
      " |  S_SequenceConstruct = typing.Union[typing.Sequence[onnxscript.onnx_typ...\n",
      " |  \n",
      " |  S_SequenceEmpty = typing.Union[typing.Sequence[onnxscript.onnx_typ...4...\n",
      " |  \n",
      " |  S_SequenceErase = ~S_SequenceErase\n",
      " |  \n",
      " |  S_SequenceInsert = ~S_SequenceInsert\n",
      " |  \n",
      " |  S_SequenceLength = ~S_SequenceLength\n",
      " |  \n",
      " |  S_SplitToSequence = typing.Union[typing.Sequence[onnxscript.onnx_typ.....\n",
      " |  \n",
      " |  T1_Compress = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_DynamicQuantizeLinear = <class 'onnxscript.onnx_types.FLOAT'>\n",
      " |  \n",
      " |  T1_MaxUnpool = ~T1_MaxUnpool\n",
      " |  \n",
      " |  T1_OneHot = ~T1_OneHot\n",
      " |  \n",
      " |  T2_DynamicQuantizeLinear = <class 'onnxscript.onnx_types.UINT8'>\n",
      " |  \n",
      " |  T2_MaxUnpool = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T2_OneHot = ~T2_OneHot\n",
      " |  \n",
      " |  T3_OneHot = ~T3_OneHot\n",
      " |  \n",
      " |  T_AveragePool = ~T_AveragePool\n",
      " |  \n",
      " |  T_BitShift = ~T_BitShift\n",
      " |  \n",
      " |  T_Compress = ~T_Compress\n",
      " |  \n",
      " |  T_ConcatFromSequence = typing.Union[onnxscript.onnx_types.BOOL, onnxsc...\n",
      " |  \n",
      " |  T_Conv = ~T_Conv\n",
      " |  \n",
      " |  T_ConvTranspose = ~T_ConvTranspose\n",
      " |  \n",
      " |  T_Det = ~T_Det\n",
      " |  \n",
      " |  T_Range = ~T_Range\n",
      " |  \n",
      " |  T_Round = ~T_Round\n",
      " |  \n",
      " |  T_SequenceAt = typing.Union[onnxscript.onnx_types.BOOL, onnxscr...t.on...\n",
      " |  \n",
      " |  T_SequenceConstruct = ~T_SequenceConstruct\n",
      " |  \n",
      " |  T_SequenceInsert = ~T_SequenceInsert\n",
      " |  \n",
      " |  T_SplitToSequence = ~T_SplitToSequence\n",
      " |  \n",
      " |  T_TopK = ~T_TopK\n",
      " |  \n",
      " |  T_Unique = ~T_Unique\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset10.Opset10:\n",
      " |  \n",
      " |  ConvInteger(self, x: 'T1_ConvInteger', w: 'T2_ConvInteger', x_zero_point: 'Optional[T1_ConvInteger]' = None, w_zero_point: 'Optional[T2_ConvInteger]' = None, *, auto_pad: 'str' = 'NOTSET', dilations: 'Optional[Sequence[int]]' = None, group: 'int' = 1, kernel_shape: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T3_ConvInteger'\n",
      " |      [üåê ConvInteger(10)](https://onnx.ai/onnx/operators/onnx__ConvInteger.html#convinteger-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The integer convolution operator consumes an input tensor, its zero-point, a filter, and its zero-point,\n",
      " |      and computes the output. The production MUST never overflow. The accumulation may overflow if and only if in 32 bits.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data tensor from previous layer; has size (N x C x H x W), where N\n",
      " |              is the batch size, C is the number of channels, and H and W are the\n",
      " |              height and width. Note that this is for the 2D image. Otherwise the size\n",
      " |              is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in\n",
      " |              effect, the operation expects input data tensor to arrive with the\n",
      " |              dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE,\n",
      " |              DATA_FEATURE ...].\n",
      " |      \n",
      " |          w: The weight tensor that will be used in the convolutions; has size (M x\n",
      " |              C/group x kH x kW), where C is the number of channels, and kH and kW are\n",
      " |              the height and width of the kernel, and M is the number of feature maps.\n",
      " |              For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x\n",
      " |              k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel.\n",
      " |              Optionally, if dimension denotation is in effect, the operation expects\n",
      " |              the weight tensor to arrive with the dimension denotation of\n",
      " |              [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL\n",
      " |              ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based\n",
      " |              indices for the shape array). Or in other words FILTER_IN_CHANNEL should\n",
      " |              be equal to DATA_CHANNEL.\n",
      " |      \n",
      " |          x_zero_point: (optional) Zero point tensor for input 'x'. It's optional and\n",
      " |              default value is 0. It's a scalar, which means a per-tensor/layer\n",
      " |              quantization.\n",
      " |      \n",
      " |          w_zero_point: (optional) Zero point tensor for input 'w'. It's optional and\n",
      " |              default value is 0.  It could be a scalar or a 1-D tensor, which means a\n",
      " |              per-tensor/layer or per output channel quantization. If it's a 1-D\n",
      " |              tensor, its number of elements should be equal to the number of output\n",
      " |              channels (M)\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults to 1 along each axis.\n",
      " |      \n",
      " |          group: number of groups input channels and output channels are divided into.\n",
      " |              default is 1.\n",
      " |      \n",
      " |          kernel_shape: The shape of the convolution kernel. If not present, should be\n",
      " |              inferred from input 'w'.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0.The value represent the number\n",
      " |              of pixels added to the beginning and end part of the corresponding\n",
      " |              axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end,\n",
      " |              x2_end,...], where xi_begin the number ofpixels added at the beginning\n",
      " |              of axis `i` and xi_end, the number of pixels added at the end of axis\n",
      " |              `i`.This attribute cannot be used simultaneously with auto_pad\n",
      " |              attribute. If not present, the padding defaultsto 0 along start and end\n",
      " |              of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each axis.\n",
      " |  \n",
      " |  IsInf(self, X: 'T1_IsInf', *, detect_negative: 'int' = 1, detect_positive: 'int' = 1) -> 'T2_IsInf'\n",
      " |      [üåê IsInf(10)](https://onnx.ai/onnx/operators/onnx__IsInf.html#isinf-10 \"Online Documentation\")\n",
      " |      \n",
      " |      Map infinity to true and other values to false.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) input\n",
      " |      \n",
      " |          detect_negative: (Optional) Whether map negative infinity to true. Default\n",
      " |              to 1 so that negative infinity induces true. Set this attribute to 0 if\n",
      " |              negative infinity should be mapped to false.\n",
      " |      \n",
      " |          detect_positive: (Optional) Whether map positive infinity to true. Default\n",
      " |              to 1 so that positive infinity induces true. Set this attribute to 0 if\n",
      " |              positive infinity should be mapped to false.\n",
      " |  \n",
      " |  MatMulInteger(self, A: 'T1_MatMulInteger', B: 'T2_MatMulInteger', a_zero_point: 'Optional[T1_MatMulInteger]' = None, b_zero_point: 'Optional[T2_MatMulInteger]' = None) -> 'T3_MatMulInteger'\n",
      " |      [üåê MatMulInteger(10)](https://onnx.ai/onnx/operators/onnx__MatMulInteger.html#matmulinteger-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html.\n",
      " |      The production MUST never overflow. The accumulation may overflow if and only if in 32 bits.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) N-dimensional matrix A\n",
      " |      \n",
      " |          B: (non-differentiable) N-dimensional matrix B\n",
      " |      \n",
      " |          a_zero_point: (optional, non-differentiable) Zero point tensor for input\n",
      " |              'A'. It's optional and default value is 0. It could be a scalar or N-D\n",
      " |              tensor. Scalar refers to per tensor quantization whereas N-D refers to\n",
      " |              per row quantization. If the input is 2D of shape [M, K] then zero point\n",
      " |              tensor may be an M element vector [zp_1, zp_2, ..., zp_M]. If the input\n",
      " |              is N-D tensor with shape [D1, D2, M, K] then zero point tensor may have\n",
      " |              shape [D1, D2, M, 1].\n",
      " |      \n",
      " |          b_zero_point: (optional, non-differentiable) Zero point tensor for input\n",
      " |              'B'. It's optional and default value is 0. It could be a scalar or a N-D\n",
      " |              tensor, Scalar refers to per tensor quantization whereas N-D refers to\n",
      " |              per col quantization. If the input is 2D of shape [K, N] then zero point\n",
      " |              tensor may be an N element vector [zp_1, zp_2, ..., zp_N]. If the input\n",
      " |              is N-D tensor with shape [D1, D2, K, N] then zero point tensor may have\n",
      " |              shape [D1, D2, 1, N].\n",
      " |  \n",
      " |  QLinearConv(self, x: 'T1_QLinearConv', x_scale: 'FLOAT', x_zero_point: 'T1_QLinearConv', w: 'T2_QLinearConv', w_scale: 'FLOAT', w_zero_point: 'T2_QLinearConv', y_scale: 'FLOAT', y_zero_point: 'T3_QLinearConv', B: 'Optional[T4_QLinearConv]' = None, *, auto_pad: 'str' = 'NOTSET', dilations: 'Optional[Sequence[int]]' = None, group: 'int' = 1, kernel_shape: 'Optional[Sequence[int]]' = None, pads: 'Optional[Sequence[int]]' = None, strides: 'Optional[Sequence[int]]' = None) -> 'T3_QLinearConv'\n",
      " |      [üåê QLinearConv(10)](https://onnx.ai/onnx/operators/onnx__QLinearConv.html#qlinearconv-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      The convolution operator consumes a quantized input tensor, its scale and zero point,\n",
      " |      a quantized filter, its scale and zero point, and output's scale and zero point,\n",
      " |      and computes the quantized output. Each scale and zero-point pair must have same shape.\n",
      " |      It means they must be either scalars (per tensor) or 1-D tensors (per output channel).\n",
      " |      Each input or output and its related zero point must have same type.\n",
      " |      When bias is present it must be quantized using scale = input scale * weight scale and\n",
      " |      zero point as 0.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data tensor from previous layer; has size (N x C x H x W), where N\n",
      " |              is the batch size, C is the number of channels, and H and W are the\n",
      " |              height and width. Note that this is for the 2D image. Otherwise the size\n",
      " |              is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in\n",
      " |              effect, the operation expects input data tensor to arrive with the\n",
      " |              dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE,\n",
      " |              DATA_FEATURE ...].\n",
      " |      \n",
      " |          x_scale: Scale tensor for input 'x'. It's a scalar, which means a\n",
      " |              per-tensor/layer quantization.\n",
      " |      \n",
      " |          x_zero_point: Zero point tensor for input 'x'. It's a scalar, which means a\n",
      " |              per-tensor/layer quantization.\n",
      " |      \n",
      " |          w: The weight tensor that will be used in the convolutions; has size (M x\n",
      " |              C/group x kH x kW), where C is the number of channels, and kH and kW are\n",
      " |              the height and width of the kernel, and M is the number of feature maps.\n",
      " |              For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x\n",
      " |              k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel.\n",
      " |              Optionally, if dimension denotation is in effect, the operation expects\n",
      " |              the weight tensor to arrive with the dimension denotation of\n",
      " |              [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL\n",
      " |              ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based\n",
      " |              indices for the shape array). Or in other words FILTER_IN_CHANNEL should\n",
      " |              be equal to DATA_CHANNEL.\n",
      " |      \n",
      " |          w_scale: Scale tensor for input 'w'. It could be a scalar or a 1-D tensor,\n",
      " |              which means a per-tensor/layer or per output channel quantization. If\n",
      " |              it's a 1-D tensor, its number of elements should be equal to the number\n",
      " |              of output channels (M).\n",
      " |      \n",
      " |          w_zero_point: Zero point tensor for input 'w'. It could be a scalar or a 1-D\n",
      " |              tensor, which means a per-tensor/layer or per output channel\n",
      " |              quantization. If it's a 1-D tensor, its number of elements should be\n",
      " |              equal to the number of output channels (M).\n",
      " |      \n",
      " |          y_scale: Scale tensor for output 'y'. It's a scalar, which means a\n",
      " |              per-tensor/layer quantization.\n",
      " |      \n",
      " |          y_zero_point: Zero point tensor for output 'y'. It's a scalar, which means a\n",
      " |              per-tensor/layer quantization.\n",
      " |      \n",
      " |          B: (optional) Optional 1D bias to be added to the convolution, has size of\n",
      " |              M. Bias must be quantized using scale = x_scale * w_scale and zero_point\n",
      " |              = 0\n",
      " |      \n",
      " |          auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.\n",
      " |              Where default value is NOTSET, which means explicit padding is used.\n",
      " |              SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =\n",
      " |              ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is\n",
      " |              split between the two sides equally or almost equally (depending on\n",
      " |              whether it is even or odd). In case the padding is an odd number, the\n",
      " |              extra padding is added at the end for SAME_UPPER and at the beginning\n",
      " |              for SAME_LOWER.\n",
      " |      \n",
      " |          dilations: dilation value along each spatial axis of the filter. If not\n",
      " |              present, the dilation defaults to 1 along each spatial axis.\n",
      " |      \n",
      " |          group: number of groups input channels and output channels are divided into.\n",
      " |              default is 1.\n",
      " |      \n",
      " |          kernel_shape: The shape of the convolution kernel. If not present, should be\n",
      " |              inferred from input 'w'.\n",
      " |      \n",
      " |          pads: Padding for the beginning and ending along each spatial axis, it can\n",
      " |              take any value greater than or equal to 0.The value represent the number\n",
      " |              of pixels added to the beginning and end part of the corresponding\n",
      " |              axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end,\n",
      " |              x2_end,...], where xi_begin the number ofpixels added at the beginning\n",
      " |              of axis `i` and xi_end, the number of pixels added at the end of axis\n",
      " |              `i`.This attribute cannot be used simultaneously with auto_pad\n",
      " |              attribute. If not present, the padding defaultsto 0 along start and end\n",
      " |              of each spatial axis.\n",
      " |      \n",
      " |          strides: Stride along each spatial axis. If not present, the stride defaults\n",
      " |              to 1 along each spatial axis.\n",
      " |  \n",
      " |  QLinearMatMul(self, a: 'T1_QLinearMatMul', a_scale: 'FLOAT', a_zero_point: 'T1_QLinearMatMul', b: 'T2_QLinearMatMul', b_scale: 'FLOAT', b_zero_point: 'T2_QLinearMatMul', y_scale: 'FLOAT', y_zero_point: 'T3_QLinearMatMul') -> 'T3_QLinearMatMul'\n",
      " |      [üåê QLinearMatMul(10)](https://onnx.ai/onnx/operators/onnx__QLinearMatMul.html#qlinearmatmul-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html.\n",
      " |      It consumes two quantized input tensors, their scales and zero points, scale and zero point of output,\n",
      " |      and computes the quantized output. The quantization formula is y = saturate((x / y_scale) + y_zero_point).\n",
      " |      For (x / y_scale), it is rounding to nearest ties to even. Refer to https://en.wikipedia.org/wiki/Rounding for details.\n",
      " |      Scale and zero point must have same shape. They must be either scalar (per tensor) or N-D tensor\n",
      " |      (per row for 'a' and per column for 'b'). Scalar refers to per tensor quantization whereas N-D refers to per row\n",
      " |      or per column quantization. If the input is 2D of shape [M, K] then zero point and scale tensor may be\n",
      " |      an M element vector [v_1, v_2, ..., v_M] for per row quantization and K element vector of shape [v_1, v_2, ..., v_K]\n",
      " |      for per column quantization. If the input is N-D tensor with shape [D1, D2, M, K] then zero point and scale tensor may\n",
      " |      have shape [D1, D2, M, 1] for per row quantization and shape [D1, D2, 1, K] for per column quantization.\n",
      " |      Production must never overflow, and accumulation may overflow if and only if in 32 bits.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          a: (non-differentiable) N-dimensional quantized matrix a\n",
      " |      \n",
      " |          a_scale: (non-differentiable) scale of quantized input a\n",
      " |      \n",
      " |          a_zero_point: (non-differentiable) zero point of quantized input a\n",
      " |      \n",
      " |          b: (non-differentiable) N-dimensional quantized matrix b\n",
      " |      \n",
      " |          b_scale: (non-differentiable) scale of quantized input b\n",
      " |      \n",
      " |          b_zero_point: (non-differentiable) zero point of quantized input b\n",
      " |      \n",
      " |          y_scale: (non-differentiable) scale of quantized output y\n",
      " |      \n",
      " |          y_zero_point: (non-differentiable) zero point of quantized output y\n",
      " |  \n",
      " |  ReverseSequence(self, input: 'T_ReverseSequence', sequence_lens: 'INT64', *, batch_axis: 'int' = 1, time_axis: 'int' = 0) -> 'T_ReverseSequence'\n",
      " |      [üåê ReverseSequence(10)](https://onnx.ai/onnx/operators/onnx__ReverseSequence.html#reversesequence-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Reverse batch of sequences having different lengths specified by `sequence_lens`.\n",
      " |      \n",
      " |      For each slice i iterating on batch axis, the operator reverses the first sequence_lens[i] elements on time axis,\n",
      " |      and copies elements whose index's beyond sequence_lens[i] to the output. So the output slice i contains reversed\n",
      " |      sequences on the first sequence_lens[i] elements, then have original values copied for the other elements.\n",
      " |      \n",
      " |      Example 1:\n",
      " |        input = [[0.0, 4.0, 8.0,  12.0],\n",
      " |                 [1.0, 5.0, 9.0,  13.0],\n",
      " |                 [2.0, 6.0, 10.0, 14.0],\n",
      " |                 [3.0, 7.0, 11.0, 15.0]]\n",
      " |        sequence_lens = [4, 3, 2, 1]\n",
      " |        time_axis = 0\n",
      " |        batch_axis = 1\n",
      " |      \n",
      " |        output = [[3.0, 6.0, 9.0,  12.0],\n",
      " |                  [2.0, 5.0, 8.0,  13.0],\n",
      " |                  [1.0, 4.0, 10.0, 14.0],\n",
      " |                  [0.0, 7.0, 11.0, 15.0]]\n",
      " |      \n",
      " |      Example 2:\n",
      " |        input = [[0.0,  1.0,  2.0,  3.0 ],\n",
      " |                 [4.0,  5.0,  6.0,  7.0 ],\n",
      " |                 [8.0,  9.0,  10.0, 11.0],\n",
      " |                 [12.0, 13.0, 14.0, 15.0]]\n",
      " |        sequence_lens = [1, 2, 3, 4]\n",
      " |        time_axis = 1\n",
      " |        batch_axis = 0\n",
      " |      \n",
      " |        output = [[0.0,  1.0,  2.0,  3.0 ],\n",
      " |                  [5.0,  4.0,  6.0,  7.0 ],\n",
      " |                  [10.0, 9.0,  8.0,  11.0],\n",
      " |                  [15.0, 14.0, 13.0, 12.0]]\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: Tensor of rank r >= 2.\n",
      " |      \n",
      " |          sequence_lens: Tensor specifying lengths of the sequences in a batch. It has\n",
      " |              shape `[batch_size]`.\n",
      " |      \n",
      " |          batch_axis: (Optional) Specify which axis is batch axis. Must be one of 1\n",
      " |              (default), or 0.\n",
      " |      \n",
      " |          time_axis: (Optional) Specify which axis is time axis. Must be one of 0\n",
      " |              (default), or 1.\n",
      " |  \n",
      " |  StringNormalizer(self, X: 'STRING', *, case_change_action: 'str' = 'NONE', is_case_sensitive: 'int' = 0, locale: 'Optional[str]' = None, stopwords: 'Optional[Sequence[str]]' = None) -> 'STRING'\n",
      " |      [üåê StringNormalizer(10)](https://onnx.ai/onnx/operators/onnx__StringNormalizer.html#stringnormalizer-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      StringNormalization performs string operations for basic cleaning.\n",
      " |      This operator has only one input (denoted by X) and only one output\n",
      " |      (denoted by Y). This operator first examines the elements in the X,\n",
      " |      and removes elements specified in \"stopwords\" attribute.\n",
      " |      After removing stop words, the intermediate result can be further lowercased,\n",
      " |      uppercased, or just returned depending the \"case_change_action\" attribute.\n",
      " |      This operator only accepts [C]- and [1, C]-tensor.\n",
      " |      If all elements in X are dropped, the output will be the empty value of string tensor with shape [1]\n",
      " |      if input shape is [C] and shape [1, 1] if input shape is [1, C].\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: UTF-8 strings to normalize\n",
      " |      \n",
      " |          case_change_action: string enum that cases output to be\n",
      " |              lowercased/uppercases/unchanged. Valid values are \"LOWER\", \"UPPER\",\n",
      " |              \"NONE\". Default is \"NONE\"\n",
      " |      \n",
      " |          is_case_sensitive: Boolean. Whether the identification of stop words in X is\n",
      " |              case-sensitive. Default is false\n",
      " |      \n",
      " |          locale: Environment dependent string that denotes the locale according to\n",
      " |              which output strings needs to be upper/lowercased.Default en_US or\n",
      " |              platform specific equivalent as decided by the implementation.\n",
      " |      \n",
      " |          stopwords: List of stop words. If not set, no word would be removed from X.\n",
      " |  \n",
      " |  ThresholdedRelu(self, X: 'T_ThresholdedRelu', *, alpha: 'float' = 1.0) -> 'T_ThresholdedRelu'\n",
      " |      [üåê ThresholdedRelu(10)](https://onnx.ai/onnx/operators/onnx__ThresholdedRelu.html#thresholdedrelu-10 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      ThresholdedRelu takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the rectified linear function, y = x for x > alpha, y = 0 otherwise,\n",
      " |      is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: Threshold value\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset10.Opset10:\n",
      " |  \n",
      " |  T1_ConvInteger = ~T1_ConvInteger\n",
      " |  \n",
      " |  T1_IsInf = ~T1_IsInf\n",
      " |  \n",
      " |  T1_MatMulInteger = ~T1_MatMulInteger\n",
      " |  \n",
      " |  T1_QLinearConv = ~T1_QLinearConv\n",
      " |  \n",
      " |  T1_QLinearMatMul = ~T1_QLinearMatMul\n",
      " |  \n",
      " |  T2_ConvInteger = ~T2_ConvInteger\n",
      " |  \n",
      " |  T2_IsInf = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T2_MatMulInteger = ~T2_MatMulInteger\n",
      " |  \n",
      " |  T2_QLinearConv = ~T2_QLinearConv\n",
      " |  \n",
      " |  T2_QLinearMatMul = ~T2_QLinearMatMul\n",
      " |  \n",
      " |  T3_ConvInteger = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T3_MatMulInteger = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T3_QLinearConv = ~T3_QLinearConv\n",
      " |  \n",
      " |  T3_QLinearMatMul = ~T3_QLinearMatMul\n",
      " |  \n",
      " |  T4_QLinearConv = <class 'onnxscript.onnx_types.INT32'>\n",
      " |  \n",
      " |  T_Resize = ~T_Resize\n",
      " |  \n",
      " |  T_ReverseSequence = ~T_ReverseSequence\n",
      " |  \n",
      " |  T_ThresholdedRelu = ~T_ThresholdedRelu\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset9.Opset9:\n",
      " |  \n",
      " |  Acosh(self, input: 'T_Acosh') -> 'T_Acosh'\n",
      " |      [üåê Acosh(9)](https://onnx.ai/onnx/operators/onnx__Acosh.html#acosh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic arccosine of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Asinh(self, input: 'T_Asinh') -> 'T_Asinh'\n",
      " |      [üåê Asinh(9)](https://onnx.ai/onnx/operators/onnx__Asinh.html#asinh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic arcsine of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Atanh(self, input: 'T_Atanh') -> 'T_Atanh'\n",
      " |      [üåê Atanh(9)](https://onnx.ai/onnx/operators/onnx__Atanh.html#atanh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic arctangent of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  ConstantOfShape(self, input: 'T1_ConstantOfShape', *, value: 'Optional[TensorProto]' = None) -> 'T2_ConstantOfShape'\n",
      " |      [üåê ConstantOfShape(9)](https://onnx.ai/onnx/operators/onnx__ConstantOfShape.html#constantofshape-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with given value and shape.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: 1D tensor. The shape of the expected output tensor. If empty tensor\n",
      " |              is given, the output would be a scalar. All values must be >= 0.\n",
      " |      \n",
      " |          value: (Optional) The value of the output elements.Should be a one-element\n",
      " |              tensor. If not specified, it defaults to a tensor of value 0 and\n",
      " |              datatype float32\n",
      " |  \n",
      " |  Cosh(self, input: 'T_Cosh') -> 'T_Cosh'\n",
      " |      [üåê Cosh(9)](https://onnx.ai/onnx/operators/onnx__Cosh.html#cosh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic cosine of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  EyeLike(self, input: 'T1_EyeLike', *, dtype: 'Optional[int]' = None, k: 'int' = 0) -> 'T2_EyeLike'\n",
      " |      [üåê EyeLike(9)](https://onnx.ai/onnx/operators/onnx__EyeLike.html#eyelike-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a 2D tensor (matrix) with ones on the diagonal and zeros everywhere else. Only 2D\n",
      " |      tensors are supported, i.e. input T1 must be of rank 2. The shape of the output tensor is the\n",
      " |      same as the input tensor. The data type can be specified by the 'dtype' argument. If\n",
      " |      'dtype' is not specified, then the type of input tensor is used. By default, the main diagonal\n",
      " |      is populated with ones, but attribute 'k' can be used to populate upper or lower diagonals.\n",
      " |      The 'dtype' argument must be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message and be valid as an output type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: 2D input tensor to copy shape, and optionally, type information from.\n",
      " |      \n",
      " |          dtype: (Optional) The data type for the elements of the output tensor. If\n",
      " |              not specified,the data type of the input tensor T1 is used. If input\n",
      " |              tensor T1 is also notspecified, then type defaults to 'float'.\n",
      " |      \n",
      " |          k: (Optional) Index of the diagonal to be populated with ones. Default is 0.\n",
      " |              If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the\n",
      " |              main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a\n",
      " |              lower diagonal.\n",
      " |  \n",
      " |  Scatter(self, data: 'T_Scatter', indices: 'Tind_Scatter', updates: 'T_Scatter', *, axis: 'int' = 0) -> 'T_Scatter'\n",
      " |      [üåê Scatter(9)](https://onnx.ai/onnx/operators/onnx__Scatter.html#scatter-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given `data`, `updates` and `indices` input tensors of rank r >= 1, write the values provided by `updates`\n",
      " |      into the first input, `data`, along `axis` dimension of `data` (by default outer-most one as axis=0) at corresponding `indices`.\n",
      " |      For each entry in `updates`, the target index in `data` is specified by corresponding entry in `indices`\n",
      " |      for dimension = axis, and index in source for dimension != axis. For instance, in a 2-D tensor case,\n",
      " |      data[indices[i][j]][j] = updates[i][j] if axis = 0, or data[i][indices[i][j]] = updates[i][j] if axis = 1,\n",
      " |      where i and j are loop counters from 0 up to the respective size in `updates` - 1.\n",
      " |      Example 1:\n",
      " |        data = [\n",
      " |            [0.0, 0.0, 0.0],\n",
      " |            [0.0, 0.0, 0.0],\n",
      " |            [0.0, 0.0, 0.0],\n",
      " |        ]\n",
      " |        indices = [\n",
      " |            [1, 0, 2],\n",
      " |            [0, 2, 1],\n",
      " |        ]\n",
      " |        updates = [\n",
      " |            [1.0, 1.1, 1.2],\n",
      " |            [2.0, 2.1, 2.2],\n",
      " |        ]\n",
      " |        output = [\n",
      " |            [2.0, 1.1, 0.0]\n",
      " |            [1.0, 0.0, 2.2]\n",
      " |            [0.0, 2.1, 1.2]\n",
      " |        ]\n",
      " |      Example 2:\n",
      " |        data = [[1.0, 2.0, 3.0, 4.0, 5.0]]\n",
      " |        indices = [[1, 3]]\n",
      " |        updates = [[1.1, 2.1]]\n",
      " |        axis = 1\n",
      " |        output = [[1.0, 1.1, 3.0, 2.1, 5.0]]\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          data: Tensor of rank r >= 1.\n",
      " |      \n",
      " |          indices: Tensor of int32/int64 indices, of r >= 1 (same rank as input).\n",
      " |      \n",
      " |          updates: Tensor of rank r >=1 (same rank and shape as indices)\n",
      " |      \n",
      " |          axis: Which axis to scatter on. Negative value means counting dimensions\n",
      " |              from the back. Accepted range is [-r, r-1]\n",
      " |  \n",
      " |  Shrink(self, input: 'T_Shrink', *, bias: 'float' = 0.0, lambd: 'float' = 0.5) -> 'T_Shrink'\n",
      " |      [üåê Shrink(9)](https://onnx.ai/onnx/operators/onnx__Shrink.html#shrink-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Shrink takes one input data (Tensor<numeric>) and produces one Tensor output,\n",
      " |      having same datatype and shape with input. It has two attributes, lambd and\n",
      " |      bias. The formula of this operator is: If x < -lambd, y = x + bias;\n",
      " |      If x > lambd, y = x - bias; Otherwise, y = 0.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) The input data as Tensor.\n",
      " |      \n",
      " |          bias: The bias value added to output. Default is 0.\n",
      " |      \n",
      " |          lambd: The lambd value for the Shrink formulation. Default is 0.5.\n",
      " |  \n",
      " |  Sinh(self, input: 'T_Sinh') -> 'T_Sinh'\n",
      " |      [üåê Sinh(9)](https://onnx.ai/onnx/operators/onnx__Sinh.html#sinh-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the hyperbolic sine of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  TfIdfVectorizer(self, X: 'T_TfIdfVectorizer', *, max_gram_length: 'int', max_skip_count: 'int', min_gram_length: 'int', mode: 'str', ngram_counts: 'Sequence[int]', ngram_indexes: 'Sequence[int]', pool_int64s: 'Optional[Sequence[int]]' = None, pool_strings: 'Optional[Sequence[str]]' = None, weights: 'Optional[Sequence[float]]' = None) -> 'T1_TfIdfVectorizer'\n",
      " |      [üåê TfIdfVectorizer(9)](https://onnx.ai/onnx/operators/onnx__TfIdfVectorizer.html#tfidfvectorizer-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      This transform extracts n-grams from the input sequence and save them as a vector. Input can\n",
      " |      be either a 1-D or 2-D tensor. For 1-D input, output is the n-gram representation of that input.\n",
      " |      For 2-D input, the output is also a  2-D tensor whose i-th row is the n-gram representation of the i-th input row.\n",
      " |      More specifically, if input shape is [C], the corresponding output shape would be [max(ngram_indexes) + 1].\n",
      " |      If input shape is [N, C], this operator produces a [N, max(ngram_indexes) + 1]-tensor.\n",
      " |      \n",
      " |      In contrast to standard n-gram extraction, here, the indexes of extracting an n-gram from the original\n",
      " |      sequence are not necessarily consecutive numbers. The discontinuity between indexes are controlled by the number of skips.\n",
      " |      If the number of skips is 2, we should skip two tokens when scanning through the original sequence.\n",
      " |      Let's consider an example. Assume that input sequence is [94, 17, 36, 12, 28] and the number of skips is 2.\n",
      " |      The associated 2-grams are [94, 12] and [17, 28] respectively indexed by [0, 3] and [1, 4].\n",
      " |      If the number of skips becomes 0, the 2-grams generated are [94, 17], [17, 36], [36, 12], [12, 28]\n",
      " |      indexed by [0, 1], [1, 2], [2, 3], [3, 4], respectively.\n",
      " |      \n",
      " |      The output vector (denoted by Y) stores the count of each n-gram;\n",
      " |      Y[ngram_indexes[i]] indicates the times that the i-th n-gram is found. The attribute ngram_indexes is used to determine the mapping\n",
      " |      between index i and the corresponding n-gram's output coordinate. If pool_int64s is [94, 17, 17, 36], ngram_indexes is [1, 0],\n",
      " |      ngram_counts=[0, 0], then the Y[0] (first element in Y) and Y[1] (second element in Y) are the counts of [17, 36] and [94, 17],\n",
      " |      respectively. An n-gram which cannot be found in pool_strings/pool_int64s should be ignored and has no effect on the output.\n",
      " |      Note that we may consider all skips up to S when generating the n-grams.\n",
      " |      \n",
      " |      The examples used above are true if mode is \"TF\". If mode is \"IDF\", all the counts larger than 1 would be truncated to 1 and\n",
      " |      the i-th element in weights would be used to scale (by multiplication) the count of the i-th n-gram in pool. If mode is \"TFIDF\",\n",
      " |      this operator first computes the counts of all n-grams and then scale them by the associated values in the weights attribute.\n",
      " |      \n",
      " |      Only one of pool_strings and pool_int64s can be set. If pool_int64s is set, the input should be an integer tensor.\n",
      " |      If pool_strings is set, the input must be a string tensor.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input for n-gram extraction\n",
      " |      \n",
      " |          max_gram_length: Maximum n-gram length. If this value is 3, 3-grams will be\n",
      " |              used to generate the output.\n",
      " |      \n",
      " |          max_skip_count: Maximum number of items (integers/strings) to be skipped\n",
      " |              when constructing an n-gram from X. If max_skip_count=1,\n",
      " |              min_gram_length=2, max_gram_length=3, this operator may generate 2-grams\n",
      " |              with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and\n",
      " |              skip_count=1\n",
      " |      \n",
      " |          min_gram_length: Minimum n-gram length. If this value is 2 and\n",
      " |              max_gram_length is 3, output may contain counts of 2-grams and 3-grams.\n",
      " |      \n",
      " |          mode: The weighting criteria. It can be one of \"TF\" (term frequency), \"IDF\"\n",
      " |              (inverse document frequency), and \"TFIDF\" (the combination of TF and\n",
      " |              IDF)\n",
      " |      \n",
      " |          ngram_counts: The starting indexes of 1-grams, 2-grams, and so on in pool.\n",
      " |              It is useful when determining the boundary between two consecutive\n",
      " |              collections of n-grams. For example, if ngram_counts is [0, 17, 36], the\n",
      " |              first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36.\n",
      " |              This format is essentially identical to CSR (or CSC) sparse matrix\n",
      " |              format, and we choose to use this due to its popularity.\n",
      " |      \n",
      " |          ngram_indexes: list of int64s (type: AttributeProto::INTS). This list is\n",
      " |              parallel to the specified 'pool_*' attribute. The i-th element in\n",
      " |              ngram_indexes indicate the coordinate of the i-th n-gram in the output\n",
      " |              tensor.\n",
      " |      \n",
      " |          pool_int64s: List of int64 n-grams learned from the training set. Either\n",
      " |              this or pool_strings attributes must be present but not both. It's an\n",
      " |              1-D tensor starting with the collections of all 1-grams and ending with\n",
      " |              the collections of n-grams. The i-th element in pool stores the n-gram\n",
      " |              that should be mapped to coordinate ngram_indexes[i] in the output\n",
      " |              vector.\n",
      " |      \n",
      " |          pool_strings: List of strings n-grams learned from the training set. Either\n",
      " |              this or pool_int64s attributes must be present but not both. It's an 1-D\n",
      " |              tensor starting with the collections of all 1-grams and ending with the\n",
      " |              collections of n-grams. The i-th element in pool stores the n-gram that\n",
      " |              should be mapped to coordinate ngram_indexes[i] in the output vector.\n",
      " |      \n",
      " |          weights: list of floats. This attribute stores the weight of each n-gram in\n",
      " |              pool. The i-th element in weights is the weight of the i-th n-gram in\n",
      " |              pool. Its length equals to the size of ngram_indexes. By default,\n",
      " |              weights is an all-one tensor.This attribute is used when mode is \"IDF\"\n",
      " |              or \"TFIDF\" to scale the associated word counts.\n",
      " |  \n",
      " |  Upsample(self, X: 'T_Upsample', scales: 'FLOAT', *, mode: 'str' = 'nearest') -> 'T_Upsample'\n",
      " |      [üåê Upsample(9)](https://onnx.ai/onnx/operators/onnx__Upsample.html#upsample-9 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Upsample the input tensor.\n",
      " |      Each dimension value of the output tensor is:\n",
      " |        output_dimension = floor(input_dimension * scale).\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: N-D tensor\n",
      " |      \n",
      " |          scales: The scale array along each dimension. It takes value greater than or\n",
      " |              equal to 1. The number of elements of 'scales' should be the same as the\n",
      " |              rank of input 'X'.\n",
      " |      \n",
      " |          mode: Two interpolation modes: nearest (default), and linear (including\n",
      " |              bilinear, trilinear, etc)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset9.Opset9:\n",
      " |  \n",
      " |  T1_ConstantOfShape = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  T1_EyeLike = ~T1_EyeLike\n",
      " |  \n",
      " |  T1_TfIdfVectorizer = <class 'onnxscript.onnx_types.FLOAT'>\n",
      " |  \n",
      " |  T2_ConstantOfShape = typing.Union[onnxscript.onnx_types.BOOL, onnxscr....\n",
      " |  \n",
      " |  T2_EyeLike = typing.Union[onnxscript.onnx_types.BOOL, onnxscr...t.onnx...\n",
      " |  \n",
      " |  T_Acosh = ~T_Acosh\n",
      " |  \n",
      " |  T_Asinh = ~T_Asinh\n",
      " |  \n",
      " |  T_Atanh = ~T_Atanh\n",
      " |  \n",
      " |  T_Cosh = ~T_Cosh\n",
      " |  \n",
      " |  T_Scatter = ~T_Scatter\n",
      " |  \n",
      " |  T_Shrink = ~T_Shrink\n",
      " |  \n",
      " |  T_Sinh = ~T_Sinh\n",
      " |  \n",
      " |  T_TfIdfVectorizer = ~T_TfIdfVectorizer\n",
      " |  \n",
      " |  T_Upsample = ~T_Upsample\n",
      " |  \n",
      " |  Tind_Scatter = ~Tind_Scatter\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset8.Opset8:\n",
      " |  \n",
      " |  I_Scan = <class 'onnxscript.onnx_types.INT64'>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset7.Opset7:\n",
      " |  \n",
      " |  Acos(self, input: 'T_Acos') -> 'T_Acos'\n",
      " |      [üåê Acos(7)](https://onnx.ai/onnx/operators/onnx__Acos.html#acos-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the arccosine (inverse of cosine) of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  And(self, A: 'T_And', B: 'T_And') -> 'T1_And'\n",
      " |      [üåê And(7)](https://onnx.ai/onnx/operators/onnx__And.html#and-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `and` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Asin(self, input: 'T_Asin') -> 'T_Asin'\n",
      " |      [üåê Asin(7)](https://onnx.ai/onnx/operators/onnx__Asin.html#asin-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the arcsine (inverse of sine) of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Atan(self, input: 'T_Atan') -> 'T_Atan'\n",
      " |      [üåê Atan(7)](https://onnx.ai/onnx/operators/onnx__Atan.html#atan-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the arctangent (inverse of tangent) of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Cos(self, input: 'T_Cos') -> 'T_Cos'\n",
      " |      [üåê Cos(7)](https://onnx.ai/onnx/operators/onnx__Cos.html#cos-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the cosine of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Multinomial(self, input: 'T1_Multinomial', *, dtype: 'int' = 6, sample_size: 'int' = 1, seed: 'Optional[float]' = None) -> 'T2_Multinomial'\n",
      " |      [üåê Multinomial(7)](https://onnx.ai/onnx/operators/onnx__Multinomial.html#multinomial-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor of samples from a multinomial distribution according to the probabilities\n",
      " |      of each of the possible outcomes.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: Input tensor with shape [batch_size, class_size], where class_size is\n",
      " |              the number of all possible outcomes. Each value along the axis zero\n",
      " |              represents the unnormalized log-probability of each corresponding\n",
      " |              outcome in a batch.\n",
      " |      \n",
      " |          dtype: (Optional) The data type for the elements of the output tensor, if\n",
      " |              not specified, we will use int32.\n",
      " |      \n",
      " |          sample_size: Number of times to sample.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  Or(self, A: 'T_Or', B: 'T_Or') -> 'T1_Or'\n",
      " |      [üåê Or(7)](https://onnx.ai/onnx/operators/onnx__Or.html#or-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `or` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  Sin(self, input: 'T_Sin') -> 'T_Sin'\n",
      " |      [üåê Sin(7)](https://onnx.ai/onnx/operators/onnx__Sin.html#sin-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the sine of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Tan(self, input: 'T_Tan') -> 'T_Tan'\n",
      " |      [üåê Tan(7)](https://onnx.ai/onnx/operators/onnx__Tan.html#tan-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the tangent of the given input tensor, element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  Xor(self, A: 'T_Xor', B: 'T_Xor') -> 'T1_Xor'\n",
      " |      [üåê Xor(7)](https://onnx.ai/onnx/operators/onnx__Xor.html#xor-7 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the tensor resulted from performing the `xor` logical operation\n",
      " |      elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).\n",
      " |      \n",
      " |      This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          A: (non-differentiable) First input operand for the logical operator.\n",
      " |      \n",
      " |          B: (non-differentiable) Second input operand for the logical operator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset7.Opset7:\n",
      " |  \n",
      " |  T1_And = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_Multinomial = ~T1_Multinomial\n",
      " |  \n",
      " |  T1_Or = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T1_Xor = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T2_Multinomial = typing.Union[onnxscript.onnx_types.INT32, onnxscript....\n",
      " |  \n",
      " |  T_Acos = ~T_Acos\n",
      " |  \n",
      " |  T_And = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T_Asin = ~T_Asin\n",
      " |  \n",
      " |  T_Atan = ~T_Atan\n",
      " |  \n",
      " |  T_Cos = ~T_Cos\n",
      " |  \n",
      " |  T_Or = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T_Sin = ~T_Sin\n",
      " |  \n",
      " |  T_Tan = ~T_Tan\n",
      " |  \n",
      " |  T_Xor = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset6.Opset6:\n",
      " |  \n",
      " |  Elu(self, X: 'T_Elu', *, alpha: 'float' = 1.0) -> 'T_Elu'\n",
      " |      [üåê Elu(6)](https://onnx.ai/onnx/operators/onnx__Elu.html#elu-6 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Elu takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the function `f(x) = alpha * (exp(x) - 1.) for x <\n",
      " |      0`, `f(x) = x for x >= 0`., is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) 1D input tensor\n",
      " |      \n",
      " |          alpha: Coefficient of ELU.\n",
      " |  \n",
      " |  HardSigmoid(self, X: 'T_HardSigmoid', *, alpha: 'float' = 0.20000000298023224, beta: 'float' = 0.5) -> 'T_HardSigmoid'\n",
      " |      [üåê HardSigmoid(6)](https://onnx.ai/onnx/operators/onnx__HardSigmoid.html#hardsigmoid-6 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      HardSigmoid takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the HardSigmoid function, y = max(0, min(1, alpha * x + beta)),\n",
      " |      is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: Value of alpha.\n",
      " |      \n",
      " |          beta: Value of beta.\n",
      " |  \n",
      " |  InstanceNormalization(self, input: 'T_InstanceNormalization', scale: 'T_InstanceNormalization', B: 'T_InstanceNormalization', *, epsilon: 'float' = 9.999999747378752e-06) -> 'T_InstanceNormalization'\n",
      " |      [üåê InstanceNormalization(6)](https://onnx.ai/onnx/operators/onnx__InstanceNormalization.html#instancenormalization-6 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Carries out instance normalization as described in the paper\n",
      " |      https://arxiv.org/abs/1607.08022.\n",
      " |      \n",
      " |      y = scale * (x - mean) / sqrt(variance + epsilon) + B,\n",
      " |      where mean and variance are computed per instance per channel.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input data tensor from the previous operator;\n",
      " |              dimensions for image case are (N x C x H x W), where N is the batch\n",
      " |              size, C is the number of channels, and H and W are the height and the\n",
      " |              width of the data. For non image case, the dimensions are in the form of\n",
      " |              (N x C x D1 x D2 ... Dn), where N is the batch size.\n",
      " |      \n",
      " |          scale: (differentiable) The input 1-dimensional scale tensor of size C.\n",
      " |      \n",
      " |          B: (differentiable) The input 1-dimensional bias tensor of size C.\n",
      " |      \n",
      " |          epsilon: The epsilon value to use to avoid division by zero.\n",
      " |  \n",
      " |  Selu(self, X: 'T_Selu', *, alpha: 'float' = 1.6732631921768188, gamma: 'float' = 1.0507010221481323) -> 'T_Selu'\n",
      " |      [üåê Selu(6)](https://onnx.ai/onnx/operators/onnx__Selu.html#selu-6 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Selu takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the scaled exponential linear unit function,\n",
      " |      `y = gamma * (alpha * e^x - alpha) for x <= 0`, `y = gamma * x for x > 0`,\n",
      " |      is applied to the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input tensor\n",
      " |      \n",
      " |          alpha: Coefficient of SELU default to 1.67326319217681884765625 (i.e.,\n",
      " |              float32 approximation of 1.6732632423543772848170429916717).\n",
      " |      \n",
      " |          gamma: Coefficient of SELU default to 1.05070102214813232421875 (i.e.,\n",
      " |              float32 approximation of 1.0507009873554804934193349852946).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset6.Opset6:\n",
      " |  \n",
      " |  T_Elu = ~T_Elu\n",
      " |  \n",
      " |  T_HardSigmoid = ~T_HardSigmoid\n",
      " |  \n",
      " |  T_InstanceNormalization = ~T_InstanceNormalization\n",
      " |  \n",
      " |  T_Selu = ~T_Selu\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset2.Opset2:\n",
      " |  \n",
      " |  GlobalLpPool(self, X: 'T_GlobalLpPool', *, p: 'int' = 2) -> 'T_GlobalLpPool'\n",
      " |      [üåê GlobalLpPool(2)](https://onnx.ai/onnx/operators/onnx__GlobalLpPool.html#globallppool-2 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       GlobalLpPool consumes an input tensor X and applies lp pool pooling across\n",
      " |       the values in the same channel. This is equivalent to LpPool with kernel size\n",
      " |       equal to the spatial dimension of input tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size.\n",
      " |      \n",
      " |          p: p value of the Lp norm used to pool over the input data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset2.Opset2:\n",
      " |  \n",
      " |  T_GlobalLpPool = ~T_GlobalLpPool\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.onnx_opset._impl.opset1.Opset1:\n",
      " |  \n",
      " |  GlobalAveragePool(self, X: 'T_GlobalAveragePool') -> 'T_GlobalAveragePool'\n",
      " |      [üåê GlobalAveragePool(1)](https://onnx.ai/onnx/operators/onnx__GlobalAveragePool.html#globalaveragepool-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       GlobalAveragePool consumes an input tensor X and applies average pooling across\n",
      " |       the values in the same channel. This is equivalent to AveragePool with kernel size\n",
      " |       equal to the spatial dimension of input tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size.\n",
      " |  \n",
      " |  GlobalMaxPool(self, X: 'T_GlobalMaxPool') -> 'T_GlobalMaxPool'\n",
      " |      [üåê GlobalMaxPool(1)](https://onnx.ai/onnx/operators/onnx__GlobalMaxPool.html#globalmaxpool-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       GlobalMaxPool consumes an input tensor X and applies max pooling across\n",
      " |       the values in the same channel. This is equivalent to MaxPool with kernel size\n",
      " |       equal to the spatial dimension of input tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data. For non image case, the dimensions are in the form of (N x C x D1\n",
      " |              x D2 ... Dn), where N is the batch size.\n",
      " |  \n",
      " |  LpNormalization(self, input: 'T_LpNormalization', *, axis: 'int' = -1, p: 'int' = 2) -> 'T_LpNormalization'\n",
      " |      [üåê LpNormalization(1)](https://onnx.ai/onnx/operators/onnx__LpNormalization.html#lpnormalization-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Given a matrix, apply Lp-normalization along the provided axis.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input matrix\n",
      " |      \n",
      " |          axis: The axis on which to apply normalization, -1 mean last axis.\n",
      " |      \n",
      " |          p: The order of the normalization, only 1 or 2 are supported.\n",
      " |  \n",
      " |  MaxRoiPool(self, X: 'T_MaxRoiPool', rois: 'T_MaxRoiPool', *, pooled_shape: 'Sequence[int]', spatial_scale: 'float' = 1.0) -> 'T_MaxRoiPool'\n",
      " |      [üåê MaxRoiPool(1)](https://onnx.ai/onnx/operators/onnx__MaxRoiPool.html#maxroipool-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |       ROI max pool consumes an input tensor X and region of interests (RoIs) to\n",
      " |       apply max pooling across each RoI, to produce output 4-D tensor of shape\n",
      " |       (num_rois, channels, pooled_shape[0], pooled_shape[1]).\n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) Input data tensor from the previous operator; dimensions\n",
      " |              for image case are (N x C x H x W), where N is the batch size, C is the\n",
      " |              number of channels, and H and W are the height and the width of the\n",
      " |              data.\n",
      " |      \n",
      " |          rois: (non-differentiable) RoIs (Regions of Interest) to pool over. Should\n",
      " |              be a 2-D tensor of shape (num_rois, 5) given as [[batch_id, x1, y1, x2,\n",
      " |              y2], ...].\n",
      " |      \n",
      " |          pooled_shape: ROI pool output shape (height, width).\n",
      " |      \n",
      " |          spatial_scale: Multiplicative spatial scale factor to translate ROI\n",
      " |              coordinates from their input scale to the scale used when pooling.\n",
      " |  \n",
      " |  Not(self, X: 'T_Not') -> 'T_Not'\n",
      " |      [üåê Not(1)](https://onnx.ai/onnx/operators/onnx__Not.html#not-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Returns the negation of the input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (non-differentiable) Input tensor\n",
      " |  \n",
      " |  RandomNormal(self, *, dtype: 'int' = 1, mean: 'float' = 0.0, scale: 'float' = 1.0, seed: 'Optional[float]' = None, shape: 'Sequence[int]') -> 'T_RandomNormal'\n",
      " |      [üåê RandomNormal(1)](https://onnx.ai/onnx/operators/onnx__RandomNormal.html#randomnormal-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with random values drawn from a normal distribution. The shape\n",
      " |      of the tensor is specified by the `shape` argument and the parameter of the normal distribution\n",
      " |      specified by `mean` and `scale`.\n",
      " |      \n",
      " |      The data type is specified by the 'dtype' argument. The 'dtype' argument must\n",
      " |      be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          dtype: The data type for the elements of the output tensor. Default is\n",
      " |              TensorProto::FLOAT.\n",
      " |      \n",
      " |          mean: The mean of the normal distribution.\n",
      " |      \n",
      " |          scale: The standard deviation of the normal distribution.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |      \n",
      " |          shape: The shape of the output tensor.\n",
      " |  \n",
      " |  RandomNormalLike(self, input: 'T1_RandomNormalLike', *, dtype: 'Optional[int]' = None, mean: 'float' = 0.0, scale: 'float' = 1.0, seed: 'Optional[float]' = None) -> 'T2_RandomNormalLike'\n",
      " |      [üåê RandomNormalLike(1)](https://onnx.ai/onnx/operators/onnx__RandomNormalLike.html#randomnormallike-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with random values drawn from a normal distribution.\n",
      " |      The shape of the output tensor is copied from the shape of the input tensor,\n",
      " |      and the parameters of the normal distribution are specified by `mean` and `scale`.\n",
      " |      \n",
      " |      The data type is specified by the 'dtype' argument, or copied from the input tensor if not provided.\n",
      " |      The 'dtype' argument must be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message, and be valid as an output type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: Input tensor to copy shape and optionally type information from.\n",
      " |      \n",
      " |          dtype: (Optional) The data type for the elements of the output tensor, if\n",
      " |              not specified, we will use the data type of the input tensor.\n",
      " |      \n",
      " |          mean: The mean of the normal distribution.\n",
      " |      \n",
      " |          scale: The standard deviation of the normal distribution.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  RandomUniform(self, *, dtype: 'int' = 1, high: 'float' = 1.0, low: 'float' = 0.0, seed: 'Optional[float]' = None, shape: 'Sequence[int]') -> 'T_RandomUniform'\n",
      " |      [üåê RandomUniform(1)](https://onnx.ai/onnx/operators/onnx__RandomUniform.html#randomuniform-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with random values drawn from a uniform distribution. The shape\n",
      " |      of the tensor is specified by the `shape` argument and the range by `low` and `high`.\n",
      " |      \n",
      " |      The data type is specified by the 'dtype' argument. The 'dtype' argument must\n",
      " |      be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          dtype: The data type for the elements of the output tensor. If not\n",
      " |              specified, default is TensorProto::FLOAT.\n",
      " |      \n",
      " |          high: Upper boundary of the output values.\n",
      " |      \n",
      " |          low: Lower boundary of the output values.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |      \n",
      " |          shape: The shape of the output tensor.\n",
      " |  \n",
      " |  RandomUniformLike(self, input: 'T1_RandomUniformLike', *, dtype: 'Optional[int]' = None, high: 'float' = 1.0, low: 'float' = 0.0, seed: 'Optional[float]' = None) -> 'T2_RandomUniformLike'\n",
      " |      [üåê RandomUniformLike(1)](https://onnx.ai/onnx/operators/onnx__RandomUniformLike.html#randomuniformlike-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Generate a tensor with random values drawn from a uniform distribution.\n",
      " |      The shape of the output tensor is copied from the shape of the input tensor,\n",
      " |      and the parameters of the uniform distribution are specified by `low` and `high`.\n",
      " |      \n",
      " |      The data type is specified by the 'dtype' argument, or copied from the input tensor if not provided.\n",
      " |      The 'dtype' argument must be one of the data types specified in the 'DataType' enum field in the\n",
      " |      TensorProto message and be valid as an output type.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: Input tensor to copy shape and optionally type information from.\n",
      " |      \n",
      " |          dtype: (Optional) The data type for the elements of the output tensor, if\n",
      " |              not specified, we will use the data type of the input tensor.\n",
      " |      \n",
      " |          high: Upper boundary of the output values.\n",
      " |      \n",
      " |          low: Lower boundary of the output values.\n",
      " |      \n",
      " |          seed: (Optional) Seed to the random generator, if not specified we will auto\n",
      " |              generate one.\n",
      " |  \n",
      " |  Softplus(self, X: 'T_Softplus') -> 'T_Softplus'\n",
      " |      [üåê Softplus(1)](https://onnx.ai/onnx/operators/onnx__Softplus.html#softplus-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Softplus takes one input data (Tensor<T>) and produces one output data\n",
      " |      (Tensor<T>) where the softplus function, y = ln(exp(x) + 1), is applied to\n",
      " |      the tensor elementwise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          X: (differentiable) 1D input tensor\n",
      " |  \n",
      " |  Softsign(self, input: 'T_Softsign') -> 'T_Softsign'\n",
      " |      [üåê Softsign(1)](https://onnx.ai/onnx/operators/onnx__Softsign.html#softsign-1 \"Online Documentation\")\n",
      " |      \n",
      " |      \n",
      " |      Calculates the softsign (x/(1+|x|)) of the given input tensor element-wise.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          input: (differentiable) Input tensor\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.onnx_opset._impl.opset1.Opset1:\n",
      " |  \n",
      " |  T1_RandomNormalLike = ~T1_RandomNormalLike\n",
      " |  \n",
      " |  T1_RandomUniformLike = ~T1_RandomUniformLike\n",
      " |  \n",
      " |  T2_RandomNormalLike = typing.Union[onnxscript.onnx_types.DOUBLE, onnxs...\n",
      " |  \n",
      " |  T2_RandomUniformLike = typing.Union[onnxscript.onnx_types.DOUBLE, onnx...\n",
      " |  \n",
      " |  T_GlobalAveragePool = ~T_GlobalAveragePool\n",
      " |  \n",
      " |  T_GlobalMaxPool = ~T_GlobalMaxPool\n",
      " |  \n",
      " |  T_LpNormalization = ~T_LpNormalization\n",
      " |  \n",
      " |  T_MaxRoiPool = ~T_MaxRoiPool\n",
      " |  \n",
      " |  T_Not = <class 'onnxscript.onnx_types.BOOL'>\n",
      " |  \n",
      " |  T_RandomNormal = typing.Union[onnxscript.onnx_types.DOUBLE, onnxs....o...\n",
      " |  \n",
      " |  T_RandomUniform = typing.Union[onnxscript.onnx_types.DOUBLE, onnxs.......\n",
      " |  \n",
      " |  T_Softplus = ~T_Softplus\n",
      " |  \n",
      " |  T_Softsign = ~T_Softsign\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from onnxscript.values.Opset:\n",
      " |  \n",
      " |  __contains__(self, opname)\n",
      " |  \n",
      " |  __getattr__(self, attr: 'str')\n",
      " |  \n",
      " |  __getitem__(self, opname)\n",
      " |  \n",
      " |  __init__(self, domain: 'Optional[str]' = None, version: 'Optional[int]' = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add_function_def(self, fun)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from onnxscript.values.Opset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from onnxscript.values.Opset:\n",
      " |  \n",
      " |  cache = {(<class 'onnxscript.onnx_opset._impl.opset1.Opset1'>, '', 1):...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\33623\\Modeling\\tutoriaux\\onnx\\onnx-scripting.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/33623/Modeling/tutoriaux/onnx/onnx-scripting.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m op\u001b[39m.\u001b[39;49mConstant(value_strings\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtoto\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mtiti\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\onnx_opset\\_impl\\opset13.py:453\u001b[0m, in \u001b[0;36mOpset13.Constant\u001b[1;34m(self, sparse_value, value, value_float, value_floats, value_int, value_ints, value_string, value_strings)\u001b[0m\n\u001b[0;32m    451\u001b[0m schema \u001b[39m=\u001b[39m get_schema(\u001b[39m\"\u001b[39m\u001b[39mConstant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m13\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    452\u001b[0m op \u001b[39m=\u001b[39m Op(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mConstant\u001b[39m\u001b[39m\"\u001b[39m, schema)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m op(\n\u001b[0;32m    454\u001b[0m     sparse_value\u001b[39m=\u001b[39;49msparse_value,\n\u001b[0;32m    455\u001b[0m     value\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m    456\u001b[0m     value_float\u001b[39m=\u001b[39;49mvalue_float,\n\u001b[0;32m    457\u001b[0m     value_floats\u001b[39m=\u001b[39;49mvalue_floats,\n\u001b[0;32m    458\u001b[0m     value_int\u001b[39m=\u001b[39;49mvalue_int,\n\u001b[0;32m    459\u001b[0m     value_ints\u001b[39m=\u001b[39;49mvalue_ints,\n\u001b[0;32m    460\u001b[0m     value_string\u001b[39m=\u001b[39;49mvalue_string,\n\u001b[0;32m    461\u001b[0m     value_strings\u001b[39m=\u001b[39;49mvalue_strings,\n\u001b[0;32m    462\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\values.py:297\u001b[0m, in \u001b[0;36mOp.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m schema \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    295\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOp \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m does not have an OpSchema and cannot be evaluated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m     )\n\u001b[1;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m evaluator\u001b[39m.\u001b[39;49mdefault()\u001b[39m.\u001b[39;49meval(schema, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\evaluator.py:196\u001b[0m, in \u001b[0;36mBaseEvaluator.eval\u001b[1;34m(self, schema, inputs, attributes)\u001b[0m\n\u001b[0;32m    194\u001b[0m attributes, closure \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapt_attributes(schema, attributes)\n\u001b[0;32m    195\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapt_inputs(schema, inputs)\n\u001b[1;32m--> 196\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval(schema, inputs, attributes, closure)\n\u001b[0;32m    197\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapt_outputs(schema, outputs)\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\evaluator.py:510\u001b[0m, in \u001b[0;36mORTEvaluator._eval\u001b[1;34m(self, schema, inputs, attributes, closure)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_eval\u001b[39m(\u001b[39mself\u001b[39m, schema, inputs, attributes, closure):\n\u001b[1;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m _call_ort(schema, inputs, attributes, closure)\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\evaluator.py:464\u001b[0m, in \u001b[0;36m_call_ort\u001b[1;34m(schema, args, kwargs, implicit_args)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_ort\u001b[39m(\n\u001b[0;32m    457\u001b[0m     schema: onnx\u001b[39m.\u001b[39mdefs\u001b[39m.\u001b[39mOpSchema,\n\u001b[0;32m    458\u001b[0m     args: Sequence[Any],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[39m# Delay import onnxruntime so that onnxscript can be used without\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[39m# installing onnxruntime.\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39monnxruntime\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mort\u001b[39;00m  \u001b[39m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39monnxruntime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnxruntime_pybind11_state\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         Fail,\n\u001b[0;32m    467\u001b[0m         InvalidArgument,\n\u001b[0;32m    468\u001b[0m         InvalidGraph,\n\u001b[0;32m    469\u001b[0m     )\n\u001b[0;32m    471\u001b[0m     model, session_run_input, inputs \u001b[39m=\u001b[39m _prepare_model_and_inputs_for_eager(\n\u001b[0;32m    472\u001b[0m         schema, args, kwargs, implicit_args\n\u001b[0;32m    473\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'"
     ]
    }
   ],
   "source": [
    "op.Constant(value_strings=['toto','titi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ERROR: Unsupported statement type <class 'ast.Expr'>.\nat: Function 'findid', line 4\n    op.Constant(value_strings=['toto','titi'])\n    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\33623\\Modeling\\tutoriaux\\onnx\\onnx-scripting.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33623/Modeling/tutoriaux/onnx/onnx-scripting.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m@script\u001b[39;49m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/33623/Modeling/tutoriaux/onnx/onnx-scripting.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;49;00m \u001b[39mfindid\u001b[39;49m(S: STRING[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m]):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/33623/Modeling/tutoriaux/onnx/onnx-scripting.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     op\u001b[39m.\u001b[39;49mConstant(value_strings\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtoto\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mtiti\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\main.py:94\u001b[0m, in \u001b[0;36mscript.<locals>.transform\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m     92\u001b[0m env \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     93\u001b[0m env\u001b[39m.\u001b[39mupdate(closure\u001b[39m.\u001b[39mnonlocals)\n\u001b[1;32m---> 94\u001b[0m result \u001b[39m=\u001b[39m script_check(f_ast, opset, env, src, default_opset\u001b[39m=\u001b[39;49mdefault_opset)\n\u001b[0;32m     95\u001b[0m \u001b[39m# TODO: add transformations.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39mreturn\u001b[39;00m onnxscript\u001b[39m.\u001b[39mOnnxFunction(opset, f, result, src, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\main.py:38\u001b[0m, in \u001b[0;36mscript_check\u001b[1;34m(f, opset, global_names, source, default_opset)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m# See if conversion succeeds.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# TODO: cleanup Converter interface/API, separating checker from\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# converter\u001b[39;00m\n\u001b[0;32m     32\u001b[0m convert \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mConverter(\n\u001b[0;32m     33\u001b[0m     opset\u001b[39m=\u001b[39mopset,\n\u001b[0;32m     34\u001b[0m     global_names\u001b[39m=\u001b[39mglobal_names,\n\u001b[0;32m     35\u001b[0m     source\u001b[39m=\u001b[39msource,\n\u001b[0;32m     36\u001b[0m     default_opset\u001b[39m=\u001b[39mdefault_opset,\n\u001b[0;32m     37\u001b[0m )\n\u001b[1;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m convert\u001b[39m.\u001b[39;49mtranslate_function_def(f)\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\converter.py:1460\u001b[0m, in \u001b[0;36mConverter.translate_function_def\u001b[1;34m(self, stmt)\u001b[0m\n\u001b[0;32m   1458\u001b[0m domain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthis_module\u001b[39m.\u001b[39mdomain\n\u001b[0;32m   1459\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mir_builder\u001b[39m.\u001b[39mnew_function(stmt\u001b[39m.\u001b[39mname, domain, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1460\u001b[0m analysis\u001b[39m.\u001b[39;49mdo_liveness_analysis(stmt, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_message)\n\u001b[0;32m   1461\u001b[0m fn_ir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_translate_function_def_common(stmt)\n\u001b[0;32m   1462\u001b[0m fn_ir\u001b[39m.\u001b[39mdebug_print()\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\_internal\\analysis.py:150\u001b[0m, in \u001b[0;36mdo_liveness_analysis\u001b[1;34m(fun, formatter)\u001b[0m\n\u001b[0;32m    148\u001b[0m live: \u001b[39mset\u001b[39m[Any] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    149\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(fun\u001b[39m.\u001b[39mbody):\n\u001b[1;32m--> 150\u001b[0m     live \u001b[39m=\u001b[39m visit(s, live)\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\_internal\\analysis.py:97\u001b[0m, in \u001b[0;36mdo_liveness_analysis.<locals>.visit\u001b[1;34m(stmt, live_out)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit\u001b[39m(stmt: ast\u001b[39m.\u001b[39mstmt, live_out: Set[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Set[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m     96\u001b[0m     stmt\u001b[39m.\u001b[39mlive_out \u001b[39m=\u001b[39m live_out  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     live \u001b[39m=\u001b[39m do_visit(stmt, live_out)\n\u001b[0;32m     98\u001b[0m     stmt\u001b[39m.\u001b[39mlive_in \u001b[39m=\u001b[39m live  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[39mreturn\u001b[39;00m live\n",
      "File \u001b[1;32mc:\\Users\\33623\\Modeling\\.venv\\onnx_env\\lib\\site-packages\\onnxscript\\_internal\\analysis.py:145\u001b[0m, in \u001b[0;36mdo_liveness_analysis.<locals>.do_visit\u001b[1;34m(stmt, live_out)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m ast_utils\u001b[39m.\u001b[39mis_print_call(stmt):\n\u001b[0;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m live_out\n\u001b[1;32m--> 145\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(formatter(stmt, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported statement type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(stmt)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: ERROR: Unsupported statement type <class 'ast.Expr'>.\nat: Function 'findid', line 4\n    op.Constant(value_strings=['toto','titi'])\n    ^\n"
     ]
    }
   ],
   "source": [
    "@script()\n",
    "def findid(S: STRING[...]):\n",
    "  \n",
    "    op.Constant(value_strings=['toto','titi'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import TensorProto, helper\n",
    "\n",
    "from onnxscript import opset15 as op\n",
    "from onnxscript import script\n",
    "\n",
    "script_const = helper.make_tensor(\"scalar_half\", TensorProto.STRING, (), ['tutu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_type: 8\n",
       "string_data: \"tutu\"\n",
       "name: \"scalar_half\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
